
> model_name
[1] "glm ch_sfm.erosion.mean ~ ch_flow.accumulation.max VIF-inf"

> model_formula
ch_sfm.erosion.mean ~ ws_sbs_mean + ws_aspect_mean + ws_drainage_density + 
    ws_bare_earth_mean + ws_RV.Sand + ws_Kw + ch_curvature.median + 
    ch_valley_width + ch_central.slope.difference + ch_stream.power + 
    ch_channel.width.over.valley.width + ch_slope.over.width.central.diff + 
    ch_stream.power.central.diff + hs_flow.accumulation.max + 
    hs_slope.median + hs_aspect.median + hs_curvature.median + 
    hs_bare.earth.mean + hs_dnbr.median + flow.accumulation.max

> ssn_mod <- ssn_glm(
+   formula = model_formula,
+   ssn.object = ET_ssn,
+   family = "Gamma",
+   tailup_type = "exponential",
+   taildown_type = .... [TRUNCATED] 

> # Print the summary of the model to the file and console
> print(summary(ssn_mod))

Call:
ssn_glm(formula = model_formula, ssn.object = ET_ssn, family = "Gamma", 
    tailup_type = "exponential", taildown_type = "none", euclid_type = "gaussian", 
    additive = "afv_flow_accum")

Deviance Residuals:
     Min       1Q   Median       3Q      Max 
-6.24901 -0.31348 -0.05135  0.19649  1.76255 

Coefficients (fixed):
                                    Estimate Std. Error z value Pr(>|z|)    
(Intercept)                        -1.865647   0.341266  -5.467 4.58e-08 ***
ws_sbs_mean                         0.020729   0.261149   0.079  0.93673    
ws_aspect_mean                      0.792366   0.572952   1.383  0.16668    
ws_drainage_density                -0.002086   0.007409  -0.282  0.77825    
ws_bare_earth_mean                  0.361513   0.156242   2.314  0.02068 *  
ws_RV.Sand                          0.030786   0.091433   0.337  0.73634    
ws_Kw                              -0.173518   0.251148  -0.691  0.48963    
ch_curvature.median                -0.017417   0.039377  -0.442  0.65827    
ch_valley_width                    -0.084402   0.051577  -1.636  0.10175    
ch_central.slope.difference        -0.002171   0.023358  -0.093  0.92595    
ch_stream.power                     0.065828   0.045894   1.434  0.15148    
ch_channel.width.over.valley.width -0.024203   0.057552  -0.421  0.67410    
ch_slope.over.width.central.diff    0.031105   0.016547   1.880  0.06015 .  
ch_stream.power.central.diff       -0.010243   0.007852  -1.305  0.19206    
hs_flow.accumulation.max            0.007131   0.023759   0.300  0.76408    
hs_slope.median                    -0.001657   0.059223  -0.028  0.97768    
hs_aspect.median                    0.093702   0.030533   3.069  0.00215 ** 
hs_curvature.median                -0.009420   0.020018  -0.471  0.63793    
hs_bare.earth.mean                  0.073744   0.048915   1.508  0.13166    
hs_dnbr.median                     -0.066162   0.049937  -1.325  0.18520    
flow.accumulation.max              -0.047990   0.044120  -1.088  0.27673    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Pseudo R-squared: 0.02326

Coefficients (covariance):
              Effect     Parameter   Estimate
  tailup exponential  de (parsill)     0.9171
  tailup exponential         range  2175.5114
     euclid gaussian  de (parsill)     0.1278
     euclid gaussian         range    24.2882
              nugget        nugget     0.0169
          dispersion    dispersion     3.2072


> # Print variance components of the model
> varcomp(ssn_mod)
# A tibble: 5 × 2
  varcomp            proportion
  <chr>                   <dbl>
1 Covariates (PR-sq)     0.0233
2 tailup_de              0.844 
3 taildown_de            0     
4 euclid_de              0.118 
5 nugget                 0.0155

> # Tidy the model output with confidence intervals and print
> print(tidy(ssn_mod, conf.int = TRUE))  
# A tibble: 21 × 7
   term                               estimate std.error statistic      p.value conf.low conf.high
   <chr>                                 <dbl>     <dbl>     <dbl>        <dbl>    <dbl>     <dbl>
 1 (Intercept)                        -1.87      0.341     -5.47   0.0000000458 -2.53     -1.20   
 2 ch_central.slope.difference        -0.00217   0.0234    -0.0929 0.926        -0.0480    0.0436 
 3 ch_channel.width.over.valley.width -0.0242    0.0576    -0.421  0.674        -0.137     0.0886 
 4 ch_curvature.median                -0.0174    0.0394    -0.442  0.658        -0.0946    0.0598 
 5 ch_slope.over.width.central.diff    0.0311    0.0165     1.88   0.0601       -0.00133   0.0635 
 6 ch_stream.power                     0.0658    0.0459     1.43   0.151        -0.0241    0.156  
 7 ch_stream.power.central.diff       -0.0102    0.00785   -1.30   0.192        -0.0256    0.00515
 8 ch_valley_width                    -0.0844    0.0516    -1.64   0.102        -0.185     0.0167 
 9 flow.accumulation.max              -0.0480    0.0441    -1.09   0.277        -0.134     0.0385 
10 hs_aspect.median                    0.0937    0.0305     3.07   0.00215       0.0339    0.154  
# ℹ 11 more rows
# ℹ Use `print(n = ...)` to see more rows

> # Provide a glance summary of the model and print
> print(glance(ssn_mod))
# A tibble: 1 × 9
      n     p  npar value   AIC  AICc logLik deviance pseudo.r.squared
  <int> <dbl> <int> <dbl> <dbl> <dbl>  <dbl>    <dbl>            <dbl>
1   873    21     6 -390. -378. -378.   195.     210.           0.0233

> # Perform Leave-One-Out Cross Validation and print
> print("Leave One Out Cross Validation")
[1] "Leave One Out Cross Validation"

> loocv_results <- loocv(ssn_mod)

> print(loocv_results)
# A tibble: 1 × 4
     bias   MSPE RMSPE   RAV
    <dbl>  <dbl> <dbl> <dbl>
1 -0.0111 0.0160 0.126 0.550

> # Stop redirecting output
> sink()
      0.020729   0.261149   0.079  0.93673    
ws_aspect_mean                      0.792366   0.572952   1.383  0.16668    
ws_drainage_density                -0.002086   0.007409  -0.282  0.77825    
ws_bare_earth_mean                  0.361513   0.156242   2.314  0.02068 *  
ws_RV.Sand                          0.030786   0.091433   0.337  0.73634    
ws_Kw                              -0.173518   0.251148  -0.691  0.48963    
ch_curvature.median                -0.017417   0.039377  -0.442  0.65827    
ch_valley_width                    -0.084402   0.051577  -1.636  0.10175    
ch_central.slope.difference        -0.002171   0.023358  -0.093  0.92595    
ch_stream.power                     0.065828   0.045894   1.434  0.15148    
ch_channel.width.over.valley.width -0.024203   0.057552  -0.421  0.67410    
ch_slope.over.width.central.diff    0.031105   0.016547   1.880  0.06015 .  
ch_stream.power.central.diff       -0.010243   0.007852  -1.305  0.19206    
hs_flow.accumulation.max            0.007131   0.023759   0.300  0.76408    
hs_slope.median                    -0.001657   0.059223  -0.028  0.97768    
hs_aspect.median                    0.093702   0.030533   3.069  0.00215 ** 
hs_curvature.median                -0.009420   0.020018  -0.471  0.63793    
hs_bare.earth.mean                  0.073744   0.048915   1.508  0.13166    
hs_dnbr.median                     -0.066162   0.049937  -1.325  0.18520    
flow.accumulation.max              -0.047990   0.044120  -1.088  0.27673    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Pseudo R-squared: 0.02326

Coefficients (covariance):
              Effect     Parameter   Estimate
  tailup exponential  de (parsill)     0.9171
  tailup exponential         range  2175.5114
     euclid gaussian  de (parsill)     0.1278
     euclid gaussian         range    24.2882
              nugget        nugget     0.0169
          dispersion    dispersion     3.2072


> # Print variance components of the model
> varcomp(ssn_mod)
# A tibble: 5 × 2
  varcomp            proportion
  <chr>                   <dbl>
1 Covariates (PR-sq)     0.0233
2 tailup_de              0.844 
3 taildown_de            0     
4 euclid_de              0.118 
5 nugget                 0.0155

> # Tidy the model output with confidence intervals and print
> print(tidy(ssn_mod, conf.int = TRUE))  
# A tibble: 21 × 7
   term                               estimate std.error statistic      p.value conf.low conf.high
   <chr>                                 <dbl>     <dbl>     <dbl>        <dbl>    <dbl>     <dbl>
 1 (Intercept)                        -1.87      0.341     -5.47   0.0000000458 -2.53     -1.20   
 2 ch_central.slope.difference        -0.00217   0.0234    -0.0929 0.926        -0.0480    0.0436 
 3 ch_channel.width.over.valley.width -0.0242    0.0576    -0.421  0.674        -0.137     0.0886 
 4 ch_curvature.median                -0.0174    0.0394    -0.442  0.658        -0.0946    0.0598 
 5 ch_slope.over.width.central.diff    0.0311    0.0165     1.88   0.0601       -0.00133   0.0635 
 6 ch_stream.power                     0.0658    0.0459     1.43   0.151        -0.0241    0.156  
 7 ch_stream.power.central.diff       -0.0102    0.00785   -1.30   0.192        -0.0256    0.00515
 8 ch_valley_width                    -0.0844    0.0516    -1.64   0.102        -0.185     0.0167 
 9 flow.accumulation.max              -0.0480    0.0441    -1.09   0.277        -0.134     0.0385 
10 hs_aspect.median                    0.0937    0.0305     3.07   0.00215       0.0339    0.154  
# ℹ 11 more rows
# ℹ Use `print(n = ...)` to see more rows

> # Provide a glance summary of the model and print
> print(glance(ssn_mod))
# A tibble: 1 × 9
      n     p  npar value   AIC  AICc logLik deviance pseudo.r.squared
  <int> <dbl> <int> <dbl> <dbl> <dbl>  <dbl>    <dbl>            <dbl>
1   873    21     6 -390. -378. -378.   195.     210.           0.0233

> # Perform Leave-One-Out Cross Validation and print
> print("Leave One Out Cross Validation")
[1] "Leave One Out Cross Validation"

> loocv_results <- loocv(ssn_mod)

> print(loocv_results)
# A tibble: 1 × 4
     bias   MSPE RMSPE   RAV
    <dbl>  <dbl> <dbl> <dbl>
1 -0.0111 0.0160 0.126 0.550

> # Stop redirecting output
> sink()

> # ----------------------------#
> # 5. Model Evaluation
> # ----------------------------#
> 
> # Extract residuals and fitted values from the model
 .... [TRUNCATED] 

> fitted_values <- fitted(ssn_mod)   

> # ----------------------------#
> # 6. Plotting and Saving Graphs
> # ----------------------------#
> 
> 
> # Create the graph save directory if sav .... [TRUNCATED] 

> # ----------------------------#
> # 7. Residuals vs Fitted Values Plot
> # ----------------------------#
> 
> # Purpose:
> #   - Linearity: Ensure t .... [TRUNCATED] 

> # Create the Residuals vs Fitted Values plot
> resid_fitted_plot <- ggplot(data.frame(Fitted = fitted_values, Residuals = residuals), aes(x = Fitted .... [TRUNCATED] 

> # Display the plot
> print(resid_fitted_plot)

> # Save the plot if saving is enabled
> if (save_graphs) {
+   ggsave(filename = file.path(graph_save_dir, "Residuals_vs_Fitted.png"), plot = resid_f .... [TRUNCATED] 
[1] "Saved Residuals vs Fitted Values plot."

> # ----------------------------#
> # 8. Q-Q Plot for Residuals
> # ----------------------------#
> 
> # Purpose:
> #   - Normality: Verify that resid .... [TRUNCATED] 

> # Enhanced Q-Q Plot using ggplot2
> qq_plot <- ggplot(data.frame(Residuals = residuals), aes(sample = Residuals)) +
+   stat_qq(color = "blue") +
+  .... [TRUNCATED] 

> # Display the ggplot2 Q-Q plot
> print(qq_plot)

> # Save the ggplot2 Q-Q plot if saving is enabled
> if (save_graphs) {
+   ggsave(filename = file.path(graph_save_dir, "QQ_Plot_Residuals_GGPlot2.png ..." ... [TRUNCATED] 
[1] "Saved ggplot2 Q-Q Plot of Residuals."

> # ----------------------------#
> # 9. Histogram of Residuals
> # ----------------------------#
> 
> # Purpose:
> #   - Normality
> #
> # What to Lo .... [TRUNCATED] 

> # Enhanced Histogram using ggplot2
> hist_plot <- ggplot(data.frame(Residuals = residuals), aes(x = Residuals)) +
+   geom_histogram(aes(y = ..densi .... [TRUNCATED] 

> # Display the ggplot2 histogram
> print(hist_plot)

> # Save the ggplot2 histogram if saving is enabled
> if (save_graphs) {
+   ggsave(filename = file.path(graph_save_dir, "Histogram_Residuals_GGPlot2. ..." ... [TRUNCATED] 
[1] "Saved ggplot2 Histogram of Residuals with Normal Curve."

> # Redirect output to the specified file and also print to console
> sink(output_file, append = TRUE, split = TRUE)

> print("")
[1] ""

> # ----------------------------#
> # 10. Statistical Tests
> # ----------------------------#
> 
> 
> # --------- Shapiro-Wilk Test for Normality ---- .... [TRUNCATED] 
[1] "-------- Shapiro-Wilk Test for Normality ---------"

> print("  - Normality: To check if the residuals are normally distributed.")
[1] "  - Normality: To check if the residuals are normally distributed."

> print("  - p-value > 0.05: Fail to reject null hypothesis (residuals are normally distributed).")
[1] "  - p-value > 0.05: Fail to reject null hypothesis (residuals are normally distributed)."

> print("  - p-value <= 0.05: Reject null hypothesis (residuals are not normally distributed).\n")
[1] "  - p-value <= 0.05: Reject null hypothesis (residuals are not normally distributed).\n"

> shapiro_test <- shapiro.test(residuals)

> print("Shapiro-Wilk Test Results:")
[1] "Shapiro-Wilk Test Results:"

> print(shapiro_test)

	Shapiro-Wilk normality test

data:  residuals
W = 0.87333, p-value < 2.2e-16


> # --------- Breusch-Pagan Test for Homoscedasticity ---------
> print("-------- Breusch-Pagan Test for Homoscedasticity ---------")
[1] "-------- Breusch-Pagan Test for Homoscedasticity ---------"

> print("  - Homoscedasticity: To check if residuals have constant variance across all levels of fitted values.")
[1] "  - Homoscedasticity: To check if residuals have constant variance across all levels of fitted values."

> print("  - p-value > 0.05: Fail to reject null hypothesis (homoscedasticity holds).")
[1] "  - p-value > 0.05: Fail to reject null hypothesis (homoscedasticity holds)."

> print("  - p-value <= 0.05: Reject null hypothesis (heteroscedasticity present).\n")
[1] "  - p-value <= 0.05: Reject null hypothesis (heteroscedasticity present).\n"

> # Extract the model frame from the ssn_lm model
> data_ssn <- model.frame(ssn_mod)

> # Perform Breusch-Pagan Test
> bp_test <- bptest(ssn_mod)

> print("Breusch-Pagan Test Results:")
[1] "Breusch-Pagan Test Results:"

> print(bp_test)

	studentized Breusch-Pagan test

data:  ssn_mod
BP = 51.066, df = 20, p-value = 0.0001556


> # --------- Moran's I Test for Spatial Autocorrelation ---------
> print("\n-------- Moran's I Test for Spatial Autocorrelation ---------")
[1] "\n-------- Moran's I Test for Spatial Autocorrelation ---------"

> print("  - Spatial Autocorrelation: To determine if there is spatial autocorrelation in the residuals.")
[1] "  - Spatial Autocorrelation: To determine if there is spatial autocorrelation in the residuals."

> print("  - p-value > 0.05: Fail to reject null hypothesis (lack of spatial autocorrelation in residuals holds).")
[1] "  - p-value > 0.05: Fail to reject null hypothesis (lack of spatial autocorrelation in residuals holds)."

> print("  - p-value <= 0.05: Reject null hypothesis (spatial autocorrelation present).\n")
[1] "  - p-value <= 0.05: Reject null hypothesis (spatial autocorrelation present).\n"

> sink()

> # Extract spatial coordinates from the SSN object
> # Ensure that your SSN object has geometry information
> coords <- st_coordinates(ssn_get_data(s .... [TRUNCATED] 

> # Create a spatial weights matrix using k-nearest neighbors (k = 4 as an example)
> knn <- knearneigh(coords, k = 4)

> nb <- knn2nb(knn)

> lw <- nb2listw(nb, style = "W", zero.policy = TRUE)

> # Compute Moran's I
> moran_test <- moran.test(residuals, lw, zero.policy = TRUE)

> sink(output_file, append = TRUE, split = TRUE)

> print("Moran's I Test Results:")
[1] "Moran's I Test Results:"

> print(moran_test)

	Moran I test under randomisation

data:  residuals  
weights: lw    

Moran I statistic standard deviate = -4.8236, p-value = 1
alternative hypothesis: greater
sample estimates:
Moran I statistic       Expectation          Variance 
    -0.1133883582     -0.0011467890      0.0005414531 


> # Stop redirecting output
> sink()

> # --------------------------------------------------
> # End of Script
> # --------------------------------------------------
> 

> # --------------------------------------------------
> # Spatial Statistical Modeling with SSN2
> # ------------------------------------------------ .... [TRUNCATED] 

> # Specify the input and output directories
> input_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/Inputs"

> output_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/SSN ET/ET Full error thresh"

> model_name <- "glm ch_sfm.erosion.mean Zuur VIF-2"

> # Use file.path to create platform-independent file paths
> streams_path <- file.path(input_dir, "streams_100k.gpkg")

> obs_points_path <- file.path(input_dir, "Combined Watersheds", "ET Full combined ssn points.gpkg")

> ssn_path <- file.path(output_dir, "1_ET_Full_logtrans_independent_vars.ssn")

> read_ssn <- FALSE # whether to create a new ssn (FALSE) or read the pre-existing ssn (TRUE)

> output_file <- file.path(output_dir, model_name, "Results.txt")

> lsn_out <- file.path(output_dir, "0_lsn")

> # Define whether to save graphs and the directory to save them
> save_graphs <- TRUE  # Set to TRUE to save graphs as PNG

> graph_save_dir <- file.path(output_dir, model_name)  # Directory to save graphs

> # ----------------------------#
> # 1. Load Necessary Libraries
> # ----------------------------#
> 
> # Load required libraries
> library(SSN2)

> library(SSNbler)

> library(sf)

> library(dplyr)

> library(purrr)

> library(ggplot2)

> library(lmtest)

> library(spdep)

> library(classInt)   # Required for knearneigh

> library(broom)      # For tidy() and glance() functions

> library(grid)       # For grid.newpage()

> if (!dir.exists(graph_save_dir)) {
+   dir.create(graph_save_dir, recursive = TRUE)
+ }

> # ----------------------------#
> # 2. Read Spatial Data
> # ----------------------------#
> 
> # Read the streams dataset
> ET_streams <- st_read(s .... [TRUNCATED] 
Reading layer `streams_100k' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\streams_100k.gpkg' using driver `GPKG'
Simple feature collection with 643 features and 2 fields
Geometry type: LINESTRING
Dimension:     XY
Bounding box:  xmin: 404042.6 ymin: 4447904 xmax: 414579.6 ymax: 4466669
Projected CRS: NAD83 / UTM zone 13N

> # Read the observation points dataset
> ET_obs <- st_read(obs_points_path)
Reading layer `ET Full combined ssn points' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\Combined Watersheds\ET Full combined ssn points.gpkg' using driver `GPKG'
Simple feature collection with 892 features and 58 fields
Geometry type: POINT
Dimension:     XY
Bounding box:  xmin: 407401.1 ymin: 4449827 xmax: 413050.2 ymax: 4464548
Projected CRS: NAD83 / UTM zone 13N

> # Uncomment the following line if you encounter an error about Multilinestrings
> # ET_streams <- st_cast(ET_streams, "LINESTRING")
> 
> # --------- .... [TRUNCATED] 
[1] "Edge Attributes:"
[1] "rid"            "STRM_VAL"       "flow_accum_max" "Length"         "upDist"         "geometry"      
[1] "Site List Components:"
[1] "obs"
[1] "Updated Edge Attributes:"
[1] "rid"            "STRM_VAL"       "flow_accum_max" "Length"         "upDist"         "flow_accum_PI"  "afv_flow_accum" "geometry"      


SSN object is valid: TRUE

> # Create a distance matrix for spatial relationships
> # Purpose: Define spatial dependencies based on distances between sites
> ssn_create_distmat( .... [TRUNCATED] 

> # ----------------------------#
> # 4. Model Fitting and Output
> # ----------------------------#
> 
> # Redirect output to the specified file and a .... [TRUNCATED] 

> model_name
[1] "glm ch_sfm.erosion.mean Zuur VIF-2"

> model_formula
ch_sfm.erosion.mean ~ ws_flow.accum.max + ws_slope.mean + ws_bare.earth.mean + 
    ws_drainage_density + ws_RV.Sand + ch_curvature.median + 
    ch_valley_width + ch_central.slope.difference + ch_channel.width.over.valley.width + 
    ch_stream.power.central.diff + hs_hillslope.length + hs_slope.median + 
    hs_northness.median + hs_eastness.median + hs_curvature.median + 
    hs_bare.earth.mean + hs_ndvi.range + hs_dnbr.median + hs_drainage_density + 
    flow.accumulation.max

> ssn_mod <- ssn_glm(
+   formula = model_formula,
+   ssn.object = ET_ssn,
+   family = "Gamma",
+   tailup_type = "exponential",
+   taildown_type = .... [TRUNCATED] 

> # Print the summary of the model to the file and console
> print(summary(ssn_mod))

Call:
ssn_glm(formula = model_formula, ssn.object = ET_ssn, family = "Gamma", 
    tailup_type = "exponential", taildown_type = "none", euclid_type = "gaussian", 
    additive = "afv_flow_accum")

Deviance Residuals:
     Min       1Q   Median       3Q      Max 
-6.30725 -0.29256 -0.04886  0.17117  1.76129 

Coefficients (fixed):
                                    Estimate Std. Error z value Pr(>|z|)    
(Intercept)                        -1.716985   0.181924  -9.438   <2e-16 ***
ws_flow.accum.max                   0.060288   0.139361   0.433   0.6653    
ws_slope.mean                       0.201991   0.130074   1.553   0.1204    
ws_bare.earth.mean                 -0.015283   0.075889  -0.201   0.8404    
ws_drainage_density                 0.004593   0.008075   0.569   0.5695    
ws_RV.Sand                          0.070641   0.044993   1.570   0.1164    
ch_curvature.median                -0.017211   0.030919  -0.557   0.5778    
ch_valley_width                    -0.066806   0.041385  -1.614   0.1065    
ch_central.slope.difference         0.013377   0.016936   0.790   0.4296    
ch_channel.width.over.valley.width  0.022934   0.043877   0.523   0.6012    
ch_stream.power.central.diff       -0.001619   0.005425  -0.298   0.7654    
hs_hillslope.length                -0.028723   0.025413  -1.130   0.2584    
hs_slope.median                     0.004491   0.053547   0.084   0.9332    
hs_northness.median                 0.004844   0.035300   0.137   0.8909    
hs_eastness.median                 -0.017579   0.024584  -0.715   0.4746    
hs_curvature.median                -0.028529   0.016873  -1.691   0.0909 .  
hs_bare.earth.mean                  0.027284   0.038247   0.713   0.4756    
hs_ndvi.range                      -0.079233   0.038697  -2.048   0.0406 *  
hs_dnbr.median                     -0.093638   0.046611  -2.009   0.0445 *  
hs_drainage_density                -0.486076   7.523372  -0.065   0.9485    
flow.accumulation.max              -0.033870   0.029014  -1.167   0.2431    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Pseudo R-squared: 0.01547

Coefficients (covariance):
              Effect     Parameter   Estimate
  tailup exponential  de (parsill)  2.404e-01
  tailup exponential         range  2.198e+02
     euclid gaussian  de (parsill)  7.488e-02
     euclid gaussian         range  2.078e+03
              nugget        nugget  1.295e-02
          dispersion    dispersion  4.143e+00


> # Print variance components of the model
> varcomp(ssn_mod)
# A tibble: 5 × 2
  varcomp            proportion
  <chr>                   <dbl>
1 Covariates (PR-sq)     0.0155
2 tailup_de              0.721 
3 taildown_de            0     
4 euclid_de              0.225 
5 nugget                 0.0388

> # Tidy the model output with confidence intervals and print
> print(tidy(ssn_mod, conf.int = TRUE))  
# A tibble: 21 × 7
   term                               estimate std.error statistic p.value conf.low conf.high
   <chr>                                 <dbl>     <dbl>     <dbl>   <dbl>    <dbl>     <dbl>
 1 (Intercept)                        -1.72      0.182      -9.44   0       -2.07    -1.36   
 2 ch_central.slope.difference         0.0134    0.0169      0.790  0.430   -0.0198   0.0466 
 3 ch_channel.width.over.valley.width  0.0229    0.0439      0.523  0.601   -0.0631   0.109  
 4 ch_curvature.median                -0.0172    0.0309     -0.557  0.578   -0.0778   0.0434 
 5 ch_stream.power.central.diff       -0.00162   0.00543    -0.298  0.765   -0.0123   0.00901
 6 ch_valley_width                    -0.0668    0.0414     -1.61   0.106   -0.148    0.0143 
 7 flow.accumulation.max              -0.0339    0.0290     -1.17   0.243   -0.0907   0.0230 
 8 hs_bare.earth.mean                  0.0273    0.0382      0.713  0.476   -0.0477   0.102  
 9 hs_curvature.median                -0.0285    0.0169     -1.69   0.0909  -0.0616   0.00454
10 hs_dnbr.median                     -0.0936    0.0466     -2.01   0.0445  -0.185   -0.00228
# ℹ 11 more rows
# ℹ Use `print(n = ...)` to see more rows

> # Provide a glance summary of the model and print
> print(glance(ssn_mod))
# A tibble: 1 × 9
      n     p  npar value   AIC  AICc logLik deviance pseudo.r.squared
  <int> <dbl> <int> <dbl> <dbl> <dbl>  <dbl>    <dbl>            <dbl>
1   892    21     6  186.  198.  198.  -93.2     177.           0.0155

> # Perform Leave-One-Out Cross Validation and print
> print("Leave One Out Cross Validation")
[1] "Leave One Out Cross Validation"

> loocv_results <- loocv(ssn_mod)

> print(loocv_results)
# A tibble: 1 × 4
     bias   MSPE RMSPE   RAV
    <dbl>  <dbl> <dbl> <dbl>
1 -0.0127 0.0187 0.137 0.319

> # Stop redirecting output
> sink()

> # ----------------------------#
> # 5. Model Evaluation
> # ----------------------------#
> 
> # Extract residuals and fitted values from the model
 .... [TRUNCATED] 

> fitted_values <- fitted(ssn_mod)   

> # ----------------------------#
> # 6. Plotting and Saving Graphs
> # ----------------------------#
> 
> 
> # Create the graph save directory if sav .... [TRUNCATED] 

> # ----------------------------#
> # 7. Residuals vs Fitted Values Plot
> # ----------------------------#
> 
> # Purpose:
> #   - Linearity: Ensure t .... [TRUNCATED] 

> # Create the Residuals vs Fitted Values plot
> resid_fitted_plot <- ggplot(data.frame(Fitted = fitted_values, Residuals = residuals), aes(x = Fitted .... [TRUNCATED] 

> # Display the plot
> print(resid_fitted_plot)

> # Save the plot if saving is enabled
> if (save_graphs) {
+   ggsave(filename = file.path(graph_save_dir, "Residuals_vs_Fitted.png"), plot = resid_f .... [TRUNCATED] 
[1] "Saved Residuals vs Fitted Values plot."

> # ----------------------------#
> # 8. Q-Q Plot for Residuals
> # ----------------------------#
> 
> # Purpose:
> #   - Normality: Verify that resid .... [TRUNCATED] 

> # Enhanced Q-Q Plot using ggplot2
> qq_plot <- ggplot(data.frame(Residuals = residuals), aes(sample = Residuals)) +
+   stat_qq(color = "blue") +
+  .... [TRUNCATED] 

> # Display the ggplot2 Q-Q plot
> print(qq_plot)

> # Save the ggplot2 Q-Q plot if saving is enabled
> if (save_graphs) {
+   ggsave(filename = file.path(graph_save_dir, "QQ_Plot_Residuals_GGPlot2.png ..." ... [TRUNCATED] 
[1] "Saved ggplot2 Q-Q Plot of Residuals."

> # ----------------------------#
> # 9. Histogram of Residuals
> # ----------------------------#
> 
> # Purpose:
> #   - Normality
> #
> # What to Lo .... [TRUNCATED] 

> # Enhanced Histogram using ggplot2
> hist_plot <- ggplot(data.frame(Residuals = residuals), aes(x = Residuals)) +
+   geom_histogram(aes(y = ..densi .... [TRUNCATED] 

> # Display the ggplot2 histogram
> print(hist_plot)

> # Save the ggplot2 histogram if saving is enabled
> if (save_graphs) {
+   ggsave(filename = file.path(graph_save_dir, "Histogram_Residuals_GGPlot2. ..." ... [TRUNCATED] 
[1] "Saved ggplot2 Histogram of Residuals with Normal Curve."

> # Redirect output to the specified file and also print to console
> sink(output_file, append = TRUE, split = TRUE)

> print("")
[1] ""

> # ----------------------------#
> # 10. Statistical Tests
> # ----------------------------#
> 
> 
> # --------- Shapiro-Wilk Test for Normality ---- .... [TRUNCATED] 
[1] "-------- Shapiro-Wilk Test for Normality ---------"

> print("  - Normality: To check if the residuals are normally distributed.")
[1] "  - Normality: To check if the residuals are normally distributed."

> print("  - p-value > 0.05: Fail to reject null hypothesis (residuals are normally distributed).")
[1] "  - p-value > 0.05: Fail to reject null hypothesis (residuals are normally distributed)."

> print("  - p-value <= 0.05: Reject null hypothesis (residuals are not normally distributed).\n")
[1] "  - p-value <= 0.05: Reject null hypothesis (residuals are not normally distributed).\n"

> shapiro_test <- shapiro.test(residuals)

> print("Shapiro-Wilk Test Results:")
[1] "Shapiro-Wilk Test Results:"

> print(shapiro_test)

	Shapiro-Wilk normality test

data:  residuals
W = 0.85179, p-value < 2.2e-16


> # --------- Breusch-Pagan Test for Homoscedasticity ---------
> print("-------- Breusch-Pagan Test for Homoscedasticity ---------")
[1] "-------- Breusch-Pagan Test for Homoscedasticity ---------"

> print("  - Homoscedasticity: To check if residuals have constant variance across all levels of fitted values.")
[1] "  - Homoscedasticity: To check if residuals have constant variance across all levels of fitted values."

> print("  - p-value > 0.05: Fail to reject null hypothesis (homoscedasticity holds).")
[1] "  - p-value > 0.05: Fail to reject null hypothesis (homoscedasticity holds)."

> print("  - p-value <= 0.05: Reject null hypothesis (heteroscedasticity present).\n")
[1] "  - p-value <= 0.05: Reject null hypothesis (heteroscedasticity present).\n"

> # Extract the model frame from the ssn_lm model
> data_ssn <- model.frame(ssn_mod)

> # Perform Breusch-Pagan Test
> bp_test <- bptest(ssn_mod)

> print("Breusch-Pagan Test Results:")
[1] "Breusch-Pagan Test Results:"

> print(bp_test)

	studentized Breusch-Pagan test

data:  ssn_mod
BP = 52.638, df = 20, p-value = 9.186e-05


> # --------- Moran's I Test for Spatial Autocorrelation ---------
> print("\n-------- Moran's I Test for Spatial Autocorrelation ---------")
[1] "\n-------- Moran's I Test for Spatial Autocorrelation ---------"

> print("  - Spatial Autocorrelation: To determine if there is spatial autocorrelation in the residuals.")
[1] "  - Spatial Autocorrelation: To determine if there is spatial autocorrelation in the residuals."

> print("  - p-value > 0.05: Fail to reject null hypothesis (lack of spatial autocorrelation in residuals holds).")
[1] "  - p-value > 0.05: Fail to reject null hypothesis (lack of spatial autocorrelation in residuals holds)."

> print("  - p-value <= 0.05: Reject null hypothesis (spatial autocorrelation present).\n")
[1] "  - p-value <= 0.05: Reject null hypothesis (spatial autocorrelation present).\n"

> sink()

> # Extract spatial coordinates from the SSN object
> # Ensure that your SSN object has geometry information
> coords <- st_coordinates(ssn_get_data(s .... [TRUNCATED] 

> # Create a spatial weights matrix using k-nearest neighbors (k = 4 as an example)
> knn <- knearneigh(coords, k = 4)

> nb <- knn2nb(knn)

> lw <- nb2listw(nb, style = "W", zero.policy = TRUE)

> # Compute Moran's I
> moran_test <- moran.test(residuals, lw, zero.policy = TRUE)

> sink(output_file, append = TRUE, split = TRUE)

> print("Moran's I Test Results:")
[1] "Moran's I Test Results:"

> print(moran_test)

	Moran I test under randomisation

data:  residuals  
weights: lw    

Moran I statistic standard deviate = -2.6969, p-value = 0.9965
alternative hypothesis: greater
sample estimates:
Moran I statistic       Expectation          Variance 
    -0.0626333675     -0.0011223345      0.0005201907 


> # Stop redirecting output
> sink()

> # --------------------------------------------------
> # End of Script
> # --------------------------------------------------
> 

> # --------------------------------------------------
> # Spatial Statistical Modeling with SSN2
> # ------------------------------------------------ .... [TRUNCATED] 

> # Specify the input and output directories
> input_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/Inputs"

> output_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/SSN ET/ET Lower error thresh"

> model_name <- "glm ch_sfm.erosion.mean Zuur VIF-2"

> read_ssn <- FALSE # whether to create a new ssn (FALSE) or read the pre-existing ssn (TRUE)

> # Use file.path to create platform-independent file paths
> streams_path <- file.path(input_dir, "streams_100k.gpkg")

> obs_points_path <- file.path(input_dir, "Combined Watersheds", "ET Full combined ssn points.gpkg")

> ssn_path <- file.path(output_dir, "1_ET_Full_logtrans_independent_vars.ssn")

> output_file <- file.path(output_dir, model_name, "Results.txt")

> lsn_out <- file.path(output_dir, "0_lsn")

> # Define whether to save graphs and the directory to save them
> save_graphs <- TRUE  # Set to TRUE to save graphs as PNG

> graph_save_dir <- file.path(output_dir, model_name)  # Directory to save graphs

> # ----------------------------#
> # 1. Load Necessary Libraries
> # ----------------------------#
> 
> # Load required libraries
> library(SSN2)

> library(SSNbler)

> library(sf)

> library(dplyr)

> library(purrr)

> library(ggplot2)

> library(lmtest)

> library(spdep)

> library(classInt)   # Required for knearneigh

> library(broom)      # For tidy() and glance() functions

> library(grid)       # For grid.newpage()

> if (!dir.exists(graph_save_dir)) {
+   dir.create(graph_save_dir, recursive = TRUE)
+ }

> # ----------------------------#
> # 2. Read Spatial Data
> # ----------------------------#
> 
> # Read the streams dataset
> ET_streams <- st_read(s .... [TRUNCATED] 
Reading layer `streams_100k' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\streams_100k.gpkg' using driver `GPKG'
Simple feature collection with 643 features and 2 fields
Geometry type: LINESTRING
Dimension:     XY
Bounding box:  xmin: 404042.6 ymin: 4447904 xmax: 414579.6 ymax: 4466669
Projected CRS: NAD83 / UTM zone 13N

> # Read the observation points dataset
> ET_obs <- st_read(obs_points_path)
Reading layer `ET Full combined ssn points' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\Combined Watersheds\ET Full combined ssn points.gpkg' using driver `GPKG'
Simple feature collection with 892 features and 58 fields
Geometry type: POINT
Dimension:     XY
Bounding box:  xmin: 407401.1 ymin: 4449827 xmax: 413050.2 ymax: 4464548
Projected CRS: NAD83 / UTM zone 13N

> # Uncomment the following line if you encounter an error about Multilinestrings
> # ET_streams <- st_cast(ET_streams, "LINESTRING")
> 
> # --------- .... [TRUNCATED] 

> # --------------------------------------------------
> # Spatial Statistical Modeling with SSN2
> # ------------------------------------------------ .... [TRUNCATED] 

> # Specify the input and output directories
> input_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/Inputs"

> output_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/SSN ET/ET Lower error thresh"

> model_name <- "glm ch_sfm.erosion.mean Zuur VIF-2"

> read_ssn <- FALSE # whether to create a new ssn (FALSE) or read the pre-existing ssn (TRUE)

> # Use file.path to create platform-independent file paths
> streams_path <- file.path(input_dir, "streams_100k.gpkg")

> obs_points_path <- file.path(input_dir, "Combined Watersheds", "ET Lower combined ssn points.gpkg")

> ssn_path <- file.path(output_dir, "1_ET_Full_logtrans_independent_vars.ssn")

> output_file <- file.path(output_dir, model_name, "Results.txt")

> lsn_out <- file.path(output_dir, "0_lsn")

> # Define whether to save graphs and the directory to save them
> save_graphs <- TRUE  # Set to TRUE to save graphs as PNG

> graph_save_dir <- file.path(output_dir, model_name)  # Directory to save graphs

> # ----------------------------#
> # 1. Load Necessary Libraries
> # ----------------------------#
> 
> # Load required libraries
> library(SSN2)

> library(SSNbler)

> library(sf)

> library(dplyr)

> library(purrr)

> library(ggplot2)

> library(lmtest)

> library(spdep)

> library(classInt)   # Required for knearneigh

> library(broom)      # For tidy() and glance() functions

> library(grid)       # For grid.newpage()

> if (!dir.exists(graph_save_dir)) {
+   dir.create(graph_save_dir, recursive = TRUE)
+ }

> # ----------------------------#
> # 2. Read Spatial Data
> # ----------------------------#
> 
> # Read the streams dataset
> ET_streams <- st_read(s .... [TRUNCATED] 
Reading layer `streams_100k' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\streams_100k.gpkg' using driver `GPKG'
Simple feature collection with 643 features and 2 fields
Geometry type: LINESTRING
Dimension:     XY
Bounding box:  xmin: 404042.6 ymin: 4447904 xmax: 414579.6 ymax: 4466669
Projected CRS: NAD83 / UTM zone 13N

> # Read the observation points dataset
> ET_obs <- st_read(obs_points_path)
Reading layer `ET Lower combined ssn points' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\Combined Watersheds\ET Lower combined ssn points.gpkg' using driver `GPKG'
Simple feature collection with 176 features and 57 fields
Geometry type: POINT
Dimension:     XY
Bounding box:  xmin: 411935.6 ymin: 4449827 xmax: 413050.2 ymax: 4450907
Projected CRS: NAD83 / UTM zone 13N

> # Uncomment the following line if you encounter an error about Multilinestrings
> # ET_streams <- st_cast(ET_streams, "LINESTRING")
> 
> # --------- .... [TRUNCATED] 
[1] "Edge Attributes:"
[1] "rid"            "STRM_VAL"       "flow_accum_max" "Length"         "upDist"         "geometry"      
[1] "Site List Components:"
[1] "obs"
[1] "Updated Edge Attributes:"
[1] "rid"            "STRM_VAL"       "flow_accum_max" "Length"         "upDist"         "flow_accum_PI"  "afv_flow_accum" "geometry"      


SSN object is valid: TRUE

> # Create a distance matrix for spatial relationships
> # Purpose: Define spatial dependencies based on distances between sites
> ssn_create_distmat( .... [TRUNCATED] 

> # ----------------------------#
> # 4. Model Fitting and Output
> # ----------------------------#
> 
> # Redirect output to the specified file and a .... [TRUNCATED] 

> model_name
[1] "glm ch_sfm.erosion.mean Zuur VIF-2"

> model_formula
ch_sfm.erosion.mean ~ ws_dnbr.mean + ws_bare.earth.mean + ch_slope.median + 
    ch_curvature.median + ch_central.slope.difference + ch_channel.width.over.valley.width + 
    ch_stream.power.central.diff + hs_hillslope.length + hs_slope.median + 
    hs_eastness.median + hs_curvature.median + hs_ndvi.range + 
    hs_dnbr.median + hs_drainage_density

> ssn_mod <- ssn_glm(
+   formula = model_formula,
+   ssn.object = ET_ssn,
+   family = "Gamma",
+   tailup_type = "exponential",
+   taildown_type = .... [TRUNCATED] 

> # Print the summary of the model to the file and console
> print(summary(ssn_mod))

Call:
ssn_glm(formula = model_formula, ssn.object = ET_ssn, family = "Gamma", 
    tailup_type = "exponential", taildown_type = "none", euclid_type = "gaussian", 
    additive = "afv_flow_accum")

Deviance Residuals:
      Min        1Q    Median        3Q       Max 
-0.573944 -0.143091 -0.007887  0.107277  0.533722 

Coefficients (fixed):
                                   Estimate Std. Error z value Pr(>|z|)    
(Intercept)                        -1.30767    0.18739  -6.978 2.99e-12 ***
ws_dnbr.mean                       -0.24164    0.22633  -1.068  0.28568    
ws_bare.earth.mean                  0.06675    0.09907   0.674  0.50045    
ch_slope.median                    -0.01225    0.10444  -0.117  0.90661    
ch_curvature.median                 0.07207    0.06103   1.181  0.23763    
ch_central.slope.difference        -0.01708    0.04122  -0.414  0.67852    
ch_channel.width.over.valley.width  0.18467    0.08881   2.079  0.03759 *  
ch_stream.power.central.diff        0.11911    0.04304   2.767  0.00565 ** 
hs_hillslope.length                -0.14380    0.08621  -1.668  0.09531 .  
hs_slope.median                    -0.10740    0.07360  -1.459  0.14448    
hs_eastness.median                 -0.13560    0.09845  -1.377  0.16843    
hs_curvature.median                -0.10431    0.05109  -2.042  0.04117 *  
hs_ndvi.range                      -0.27003    0.10182  -2.652  0.00800 ** 
hs_dnbr.median                     -0.16609    0.12936  -1.284  0.19917    
hs_drainage_density                 1.11734   25.88454   0.043  0.96557    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Pseudo R-squared: 0.166

Coefficients (covariance):
              Effect     Parameter   Estimate
  tailup exponential  de (parsill)    0.29780
  tailup exponential         range   93.47916
     euclid gaussian  de (parsill)    0.03012
     euclid gaussian         range  376.54744
              nugget        nugget    0.08486
          dispersion    dispersion   10.12906


> # Print variance components of the model
> varcomp(ssn_mod)
# A tibble: 5 × 2
  varcomp            proportion
  <chr>                   <dbl>
1 Covariates (PR-sq)     0.166 
2 tailup_de              0.602 
3 taildown_de            0     
4 euclid_de              0.0609
5 nugget                 0.171 

> # Tidy the model output with confidence intervals and print
> print(tidy(ssn_mod, conf.int = TRUE))  
# A tibble: 15 × 7
   term                               estimate std.error statistic  p.value conf.low conf.high
   <chr>                                 <dbl>     <dbl>     <dbl>    <dbl>    <dbl>     <dbl>
 1 (Intercept)                         -1.31      0.187    -6.98   2.99e-12  -1.67    -0.940  
 2 ch_central.slope.difference         -0.0171    0.0412   -0.414  6.79e- 1  -0.0979   0.0637 
 3 ch_channel.width.over.valley.width   0.185     0.0888    2.08   3.76e- 2   0.0106   0.359  
 4 ch_curvature.median                  0.0721    0.0610    1.18   2.38e- 1  -0.0475   0.192  
 5 ch_slope.median                     -0.0123    0.104    -0.117  9.07e- 1  -0.217    0.192  
 6 ch_stream.power.central.diff         0.119     0.0430    2.77   5.65e- 3   0.0348   0.203  
 7 hs_curvature.median                 -0.104     0.0511   -2.04   4.12e- 2  -0.204   -0.00418
 8 hs_dnbr.median                      -0.166     0.129    -1.28   1.99e- 1  -0.420    0.0875 
 9 hs_drainage_density                  1.12     25.9       0.0432 9.66e- 1 -49.6     51.9    
10 hs_eastness.median                  -0.136     0.0985   -1.38   1.68e- 1  -0.329    0.0574 
11 hs_hillslope.length                 -0.144     0.0862   -1.67   9.53e- 2  -0.313    0.0252 
12 hs_ndvi.range                       -0.270     0.102    -2.65   8.00e- 3  -0.470   -0.0705 
13 hs_slope.median                     -0.107     0.0736   -1.46   1.44e- 1  -0.252    0.0368 
14 ws_bare.earth.mean                   0.0668    0.0991    0.674  5.00e- 1  -0.127    0.261  
15 ws_dnbr.mean                        -0.242     0.226    -1.07   2.86e- 1  -0.685    0.202  

> # Provide a glance summary of the model and print
> print(glance(ssn_mod))
# A tibble: 1 × 9
      n     p  npar value   AIC  AICc logLik deviance pseudo.r.squared
  <int> <dbl> <int> <dbl> <dbl> <dbl>  <dbl>    <dbl>            <dbl>
1   176    15     6  199.  211.  211.  -99.5     6.26            0.166

> # Perform Leave-One-Out Cross Validation and print
> print("Leave One Out Cross Validation")
[1] "Leave One Out Cross Validation"

> loocv_results <- loocv(ssn_mod)

> print(loocv_results)
# A tibble: 1 × 4
     bias   MSPE RMSPE   RAV
    <dbl>  <dbl> <dbl> <dbl>
1 -0.0419 0.0588 0.242 0.427

> # Stop redirecting output
> sink()

> # ----------------------------#
> # 5. Model Evaluation
> # ----------------------------#
> 
> # Extract residuals and fitted values from the model
 .... [TRUNCATED] 

> fitted_values <- fitted(ssn_mod)   

> # ----------------------------#
> # 6. Plotting and Saving Graphs
> # ----------------------------#
> 
> 
> # Create the graph save directory if sav .... [TRUNCATED] 

> # ----------------------------#
> # 7. Residuals vs Fitted Values Plot
> # ----------------------------#
> 
> # Purpose:
> #   - Linearity: Ensure t .... [TRUNCATED] 

> # Create the Residuals vs Fitted Values plot
> resid_fitted_plot <- ggplot(data.frame(Fitted = fitted_values, Residuals = residuals), aes(x = Fitted .... [TRUNCATED] 

> # Display the plot
> print(resid_fitted_plot)

> # Save the plot if saving is enabled
> if (save_graphs) {
+   ggsave(filename = file.path(graph_save_dir, "Residuals_vs_Fitted.png"), plot = resid_f .... [TRUNCATED] 
[1] "Saved Residuals vs Fitted Values plot."

> # ----------------------------#
> # 8. Q-Q Plot for Residuals
> # ----------------------------#
> 
> # Purpose:
> #   - Normality: Verify that resid .... [TRUNCATED] 

> # Enhanced Q-Q Plot using ggplot2
> qq_plot <- ggplot(data.frame(Residuals = residuals), aes(sample = Residuals)) +
+   stat_qq(color = "blue") +
+  .... [TRUNCATED] 

> # Display the ggplot2 Q-Q plot
> print(qq_plot)

> # Save the ggplot2 Q-Q plot if saving is enabled
> if (save_graphs) {
+   ggsave(filename = file.path(graph_save_dir, "QQ_Plot_Residuals_GGPlot2.png ..." ... [TRUNCATED] 
[1] "Saved ggplot2 Q-Q Plot of Residuals."

> # ----------------------------#
> # 9. Histogram of Residuals
> # ----------------------------#
> 
> # Purpose:
> #   - Normality
> #
> # What to Lo .... [TRUNCATED] 

> # Enhanced Histogram using ggplot2
> hist_plot <- ggplot(data.frame(Residuals = residuals), aes(x = Residuals)) +
+   geom_histogram(aes(y = ..densi .... [TRUNCATED] 

> # Display the ggplot2 histogram
> print(hist_plot)

> # Save the ggplot2 histogram if saving is enabled
> if (save_graphs) {
+   ggsave(filename = file.path(graph_save_dir, "Histogram_Residuals_GGPlot2. ..." ... [TRUNCATED] 
[1] "Saved ggplot2 Histogram of Residuals with Normal Curve."

> # Redirect output to the specified file and also print to console
> sink(output_file, append = TRUE, split = TRUE)

> print("")
[1] ""

> # ----------------------------#
> # 10. Statistical Tests
> # ----------------------------#
> 
> 
> # --------- Shapiro-Wilk Test for Normality ---- .... [TRUNCATED] 
[1] "-------- Shapiro-Wilk Test for Normality ---------"

> print("  - Normality: To check if the residuals are normally distributed.")
[1] "  - Normality: To check if the residuals are normally distributed."

> print("  - p-value > 0.05: Fail to reject null hypothesis (residuals are normally distributed).")
[1] "  - p-value > 0.05: Fail to reject null hypothesis (residuals are normally distributed)."

> print("  - p-value <= 0.05: Reject null hypothesis (residuals are not normally distributed).\n")
[1] "  - p-value <= 0.05: Reject null hypothesis (residuals are not normally distributed).\n"

> shapiro_test <- shapiro.test(residuals)

> print("Shapiro-Wilk Test Results:")
[1] "Shapiro-Wilk Test Results:"

> print(shapiro_test)

	Shapiro-Wilk normality test

data:  residuals
W = 0.99682, p-value = 0.9751


> # --------- Breusch-Pagan Test for Homoscedasticity ---------
> print("-------- Breusch-Pagan Test for Homoscedasticity ---------")
[1] "-------- Breusch-Pagan Test for Homoscedasticity ---------"

> print("  - Homoscedasticity: To check if residuals have constant variance across all levels of fitted values.")
[1] "  - Homoscedasticity: To check if residuals have constant variance across all levels of fitted values."

> print("  - p-value > 0.05: Fail to reject null hypothesis (homoscedasticity holds).")
[1] "  - p-value > 0.05: Fail to reject null hypothesis (homoscedasticity holds)."

> print("  - p-value <= 0.05: Reject null hypothesis (heteroscedasticity present).\n")
[1] "  - p-value <= 0.05: Reject null hypothesis (heteroscedasticity present).\n"

> # Extract the model frame from the ssn_lm model
> data_ssn <- model.frame(ssn_mod)

> # Perform Breusch-Pagan Test
> bp_test <- bptest(ssn_mod)

> print("Breusch-Pagan Test Results:")
[1] "Breusch-Pagan Test Results:"

> print(bp_test)

	studentized Breusch-Pagan test

data:  ssn_mod
BP = 18.3, df = 14, p-value = 0.1935


> # --------- Moran's I Test for Spatial Autocorrelation ---------
> print("\n-------- Moran's I Test for Spatial Autocorrelation ---------")
[1] "\n-------- Moran's I Test for Spatial Autocorrelation ---------"

> print("  - Spatial Autocorrelation: To determine if there is spatial autocorrelation in the residuals.")
[1] "  - Spatial Autocorrelation: To determine if there is spatial autocorrelation in the residuals."

> print("  - p-value > 0.05: Fail to reject null hypothesis (lack of spatial autocorrelation in residuals holds).")
[1] "  - p-value > 0.05: Fail to reject null hypothesis (lack of spatial autocorrelation in residuals holds)."

> print("  - p-value <= 0.05: Reject null hypothesis (spatial autocorrelation present).\n")
[1] "  - p-value <= 0.05: Reject null hypothesis (spatial autocorrelation present).\n"

> sink()

> # Extract spatial coordinates from the SSN object
> # Ensure that your SSN object has geometry information
> coords <- st_coordinates(ssn_get_data(s .... [TRUNCATED] 

> # Create a spatial weights matrix using k-nearest neighbors (k = 4 as an example)
> knn <- knearneigh(coords, k = 4)

> nb <- knn2nb(knn)

> lw <- nb2listw(nb, style = "W", zero.policy = TRUE)

> # Compute Moran's I
> moran_test <- moran.test(residuals, lw, zero.policy = TRUE)

> sink(output_file, append = TRUE, split = TRUE)

> print("Moran's I Test Results:")
[1] "Moran's I Test Results:"

> print(moran_test)

	Moran I test under randomisation

data:  residuals  
weights: lw    

Moran I statistic standard deviate = -2.9669, p-value = 0.9985
alternative hypothesis: greater
sample estimates:
Moran I statistic       Expectation          Variance 
     -0.160972433      -0.005714286       0.002738462 


> # Stop redirecting output
> sink()

> # --------------------------------------------------
> # End of Script
> # --------------------------------------------------
> 

> # --------------------------------------------------
> # Spatial Statistical Modeling with SSN2
> # ------------------------------------------------ .... [TRUNCATED] 

> # Specify the input and output directories
> input_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/Inputs"

> output_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/SSN ET/ET LM2 error thresh"

> model_name <- "glm ch_sfm.erosion.mean Zuur VIF-2"

> read_ssn <- FALSE # whether to create a new ssn (FALSE) or read the pre-existing ssn (TRUE)

> # Use file.path to create platform-independent file paths
> streams_path <- file.path(input_dir, "streams_100k.gpkg")

> obs_points_path <- file.path(input_dir, "Individual Watersheds", "LM2 ssn points.gpkg")

> ssn_path <- file.path(output_dir, "1_ET_Full_logtrans_independent_vars.ssn")

> output_file <- file.path(output_dir, model_name, "Results.txt")

> lsn_out <- file.path(output_dir, "0_lsn")

> # Define whether to save graphs and the directory to save them
> save_graphs <- TRUE  # Set to TRUE to save graphs as PNG

> graph_save_dir <- file.path(output_dir, model_name)  # Directory to save graphs

> # ----------------------------#
> # 1. Load Necessary Libraries
> # ----------------------------#
> 
> # Load required libraries
> library(SSN2)

> library(SSNbler)

> library(sf)

> library(dplyr)

> library(purrr)

> library(ggplot2)

> library(lmtest)

> library(spdep)

> library(classInt)   # Required for knearneigh

> library(broom)      # For tidy() and glance() functions

> library(grid)       # For grid.newpage()

> if (!dir.exists(graph_save_dir)) {
+   dir.create(graph_save_dir, recursive = TRUE)
+ }

> # ----------------------------#
> # 2. Read Spatial Data
> # ----------------------------#
> 
> # Read the streams dataset
> ET_streams <- st_read(s .... [TRUNCATED] 
Reading layer `streams_100k' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\streams_100k.gpkg' using driver `GPKG'
Simple feature collection with 643 features and 2 fields
Geometry type: LINESTRING
Dimension:     XY
Bounding box:  xmin: 404042.6 ymin: 4447904 xmax: 414579.6 ymax: 4466669
Projected CRS: NAD83 / UTM zone 13N

> # Read the observation points dataset
> ET_obs <- st_read(obs_points_path)
Reading layer `LM2 ssn points' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\Individual Watersheds\LM2 ssn points.gpkg' using driver `GPKG'
Simple feature collection with 98 features and 57 fields
Geometry type: POINT
Dimension:     XY
Bounding box:  xmin: 412352.5 ymin: 4449827 xmax: 413050.2 ymax: 4450417
Projected CRS: NAD83 / UTM zone 13N

> # Uncomment the following line if you encounter an error about Multilinestrings
> # ET_streams <- st_cast(ET_streams, "LINESTRING")
> 
> # --------- .... [TRUNCATED] 
[1] "Edge Attributes:"
[1] "rid"            "STRM_VAL"       "flow_accum_max" "Length"         "upDist"         "geometry"      
[1] "Site List Components:"
[1] "obs"
[1] "Updated Edge Attributes:"
[1] "rid"            "STRM_VAL"       "flow_accum_max" "Length"         "upDist"         "flow_accum_PI"  "afv_flow_accum" "geometry"      


SSN object is valid: TRUE

> # Create a distance matrix for spatial relationships
> # Purpose: Define spatial dependencies based on distances between sites
> ssn_create_distmat( .... [TRUNCATED] 

> # ----------------------------#
> # 4. Model Fitting and Output
> # ----------------------------#
> 
> # Redirect output to the specified file and a .... [TRUNCATED] 

> model_name
[1] "glm ch_sfm.erosion.mean Zuur VIF-2"

> model_formula
ch_sfm.erosion.mean ~ ws_mi60.max + ws_accum_precip.mean + ws_sbs.mean + 
    ws_bare.earth.mean + ws_RV.Clay + ws_Kw + ch_slope.median + 
    ch_curvature.median + ch_valley_width + ch_central.slope.difference + 
    ch_channel.width.over.valley.width + ch_stream.power.central.diff + 
    hs_eastness.median + hs_curvature.median + hs_bare.earth.mean + 
    hs_dnbr.median + hs_drainage_density

> ssn_mod <- ssn_glm(
+   formula = model_formula,
+   ssn.object = ET_ssn,
+   family = "Gamma",
+   tailup_type = "exponential",
+   taildown_type = .... [TRUNCATED] 

> # --------------------------------------------------
> # Spatial Statistical Modeling with SSN2
> # ------------------------------------------------ .... [TRUNCATED] 

> # Specify the input and output directories
> input_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/Inputs"

> output_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/SSN ET/ET LM2 error thresh"

> model_name <- "glm ch_sfm.erosion.mean Zuur VIF-2"

> read_ssn <- TRUE # whether to create a new ssn (FALSE) or read the pre-existing ssn (TRUE)

> # Use file.path to create platform-independent file paths
> streams_path <- file.path(input_dir, "streams_100k.gpkg")

> obs_points_path <- file.path(input_dir, "Individual Watersheds", "LM2 ssn points.gpkg")

> ssn_path <- file.path(output_dir, "1_ET_Full_logtrans_independent_vars.ssn")

> output_file <- file.path(output_dir, model_name, "Results.txt")

> lsn_out <- file.path(output_dir, "0_lsn")

> # Define whether to save graphs and the directory to save them
> save_graphs <- TRUE  # Set to TRUE to save graphs as PNG

> graph_save_dir <- file.path(output_dir, model_name)  # Directory to save graphs

> # ----------------------------#
> # 1. Load Necessary Libraries
> # ----------------------------#
> 
> # Load required libraries
> library(SSN2)

> library(SSNbler)

> library(sf)

> library(dplyr)

> library(purrr)

> library(ggplot2)

> library(lmtest)

> library(spdep)

> library(classInt)   # Required for knearneigh

> library(broom)      # For tidy() and glance() functions

> library(grid)       # For grid.newpage()

> if (!dir.exists(graph_save_dir)) {
+   dir.create(graph_save_dir, recursive = TRUE)
+ }

> # ----------------------------#
> # 2. Read Spatial Data
> # ----------------------------#
> 
> # Read the streams dataset
> ET_streams <- st_read(s .... [TRUNCATED] 
Reading layer `streams_100k' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\streams_100k.gpkg' using driver `GPKG'
Simple feature collection with 643 features and 2 fields
Geometry type: LINESTRING
Dimension:     XY
Bounding box:  xmin: 404042.6 ymin: 4447904 xmax: 414579.6 ymax: 4466669
Projected CRS: NAD83 / UTM zone 13N

> # Read the observation points dataset
> ET_obs <- st_read(obs_points_path)
Reading layer `LM2 ssn points' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\Individual Watersheds\LM2 ssn points.gpkg' using driver `GPKG'
Simple feature collection with 98 features and 57 fields
Geometry type: POINT
Dimension:     XY
Bounding box:  xmin: 412352.5 ymin: 4449827 xmax: 413050.2 ymax: 4450417
Projected CRS: NAD83 / UTM zone 13N

> # Uncomment the following line if you encounter an error about Multilinestrings
> # ET_streams <- st_cast(ET_streams, "LINESTRING")
> 
> # --------- .... [TRUNCATED] 

> # Create a distance matrix for spatial relationships
> # Purpose: Define spatial dependencies based on distances between sites
> ssn_create_distmat( .... [TRUNCATED] 

> # ----------------------------#
> # 4. Model Fitting and Output
> # ----------------------------#
> 
> # Redirect output to the specified file and a .... [TRUNCATED] 

> model_name
[1] "glm ch_sfm.erosion.mean Zuur VIF-2"

> model_formula
ch_sfm.erosion.mean ~ ws_mi60.max + ws_accum_precip.mean + ws_sbs.mean + 
    ws_bare.earth.mean + ws_RV.Clay + ws_Kw + ch_slope.median + 
    ch_curvature.median + ch_valley_width + ch_central.slope.difference + 
    ch_channel.width.over.valley.width + ch_stream.power.central.diff + 
    hs_eastness.median + hs_curvature.median + hs_bare.earth.mean + 
    hs_dnbr.median + hs_drainage_density

> ssn_mod <- ssn_glm(
+   formula = model_formula,
+   ssn.object = ET_ssn,
+   family = "Gamma",
+   tailup_type = "exponential",
+   taildown_type = .... [TRUNCATED] 

> # --------------------------------------------------
> # Spatial Statistical Modeling with SSN2
> # ------------------------------------------------ .... [TRUNCATED] 

> # Specify the input and output directories
> input_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/Inputs"

> output_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/SSN ET/ET LM2 error thresh"

> model_name <- "glm ch_sfm.erosion.mean Zuur VIF-2"

> read_ssn <- TRUE # whether to create a new ssn (FALSE) or read the pre-existing ssn (TRUE)

> # Use file.path to create platform-independent file paths
> streams_path <- file.path(input_dir, "streams_100k.gpkg")

> obs_points_path <- file.path(input_dir, "Individual Watersheds", "LM2 ssn points.gpkg")

> ssn_path <- file.path(output_dir, "1_ET_Full_logtrans_independent_vars.ssn")

> output_file <- file.path(output_dir, model_name, "Results.txt")

> lsn_out <- file.path(output_dir, "0_lsn")

> # Define whether to save graphs and the directory to save them
> save_graphs <- TRUE  # Set to TRUE to save graphs as PNG

> graph_save_dir <- file.path(output_dir, model_name)  # Directory to save graphs

> # ----------------------------#
> # 1. Load Necessary Libraries
> # ----------------------------#
> 
> # Load required libraries
> library(SSN2)

> library(SSNbler)

> library(sf)

> library(dplyr)

> library(purrr)

> library(ggplot2)

> library(lmtest)

> library(spdep)

> library(classInt)   # Required for knearneigh

> library(broom)      # For tidy() and glance() functions

> library(grid)       # For grid.newpage()

> if (!dir.exists(graph_save_dir)) {
+   dir.create(graph_save_dir, recursive = TRUE)
+ }

> # ----------------------------#
> # 2. Read Spatial Data
> # ----------------------------#
> 
> # Read the streams dataset
> ET_streams <- st_read(s .... [TRUNCATED] 
Reading layer `streams_100k' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\streams_100k.gpkg' using driver `GPKG'
Simple feature collection with 643 features and 2 fields
Geometry type: LINESTRING
Dimension:     XY
Bounding box:  xmin: 404042.6 ymin: 4447904 xmax: 414579.6 ymax: 4466669
Projected CRS: NAD83 / UTM zone 13N

> # Read the observation points dataset
> ET_obs <- st_read(obs_points_path)
Reading layer `LM2 ssn points' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\Individual Watersheds\LM2 ssn points.gpkg' using driver `GPKG'
Simple feature collection with 98 features and 57 fields
Geometry type: POINT
Dimension:     XY
Bounding box:  xmin: 412352.5 ymin: 4449827 xmax: 413050.2 ymax: 4450417
Projected CRS: NAD83 / UTM zone 13N

> # Uncomment the following line if you encounter an error about Multilinestrings
> # ET_streams <- st_cast(ET_streams, "LINESTRING")
> 
> # --------- .... [TRUNCATED] 

> # Create a distance matrix for spatial relationships
> # Purpose: Define spatial dependencies based on distances between sites
> ssn_create_distmat( .... [TRUNCATED] 

> #-----------------------------------#
> #3.5 Test Correlations
> # ---------------------------------- #
> 
> # ------------------------------------- .... [TRUNCATED] 
package ‘listenv’ successfully unpacked and MD5 sums checked
package ‘parallelly’ successfully unpacked and MD5 sums checked
package ‘future’ successfully unpacked and MD5 sums checked
package ‘globals’ successfully unpacked and MD5 sums checked
package ‘shape’ successfully unpacked and MD5 sums checked
package ‘future.apply’ successfully unpacked and MD5 sums checked
package ‘numDeriv’ successfully unpacked and MD5 sums checked
package ‘progressr’ successfully unpacked and MD5 sums checked
package ‘SQUAREM’ successfully unpacked and MD5 sums checked
package ‘diagram’ successfully unpacked and MD5 sums checked
package ‘lava’ successfully unpacked and MD5 sums checked
package ‘tzdb’ successfully unpacked and MD5 sums checked
package ‘prodlim’ successfully unpacked and MD5 sums checked
package ‘timechange’ successfully unpacked and MD5 sums checked
package ‘iterators’ successfully unpacked and MD5 sums checked
package ‘data.table’ successfully unpacked and MD5 sums checked
package ‘clock’ successfully unpacked and MD5 sums checked
package ‘gower’ successfully unpacked and MD5 sums checked
package ‘hardhat’ successfully unpacked and MD5 sums checked
package ‘ipred’ successfully unpacked and MD5 sums checked
package ‘lubridate’ successfully unpacked and MD5 sums checked
package ‘timeDate’ successfully unpacked and MD5 sums checked
package ‘foreach’ successfully unpacked and MD5 sums checked
package ‘ModelMetrics’ successfully unpacked and MD5 sums checked
package ‘plyr’ successfully unpacked and MD5 sums checked
package ‘pROC’ successfully unpacked and MD5 sums checked
package ‘recipes’ successfully unpacked and MD5 sums checked
package ‘reshape2’ successfully unpacked and MD5 sums checked
package ‘caret’ successfully unpacked and MD5 sums checked

The downloaded binary packages are in
	C:\Users\alextd\AppData\Local\Temp\7\RtmpCK4Dna\downloaded_packages

> if (!requireNamespace("corrplot", quietly = TRUE)) {
+   install.packages("corrplot")
+ }
package ‘corrplot’ successfully unpacked and MD5 sums checked

The downloaded binary packages are in
	C:\Users\alextd\AppData\Local\Temp\7\RtmpCK4Dna\downloaded_packages

> library(caret)

> library(corrplot)

> # ----------------------------#
> # B. Extract Explanatory Variables
> # ----------------------------#
> 
> # Assuming 'ET_obs' contains your explan .... [TRUNCATED] 

> # ----------------------------#
> # C. Compute Correlation Matrix
> # ----------------------------#
> 
> # Calculate the correlation matrix using pa .... [TRUNCATED] 

> # ----------------------------#
> # D. Identify Highly Correlated Pairs
> # ----------------------------#
> 
> # Define a correlation threshold
> co .... [TRUNCATED] 

> # Find pairs with absolute correlation above the threshold (excluding self-correlations)
> high_cor_pairs <- which(abs(cor_matrix) > cor_threshold & .... [TRUNCATED] 

> # Remove duplicate pairs (e.g., if (A,B) is identified, remove (B,A))
> high_cor_pairs <- high_cor_pairs[high_cor_pairs[,1] < high_cor_pairs[,2], ]

> # Check if any highly correlated pairs are found
> if(nrow(high_cor_pairs) > 0){
+   cat("Highly Correlated Variable Pairs (|correlation| >", cor_th .... [TRUNCATED] 
No pairs of variables with |correlation| > 0.8  were found.

> # ----------------------------#
> # E. Visualize the Correlation Matrix (Optional)
> # ----------------------------#
> 
> # Plot the correlation mat .... [TRUNCATED] 

> # ----------------------------#
> # F. Calculate Variance Inflation Factor (VIF)
> # ----------------------------#
> 
> # Fit a linear model to comp .... [TRUNCATED] 

> # --------------------------------------------------
> # Spatial Statistical Modeling with SSN2
> # ------------------------------------------------ .... [TRUNCATED] 

> # Specify the input and output directories
> input_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/Inputs"

> output_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/SSN ET/ET LM2 error thresh"

> model_name <- "glm ch_sfm.erosion.mean Zuur VIF-2"

> read_ssn <- TRUE # whether to create a new ssn (FALSE) or read the pre-existing ssn (TRUE)

> # Use file.path to create platform-independent file paths
> streams_path <- file.path(input_dir, "streams_100k.gpkg")

> obs_points_path <- file.path(input_dir, "Individual Watersheds", "LM2 ssn points.gpkg")

> ssn_path <- file.path(output_dir, "1_ET_Full_logtrans_independent_vars.ssn")

> output_file <- file.path(output_dir, model_name, "Results.txt")

> lsn_out <- file.path(output_dir, "0_lsn")

> # Define whether to save graphs and the directory to save them
> save_graphs <- TRUE  # Set to TRUE to save graphs as PNG

> graph_save_dir <- file.path(output_dir, model_name)  # Directory to save graphs

> # ----------------------------#
> # 1. Load Necessary Libraries
> # ----------------------------#
> 
> # Load required libraries
> library(SSN2)

> library(SSNbler)

> library(sf)

> library(dplyr)

> library(purrr)

> library(ggplot2)

> library(lmtest)

> library(spdep)

> library(classInt)   # Required for knearneigh

> library(broom)      # For tidy() and glance() functions

> library(grid)       # For grid.newpage()

> if (!dir.exists(graph_save_dir)) {
+   dir.create(graph_save_dir, recursive = TRUE)
+ }

> # ----------------------------#
> # 2. Read Spatial Data
> # ----------------------------#
> 
> # Read the streams dataset
> ET_streams <- st_read(s .... [TRUNCATED] 
Reading layer `streams_100k' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\streams_100k.gpkg' using driver `GPKG'
Simple feature collection with 643 features and 2 fields
Geometry type: LINESTRING
Dimension:     XY
Bounding box:  xmin: 404042.6 ymin: 4447904 xmax: 414579.6 ymax: 4466669
Projected CRS: NAD83 / UTM zone 13N

> # Read the observation points dataset
> ET_obs <- st_read(obs_points_path)
Reading layer `LM2 ssn points' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\Individual Watersheds\LM2 ssn points.gpkg' using driver `GPKG'
Simple feature collection with 98 features and 57 fields
Geometry type: POINT
Dimension:     XY
Bounding box:  xmin: 412352.5 ymin: 4449827 xmax: 413050.2 ymax: 4450417
Projected CRS: NAD83 / UTM zone 13N

> # Uncomment the following line if you encounter an error about Multilinestrings
> # ET_streams <- st_cast(ET_streams, "LINESTRING")
> 
> # --------- .... [TRUNCATED] 

> # Create a distance matrix for spatial relationships
> # Purpose: Define spatial dependencies based on distances between sites
> ssn_create_distmat( .... [TRUNCATED] 

> #-----------------------------------#
> #3.5 Test Correlations
> # ---------------------------------- #
> 
> # ------------------------------------- .... [TRUNCATED] 

> if (!requireNamespace("corrplot", quietly = TRUE)) {
+   install.packages("corrplot")
+ }

> library(caret)

> library(corrplot)

> # ----------------------------#
> # B. Extract Explanatory Variables
> # ----------------------------#
> 
> # Assuming 'ET_obs' contains your explan .... [TRUNCATED] 

> # ----------------------------#
> # C. Compute Correlation Matrix
> # ----------------------------#
> 
> # Calculate the correlation matrix using pa .... [TRUNCATED] 

> # ----------------------------#
> # D. Identify Highly Correlated Pairs
> # ----------------------------#
> 
> # Define a correlation threshold
> co .... [TRUNCATED] 

> # Find pairs with absolute correlation above the threshold (excluding self-correlations)
> high_cor_pairs <- which(abs(cor_matrix) > cor_threshold & .... [TRUNCATED] 

> # Remove duplicate pairs (e.g., if (A,B) is identified, remove (B,A))
> high_cor_pairs <- high_cor_pairs[high_cor_pairs[,1] < high_cor_pairs[,2], ]

> # Check if any highly correlated pairs are found
> if(nrow(high_cor_pairs) > 0){
+   cat("Highly Correlated Variable Pairs (|correlation| >", cor_th .... [TRUNCATED] 
No pairs of variables with |correlation| > 0.8  were found.

> # ----------------------------#
> # E. Visualize the Correlation Matrix (Optional)
> # ----------------------------#
> 
> # Plot the correlation mat .... [TRUNCATED] 

> # ----------------------------#
> # F. Calculate Variance Inflation Factor (VIF)
> # ----------------------------#
> 
> # Fit a linear model to comp .... [TRUNCATED] 

> # --------------------------------------------------
> # Spatial Statistical Modeling with SSN2
> # ------------------------------------------------ .... [TRUNCATED] 

> # Specify the input and output directories
> input_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/Inputs"

> output_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/SSN ET/ET LM2 error thresh"

> model_name <- "glm ch_sfm.erosion.mean Zuur VIF-2"

> read_ssn <- TRUE # whether to create a new ssn (FALSE) or read the pre-existing ssn (TRUE)

> # Use file.path to create platform-independent file paths
> streams_path <- file.path(input_dir, "streams_100k.gpkg")

> obs_points_path <- file.path(input_dir, "Individual Watersheds", "LM2 ssn points.gpkg")

> ssn_path <- file.path(output_dir, "1_ET_Full_logtrans_independent_vars.ssn")

> output_file <- file.path(output_dir, model_name, "Results.txt")

> lsn_out <- file.path(output_dir, "0_lsn")

> # Define whether to save graphs and the directory to save them
> save_graphs <- TRUE  # Set to TRUE to save graphs as PNG

> graph_save_dir <- file.path(output_dir, model_name)  # Directory to save graphs

> # ----------------------------#
> # 1. Load Necessary Libraries
> # ----------------------------#
> 
> # Load required libraries
> library(SSN2)

> library(SSNbler)

> library(sf)

> library(dplyr)

> library(purrr)

> library(ggplot2)

> library(lmtest)

> library(spdep)

> library(classInt)   # Required for knearneigh

> library(broom)      # For tidy() and glance() functions

> library(grid)       # For grid.newpage()

> if (!dir.exists(graph_save_dir)) {
+   dir.create(graph_save_dir, recursive = TRUE)
+ }

> # ----------------------------#
> # 2. Read Spatial Data
> # ----------------------------#
> 
> # Read the streams dataset
> ET_streams <- st_read(s .... [TRUNCATED] 
Reading layer `streams_100k' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\streams_100k.gpkg' using driver `GPKG'
Simple feature collection with 643 features and 2 fields
Geometry type: LINESTRING
Dimension:     XY
Bounding box:  xmin: 404042.6 ymin: 4447904 xmax: 414579.6 ymax: 4466669
Projected CRS: NAD83 / UTM zone 13N

> # Read the observation points dataset
> ET_obs <- st_read(obs_points_path)
Reading layer `LM2 ssn points' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\Individual Watersheds\LM2 ssn points.gpkg' using driver `GPKG'
Simple feature collection with 98 features and 57 fields
Geometry type: POINT
Dimension:     XY
Bounding box:  xmin: 412352.5 ymin: 4449827 xmax: 413050.2 ymax: 4450417
Projected CRS: NAD83 / UTM zone 13N

> # Uncomment the following line if you encounter an error about Multilinestrings
> # ET_streams <- st_cast(ET_streams, "LINESTRING")
> 
> # --------- .... [TRUNCATED] 

> # Create a distance matrix for spatial relationships
> # Purpose: Define spatial dependencies based on distances between sites
> ssn_create_distmat( .... [TRUNCATED] 

> # ----------------------------#
> # 3.5 Test Correlations
> # ----------------------------#
> 
> # A. Load Additional Necessary Libraries
> if (!req .... [TRUNCATED] 

> if (!requireNamespace("corrplot", quietly = TRUE)) {
+   install.packages("corrplot")
+ }

> library(caret)

> library(corrplot)

> library(car)  # For VIF

> # --------------------------------------------------
> # Spatial Statistical Modeling with SSN2
> # ------------------------------------------------ .... [TRUNCATED] 

> # Specify the input and output directories
> input_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/Inputs"

> output_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/SSN ET/ET LM2 error thresh"

> model_name <- "glm ch_sfm.erosion.mean Zuur VIF-2"

> read_ssn <- TRUE # whether to create a new ssn (FALSE) or read the pre-existing ssn (TRUE)

> # Use file.path to create platform-independent file paths
> streams_path <- file.path(input_dir, "streams_100k.gpkg")

> obs_points_path <- file.path(input_dir, "Individual Watersheds", "LM2 ssn points.gpkg")

> ssn_path <- file.path(output_dir, "1_ET_Full_logtrans_independent_vars.ssn")

> output_file <- file.path(output_dir, model_name, "Results.txt")

> lsn_out <- file.path(output_dir, "0_lsn")

> # Define whether to save graphs and the directory to save them
> save_graphs <- TRUE  # Set to TRUE to save graphs as PNG

> graph_save_dir <- file.path(output_dir, model_name)  # Directory to save graphs

> # ----------------------------#
> # 1. Load Necessary Libraries
> # ----------------------------#
> 
> # Load required libraries
> library(SSN2)

> library(SSNbler)

> library(sf)

> library(dplyr)

> library(purrr)

> library(ggplot2)

> library(lmtest)

> library(spdep)

> library(classInt)   # Required for knearneigh

> library(broom)      # For tidy() and glance() functions

> library(grid)       # For grid.newpage()

> if (!dir.exists(graph_save_dir)) {
+   dir.create(graph_save_dir, recursive = TRUE)
+ }

> # ----------------------------#
> # 2. Read Spatial Data
> # ----------------------------#
> 
> # Read the streams dataset
> ET_streams <- st_read(s .... [TRUNCATED] 
Reading layer `streams_100k' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\streams_100k.gpkg' using driver `GPKG'
Simple feature collection with 643 features and 2 fields
Geometry type: LINESTRING
Dimension:     XY
Bounding box:  xmin: 404042.6 ymin: 4447904 xmax: 414579.6 ymax: 4466669
Projected CRS: NAD83 / UTM zone 13N

> # Read the observation points dataset
> ET_obs <- st_read(obs_points_path)
Reading layer `LM2 ssn points' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\Individual Watersheds\LM2 ssn points.gpkg' using driver `GPKG'
Simple feature collection with 98 features and 57 fields
Geometry type: POINT
Dimension:     XY
Bounding box:  xmin: 412352.5 ymin: 4449827 xmax: 413050.2 ymax: 4450417
Projected CRS: NAD83 / UTM zone 13N

> # Uncomment the following line if you encounter an error about Multilinestrings
> # ET_streams <- st_cast(ET_streams, "LINESTRING")
> 
> # --------- .... [TRUNCATED] 

> # Create a distance matrix for spatial relationships
> # Purpose: Define spatial dependencies based on distances between sites
> ssn_create_distmat( .... [TRUNCATED] 

> # ----------------------------#
> # 3.5 Test Correlations
> # ----------------------------#
> 
> # A. Load Additional Necessary Libraries
> if (!req .... [TRUNCATED] 

> if (!requireNamespace("corrplot", quietly = TRUE)) {
+   install.packages("corrplot")
+ }

> # Install the 'car' package
> install.packages("car")
package ‘cowplot’ successfully unpacked and MD5 sums checked
package ‘Deriv’ successfully unpacked and MD5 sums checked
package ‘modelr’ successfully unpacked and MD5 sums checked
package ‘microbenchmark’ successfully unpacked and MD5 sums checked
package ‘doBy’ successfully unpacked and MD5 sums checked
package ‘SparseM’ successfully unpacked and MD5 sums checked
package ‘MatrixModels’ successfully unpacked and MD5 sums checked
package ‘minqa’ successfully unpacked and MD5 sums checked
package ‘nloptr’ successfully unpacked and MD5 sums checked
package ‘RcppEigen’ successfully unpacked and MD5 sums checked
package ‘carData’ successfully unpacked and MD5 sums checked
package ‘abind’ successfully unpacked and MD5 sums checked
package ‘Formula’ successfully unpacked and MD5 sums checked
package ‘pbkrtest’ successfully unpacked and MD5 sums checked
package ‘quantreg’ successfully unpacked and MD5 sums checked
package ‘lme4’ successfully unpacked and MD5 sums checked
package ‘car’ successfully unpacked and MD5 sums checked

The downloaded binary packages are in
	C:\Users\alextd\AppData\Local\Temp\7\RtmpCK4Dna\downloaded_packages

> # Load the 'car' package
> library(caret)

> library(corrplot)

> library(car)  # For VIF

> # B. Extract Explanatory Variables
> explanatory_vars <- ET_obs %>%
+   st_drop_geometry() %>%
+   select(
+     ws_mi60.max,
+     ws_accum_precip. .... [TRUNCATED] 

> # C. Compute Correlation Matrix
> cor_matrix <- cor(explanatory_vars, use = "pairwise.complete.obs")

> # D. Identify Highly Correlated Pairs
> cor_threshold <- 0.8

> high_cor_pairs <- which(abs(cor_matrix) > cor_threshold & abs(cor_matrix) < 1, arr.ind = TRUE)

> high_cor_pairs <- high_cor_pairs[high_cor_pairs[,1] < high_cor_pairs[,2], ]

> if(nrow(high_cor_pairs) > 0){
+   cat("Highly Correlated Variable Pairs (|correlation| >", cor_threshold, "):\n")
+   for(i in 1:nrow(high_cor_pairs .... [TRUNCATED] 
No pairs of variables with |correlation| > 0.8  were found.

> # E. Visualize the Correlation Matrix (Optional)
> corrplot(cor_matrix, method = "color", type = "upper", 
+          tl.col = "black", tl.srt = 45, .... [TRUNCATED] 

> # A. Detect Zero Variance Variables
> variable_variances <- sapply(explanatory_vars, var, na.rm = TRUE)

> zero_var_vars <- names(variable_variances[variable_variances == 0])

> if(length(zero_var_vars) > 0){
+   cat("Variables with Zero Variance:\n")
+   print(zero_var_vars)
+ } else {
+   cat("No variables with zero varian ..." ... [TRUNCATED] 
Variables with Zero Variance:
[1] "ws_mi60.max"          "ws_accum_precip.mean"

> # B. Remove Zero Variance Variables
> explanatory_vars_clean <- explanatory_vars %>%
+   select(-all_of(zero_var_vars))

> if(length(zero_var_vars) > 0){
+   cat("\nRemoved zero variance variables from the dataset.\n")
+ } else {
+   cat("\nNo variables were removed.\n") .... [TRUNCATED] 

Removed zero variance variables from the dataset.

> # Recompute Correlation Matrix
> cor_matrix_clean <- cor(explanatory_vars_clean, use = "pairwise.complete.obs")

> # Reidentify Highly Correlated Pairs
> high_cor_pairs_clean <- which(abs(cor_matrix_clean) > cor_threshold & abs(cor_matrix_clean) < 1, arr.ind = TR .... [TRUNCATED] 

> high_cor_pairs_clean <- high_cor_pairs_clean[high_cor_pairs_clean[,1] < high_cor_pairs_clean[,2], ]

> if(nrow(high_cor_pairs_clean) > 0){
+   cat("Highly Correlated Variable Pairs after Cleaning (|correlation| >", cor_threshold, "):\n")
+   for(i in  .... [TRUNCATED] 
No pairs of variables with |correlation| > 0.8  were found after cleaning.

> # Recompute VIF
> model_data <- ET_obs %>%
+   st_drop_geometry() %>%
+   select(ch_sfm.erosion.mean, all_of(names(explanatory_vars_clean)))

> model_data <- na.omit(model_data)

> vif_model <- lm(ch_sfm.erosion.mean ~ ., data = model_data)

> vif_values <- vif(vif_model)

> cat("\nVariance Inflation Factor (VIF) for Each Predictor:\n")

Variance Inflation Factor (VIF) for Each Predictor:

> print(vif_values)
                       ws_sbs.mean                 ws_bare.earth.mean                         ws_RV.Clay                              ws_Kw                    ch_slope.median 
                          2.354553                           2.549648                           2.895209                           1.862709                           2.024705 
               ch_curvature.median                    ch_valley_width        ch_central.slope.difference ch_channel.width.over.valley.width       ch_stream.power.central.diff 
                          2.318321                           1.690388                           1.654013                           2.176786                           1.695909 
                hs_eastness.median                hs_curvature.median                 hs_bare.earth.mean                     hs_dnbr.median                hs_drainage_density 
                          1.563262                           1.245337                           2.915751                           2.408376                           1.442023 

> vif_threshold <- 5

> high_vif <- vif_values[vif_values > vif_threshold]

> if(length(high_vif) > 0){
+   cat("\nVariables with VIF >", vif_threshold, "indicating multicollinearity:\n")
+   print(high_vif)
+   
+   # Remove  .... [TRUNCATED] 

No variables with VIF > 5 were found.

> # ----------------------------#
> # 4. Model Fitting and Output
> # ----------------------------#
> 
> # Redirect output to the specified file and a .... [TRUNCATED] 

> model_name
[1] "glm ch_sfm.erosion.mean Zuur VIF-2"

> model_formula
ch_sfm.erosion.mean ~ ws_mi60.max + ws_accum_precip.mean + ws_sbs.mean + 
    ws_bare.earth.mean + ws_RV.Clay + ws_Kw + ch_slope.median + 
    ch_curvature.median + ch_valley_width + ch_central.slope.difference + 
    ch_channel.width.over.valley.width + ch_stream.power.central.diff + 
    hs_eastness.median + hs_curvature.median + hs_bare.earth.mean + 
    hs_dnbr.median + hs_drainage_density

> ssn_mod <- ssn_glm(
+   formula = model_formula,
+   ssn.object = ET_ssn,
+   family = "Gamma",
+   tailup_type = "exponential",
+   taildown_type = .... [TRUNCATED] 

> # --------------------------------------------------
> # Spatial Statistical Modeling with SSN2
> # ------------------------------------------------ .... [TRUNCATED] 

> # Specify the input and output directories
> input_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/Inputs"

> output_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/SSN ET/ET LM2 error thresh"

> model_name <- "glm ch_sfm.erosion.mean Zuur VIF-2"

> read_ssn <- TRUE # whether to create a new ssn (FALSE) or read the pre-existing ssn (TRUE)

> # Use file.path to create platform-independent file paths
> streams_path <- file.path(input_dir, "streams_100k.gpkg")

> obs_points_path <- file.path(input_dir, "Individual Watersheds", "LM2 ssn points.gpkg")

> ssn_path <- file.path(output_dir, "1_ET_Full_logtrans_independent_vars.ssn")

> output_file <- file.path(output_dir, model_name, "Results.txt")

> lsn_out <- file.path(output_dir, "0_lsn")

> # Define whether to save graphs and the directory to save them
> save_graphs <- TRUE  # Set to TRUE to save graphs as PNG

> graph_save_dir <- file.path(output_dir, model_name)  # Directory to save graphs

> # ----------------------------#
> # 1. Load Necessary Libraries
> # ----------------------------#
> 
> # Load required libraries
> library(SSN2)

> library(SSNbler)

> library(sf)

> library(dplyr)

> library(purrr)

> library(ggplot2)

> library(lmtest)

> library(spdep)

> library(classInt)   # Required for knearneigh

> library(broom)      # For tidy() and glance() functions

> library(grid)       # For grid.newpage()

> if (!dir.exists(graph_save_dir)) {
+   dir.create(graph_save_dir, recursive = TRUE)
+ }

> # ----------------------------#
> # 2. Read Spatial Data
> # ----------------------------#
> 
> # Read the streams dataset
> ET_streams <- st_read(s .... [TRUNCATED] 
Reading layer `streams_100k' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\streams_100k.gpkg' using driver `GPKG'
Simple feature collection with 643 features and 2 fields
Geometry type: LINESTRING
Dimension:     XY
Bounding box:  xmin: 404042.6 ymin: 4447904 xmax: 414579.6 ymax: 4466669
Projected CRS: NAD83 / UTM zone 13N

> # Read the observation points dataset
> ET_obs <- st_read(obs_points_path)
Reading layer `LM2 ssn points' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\Individual Watersheds\LM2 ssn points.gpkg' using driver `GPKG'
Simple feature collection with 98 features and 57 fields
Geometry type: POINT
Dimension:     XY
Bounding box:  xmin: 412352.5 ymin: 4449827 xmax: 413050.2 ymax: 4450417
Projected CRS: NAD83 / UTM zone 13N

> # Uncomment the following line if you encounter an error about Multilinestrings
> # ET_streams <- st_cast(ET_streams, "LINESTRING")
> 
> # --------- .... [TRUNCATED] 

> # Create a distance matrix for spatial relationships
> # Purpose: Define spatial dependencies based on distances between sites
> ssn_create_distmat( .... [TRUNCATED] 

> # ----------------------------#
> # 4. Model Fitting and Output
> # ----------------------------#
> 
> # Redirect output to the specified file and a .... [TRUNCATED] 

> model_name
[1] "glm ch_sfm.erosion.mean Zuur VIF-2"

> model_formula
ch_sfm.erosion.mean ~ ch_slope.median + ch_curvature.median + 
    ch_valley_width + ch_central.slope.difference + ch_channel.width.over.valley.width + 
    ch_stream.power.central.diff + hs_eastness.median + hs_curvature.median + 
    hs_bare.earth.mean + hs_ndvi.range + hs_dnbr.median + hs_drainage_density

> ssn_mod <- ssn_glm(
+   formula = model_formula,
+   ssn.object = ET_ssn,
+   family = "Gamma",
+   tailup_type = "exponential",
+   taildown_type = .... [TRUNCATED] 

> # Print the summary of the model to the file and console
> print(summary(ssn_mod))

Call:
ssn_glm(formula = model_formula, ssn.object = ET_ssn, family = "Gamma", 
    tailup_type = "exponential", taildown_type = "none", euclid_type = "gaussian", 
    additive = "afv_flow_accum")

Deviance Residuals:
     Min       1Q   Median       3Q      Max 
-0.72622 -0.19081 -0.01588  0.15076  0.50516 

Coefficients (fixed):
                                    Estimate Std. Error z value Pr(>|z|)    
(Intercept)                         -1.52659    0.16853  -9.058  < 2e-16 ***
ch_slope.median                     -0.08729    0.18754  -0.465  0.64160    
ch_curvature.median                 -0.01353    0.10053  -0.135  0.89290    
ch_valley_width                     -0.12441    0.07374  -1.687  0.09159 .  
ch_central.slope.difference         -0.03783    0.06236  -0.607  0.54415    
ch_channel.width.over.valley.width  -0.02217    0.11037  -0.201  0.84077    
ch_stream.power.central.diff         0.15606    0.05910   2.641  0.00827 ** 
hs_eastness.median                  -0.23917    0.12037  -1.987  0.04692 *  
hs_curvature.median                 -0.05840    0.07338  -0.796  0.42611    
hs_bare.earth.mean                  -0.26103    0.14292  -1.826  0.06780 .  
hs_ndvi.range                       -0.45291    0.16942  -2.673  0.00751 ** 
hs_dnbr.median                       0.07096    0.13123   0.541  0.58871    
hs_drainage_density                -43.82702   36.05919  -1.215  0.22421    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Pseudo R-squared: 0.159

Coefficients (covariance):
              Effect     Parameter   Estimate
  tailup exponential  de (parsill)  1.250e-02
  tailup exponential         range  2.214e+03
     euclid gaussian  de (parsill)  9.897e-02
     euclid gaussian         range  7.562e+01
              nugget        nugget  1.439e-01
          dispersion    dispersion  6.733e+00


> # Print variance components of the model
> varcomp(ssn_mod)
# A tibble: 5 × 2
  varcomp            proportion
  <chr>                   <dbl>
1 Covariates (PR-sq)     0.159 
2 tailup_de              0.0411
3 taildown_de            0     
4 euclid_de              0.326 
5 nugget                 0.474 

> # Tidy the model output with confidence intervals and print
> print(tidy(ssn_mod, conf.int = TRUE))  
# A tibble: 13 × 7
   term                               estimate std.error statistic p.value  conf.low conf.high
   <chr>                                 <dbl>     <dbl>     <dbl>   <dbl>     <dbl>     <dbl>
 1 (Intercept)                         -1.53      0.169     -9.06  0         -1.86    -1.20   
 2 ch_central.slope.difference         -0.0378    0.0624    -0.607 0.544     -0.160    0.0844 
 3 ch_channel.width.over.valley.width  -0.0222    0.110     -0.201 0.841     -0.238    0.194  
 4 ch_curvature.median                 -0.0135    0.101     -0.135 0.893     -0.211    0.183  
 5 ch_slope.median                     -0.0873    0.188     -0.465 0.642     -0.455    0.280  
 6 ch_stream.power.central.diff         0.156     0.0591     2.64  0.00827    0.0402   0.272  
 7 ch_valley_width                     -0.124     0.0737    -1.69  0.0916    -0.269    0.0201 
 8 hs_bare.earth.mean                  -0.261     0.143     -1.83  0.0678    -0.541    0.0191 
 9 hs_curvature.median                 -0.0584    0.0734    -0.796 0.426     -0.202    0.0854 
10 hs_dnbr.median                       0.0710    0.131      0.541 0.589     -0.186    0.328  
11 hs_drainage_density                -43.8      36.1       -1.22  0.224   -115.      26.8    
12 hs_eastness.median                  -0.239     0.120     -1.99  0.0469    -0.475   -0.00326
13 hs_ndvi.range                       -0.453     0.169     -2.67  0.00751   -0.785   -0.121  

> # Provide a glance summary of the model and print
> print(glance(ssn_mod))
# A tibble: 1 × 9
      n     p  npar value   AIC  AICc logLik deviance pseudo.r.squared
  <int> <dbl> <int> <dbl> <dbl> <dbl>  <dbl>    <dbl>            <dbl>
1    98    13     6  46.7  58.7  59.6  -23.3     6.14            0.159

> # Perform Leave-One-Out Cross Validation and print
> print("Leave One Out Cross Validation")
[1] "Leave One Out Cross Validation"

> loocv_results <- loocv(ssn_mod)

> print(loocv_results)
# A tibble: 1 × 4
     bias   MSPE RMSPE   RAV
    <dbl>  <dbl> <dbl> <dbl>
1 -0.0346 0.0421 0.205 0.466

> # Stop redirecting output
> sink()

> # ----------------------------#
> # 5. Model Evaluation
> # ----------------------------#
> 
> # Extract residuals and fitted values from the model
 .... [TRUNCATED] 

> fitted_values <- fitted(ssn_mod)   

> # ----------------------------#
> # 6. Plotting and Saving Graphs
> # ----------------------------#
> 
> 
> # Create the graph save directory if sav .... [TRUNCATED] 

> # ----------------------------#
> # 7. Residuals vs Fitted Values Plot
> # ----------------------------#
> 
> # Purpose:
> #   - Linearity: Ensure t .... [TRUNCATED] 

> # Create the Residuals vs Fitted Values plot
> resid_fitted_plot <- ggplot(data.frame(Fitted = fitted_values, Residuals = residuals), aes(x = Fitted .... [TRUNCATED] 

> # Display the plot
> print(resid_fitted_plot)

> # Save the plot if saving is enabled
> if (save_graphs) {
+   ggsave(filename = file.path(graph_save_dir, "Residuals_vs_Fitted.png"), plot = resid_f .... [TRUNCATED] 
[1] "Saved Residuals vs Fitted Values plot."

> # ----------------------------#
> # 8. Q-Q Plot for Residuals
> # ----------------------------#
> 
> # Purpose:
> #   - Normality: Verify that resid .... [TRUNCATED] 

> # Enhanced Q-Q Plot using ggplot2
> qq_plot <- ggplot(data.frame(Residuals = residuals), aes(sample = Residuals)) +
+   stat_qq(color = "blue") +
+  .... [TRUNCATED] 

> # Display the ggplot2 Q-Q plot
> print(qq_plot)

> # Save the ggplot2 Q-Q plot if saving is enabled
> if (save_graphs) {
+   ggsave(filename = file.path(graph_save_dir, "QQ_Plot_Residuals_GGPlot2.png ..." ... [TRUNCATED] 
[1] "Saved ggplot2 Q-Q Plot of Residuals."

> # ----------------------------#
> # 9. Histogram of Residuals
> # ----------------------------#
> 
> # Purpose:
> #   - Normality
> #
> # What to Lo .... [TRUNCATED] 

> # Enhanced Histogram using ggplot2
> hist_plot <- ggplot(data.frame(Residuals = residuals), aes(x = Residuals)) +
+   geom_histogram(aes(y = ..densi .... [TRUNCATED] 

> # Display the ggplot2 histogram
> print(hist_plot)

> # Save the ggplot2 histogram if saving is enabled
> if (save_graphs) {
+   ggsave(filename = file.path(graph_save_dir, "Histogram_Residuals_GGPlot2. ..." ... [TRUNCATED] 
[1] "Saved ggplot2 Histogram of Residuals with Normal Curve."

> # Redirect output to the specified file and also print to console
> sink(output_file, append = TRUE, split = TRUE)

> print("")
[1] ""

> # ----------------------------#
> # 10. Statistical Tests
> # ----------------------------#
> 
> 
> # --------- Shapiro-Wilk Test for Normality ---- .... [TRUNCATED] 
[1] "-------- Shapiro-Wilk Test for Normality ---------"

> print("  - Normality: To check if the residuals are normally distributed.")
[1] "  - Normality: To check if the residuals are normally distributed."

> print("  - p-value > 0.05: Fail to reject null hypothesis (residuals are normally distributed).")
[1] "  - p-value > 0.05: Fail to reject null hypothesis (residuals are normally distributed)."

> print("  - p-value <= 0.05: Reject null hypothesis (residuals are not normally distributed).\n")
[1] "  - p-value <= 0.05: Reject null hypothesis (residuals are not normally distributed).\n"

> shapiro_test <- shapiro.test(residuals)

> print("Shapiro-Wilk Test Results:")
[1] "Shapiro-Wilk Test Results:"

> print(shapiro_test)

	Shapiro-Wilk normality test

data:  residuals
W = 0.99326, p-value = 0.9095


> # --------- Breusch-Pagan Test for Homoscedasticity ---------
> print("-------- Breusch-Pagan Test for Homoscedasticity ---------")
[1] "-------- Breusch-Pagan Test for Homoscedasticity ---------"

> print("  - Homoscedasticity: To check if residuals have constant variance across all levels of fitted values.")
[1] "  - Homoscedasticity: To check if residuals have constant variance across all levels of fitted values."

> print("  - p-value > 0.05: Fail to reject null hypothesis (homoscedasticity holds).")
[1] "  - p-value > 0.05: Fail to reject null hypothesis (homoscedasticity holds)."

> print("  - p-value <= 0.05: Reject null hypothesis (heteroscedasticity present).\n")
[1] "  - p-value <= 0.05: Reject null hypothesis (heteroscedasticity present).\n"

> # Extract the model frame from the ssn_lm model
> data_ssn <- model.frame(ssn_mod)

> # Perform Breusch-Pagan Test
> bp_test <- bptest(ssn_mod)

> print("Breusch-Pagan Test Results:")
[1] "Breusch-Pagan Test Results:"

> print(bp_test)

	studentized Breusch-Pagan test

data:  ssn_mod
BP = 23.501, df = 12, p-value = 0.02376


> # --------- Moran's I Test for Spatial Autocorrelation ---------
> print("\n-------- Moran's I Test for Spatial Autocorrelation ---------")
[1] "\n-------- Moran's I Test for Spatial Autocorrelation ---------"

> print("  - Spatial Autocorrelation: To determine if there is spatial autocorrelation in the residuals.")
[1] "  - Spatial Autocorrelation: To determine if there is spatial autocorrelation in the residuals."

> print("  - p-value > 0.05: Fail to reject null hypothesis (lack of spatial autocorrelation in residuals holds).")
[1] "  - p-value > 0.05: Fail to reject null hypothesis (lack of spatial autocorrelation in residuals holds)."

> print("  - p-value <= 0.05: Reject null hypothesis (spatial autocorrelation present).\n")
[1] "  - p-value <= 0.05: Reject null hypothesis (spatial autocorrelation present).\n"

> sink()

> # Extract spatial coordinates from the SSN object
> # Ensure that your SSN object has geometry information
> coords <- st_coordinates(ssn_get_data(s .... [TRUNCATED] 

> # Create a spatial weights matrix using k-nearest neighbors (k = 4 as an example)
> knn <- knearneigh(coords, k = 4)

> nb <- knn2nb(knn)

> lw <- nb2listw(nb, style = "W", zero.policy = TRUE)

> # Compute Moran's I
> moran_test <- moran.test(residuals, lw, zero.policy = TRUE)

> sink(output_file, append = TRUE, split = TRUE)

> print("Moran's I Test Results:")
[1] "Moran's I Test Results:"

> print(moran_test)

	Moran I test under randomisation

data:  residuals  
weights: lw    

Moran I statistic standard deviate = -1.2728, p-value = 0.8985
alternative hypothesis: greater
sample estimates:
Moran I statistic       Expectation          Variance 
     -0.098800062      -0.010309278       0.004833796 


> # Stop redirecting output
> sink()

> # --------------------------------------------------
> # End of Script
> # --------------------------------------------------
> 

> # --------------------------------------------------
> # Spatial Statistical Modeling with SSN2
> # ------------------------------------------------ .... [TRUNCATED] 

> # Specify the input and output directories
> input_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/Inputs"

> output_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/SSN ET/ET LM2 error thresh"

> model_name <- "glm ch_sfm.erosion.norm Zuur VIF-3"

> read_ssn <- TRUE # whether to create a new ssn (FALSE) or read the pre-existing ssn (TRUE)

> # Use file.path to create platform-independent file paths
> streams_path <- file.path(input_dir, "streams_100k.gpkg")

> obs_points_path <- file.path(input_dir, "Individual Watersheds", "LM2 ssn points.gpkg")

> ssn_path <- file.path(output_dir, "1_ET_Full_logtrans_independent_vars.ssn")

> output_file <- file.path(output_dir, model_name, "Results.txt")

> lsn_out <- file.path(output_dir, "0_lsn")

> # Define whether to save graphs and the directory to save them
> save_graphs <- TRUE  # Set to TRUE to save graphs as PNG

> graph_save_dir <- file.path(output_dir, model_name)  # Directory to save graphs

> # ----------------------------#
> # 1. Load Necessary Libraries
> # ----------------------------#
> 
> # Load required libraries
> library(SSN2)

> library(SSNbler)

> library(sf)

> library(dplyr)

> library(purrr)

> library(ggplot2)

> library(lmtest)

> library(spdep)

> library(classInt)   # Required for knearneigh

> library(broom)      # For tidy() and glance() functions

> library(grid)       # For grid.newpage()

> if (!dir.exists(graph_save_dir)) {
+   dir.create(graph_save_dir, recursive = TRUE)
+ }

> # ----------------------------#
> # 2. Read Spatial Data
> # ----------------------------#
> 
> # Read the streams dataset
> ET_streams <- st_read(s .... [TRUNCATED] 
Reading layer `streams_100k' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\streams_100k.gpkg' using driver `GPKG'
Simple feature collection with 643 features and 2 fields
Geometry type: LINESTRING
Dimension:     XY
Bounding box:  xmin: 404042.6 ymin: 4447904 xmax: 414579.6 ymax: 4466669
Projected CRS: NAD83 / UTM zone 13N

> # Read the observation points dataset
> ET_obs <- st_read(obs_points_path)
Reading layer `LM2 ssn points' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\Individual Watersheds\LM2 ssn points.gpkg' using driver `GPKG'
Simple feature collection with 98 features and 59 fields
Geometry type: POINT
Dimension:     XY
Bounding box:  xmin: 412352.5 ymin: 4449827 xmax: 413050.2 ymax: 4450417
Projected CRS: NAD83 / UTM zone 13N

> # Uncomment the following line if you encounter an error about Multilinestrings
> # ET_streams <- st_cast(ET_streams, "LINESTRING")
> 
> # --------- .... [TRUNCATED] 

> # Create a distance matrix for spatial relationships
> # Purpose: Define spatial dependencies based on distances between sites
> ssn_create_distmat( .... [TRUNCATED] 

> # ----------------------------#
> # 4. Model Fitting and Output
> # ----------------------------#
> 
> # Redirect output to the specified file and a .... [TRUNCATED] 

> model_name
[1] "glm ch_sfm.erosion.norm Zuur VIF-3"

> model_formula
ch_sfm.erosion.norm ~ ch_slope.median + ch_curvature.median + 
    ch_valley_width + ch_central.slope.difference + ch_channel.width.over.valley.width + 
    ch_stream.power.central.diff + hs_eastness.median + hs_curvature.median + 
    hs_bare.earth.mean + hs_ndvi.range + hs_dnbr.median + hs_drainage_density

> ssn_mod <- ssn_glm(
+   formula = model_formula,
+   ssn.object = ET_ssn,
+   family = "Gamma",
+   tailup_type = "exponential",
+   taildown_type = .... [TRUNCATED] 

> # --------------------------------------------------
> # Spatial Statistical Modeling with SSN2
> # ------------------------------------------------ .... [TRUNCATED] 

> # Specify the input and output directories
> input_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/Inputs"

> output_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/SSN ET/ET LM2 error thresh"

> model_name <- "glm ch_sfm.erosion.norm Zuur VIF-3"

> read_ssn <- FALSE # whether to create a new ssn (FALSE) or read the pre-existing ssn (TRUE)

> # Use file.path to create platform-independent file paths
> streams_path <- file.path(input_dir, "streams_100k.gpkg")

> obs_points_path <- file.path(input_dir, "Individual Watersheds", "LM2 ssn points.gpkg")

> ssn_path <- file.path(output_dir, "1_ET_Full_logtrans_independent_vars.ssn")

> output_file <- file.path(output_dir, model_name, "Results.txt")

> lsn_out <- file.path(output_dir, "0_lsn")

> # Define whether to save graphs and the directory to save them
> save_graphs <- TRUE  # Set to TRUE to save graphs as PNG

> graph_save_dir <- file.path(output_dir, model_name)  # Directory to save graphs

> # ----------------------------#
> # 1. Load Necessary Libraries
> # ----------------------------#
> 
> # Load required libraries
> library(SSN2)

> library(SSNbler)

> library(sf)

> library(dplyr)

> library(purrr)

> library(ggplot2)

> library(lmtest)

> library(spdep)

> library(classInt)   # Required for knearneigh

> library(broom)      # For tidy() and glance() functions

> library(grid)       # For grid.newpage()

> if (!dir.exists(graph_save_dir)) {
+   dir.create(graph_save_dir, recursive = TRUE)
+ }

> # ----------------------------#
> # 2. Read Spatial Data
> # ----------------------------#
> 
> # Read the streams dataset
> ET_streams <- st_read(s .... [TRUNCATED] 
Reading layer `streams_100k' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\streams_100k.gpkg' using driver `GPKG'
Simple feature collection with 643 features and 2 fields
Geometry type: LINESTRING
Dimension:     XY
Bounding box:  xmin: 404042.6 ymin: 4447904 xmax: 414579.6 ymax: 4466669
Projected CRS: NAD83 / UTM zone 13N

> # Read the observation points dataset
> ET_obs <- st_read(obs_points_path)
Reading layer `LM2 ssn points' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\Individual Watersheds\LM2 ssn points.gpkg' using driver `GPKG'
Simple feature collection with 98 features and 59 fields
Geometry type: POINT
Dimension:     XY
Bounding box:  xmin: 412352.5 ymin: 4449827 xmax: 413050.2 ymax: 4450417
Projected CRS: NAD83 / UTM zone 13N

> # Uncomment the following line if you encounter an error about Multilinestrings
> # ET_streams <- st_cast(ET_streams, "LINESTRING")
> 
> # --------- .... [TRUNCATED] 
[1] "Edge Attributes:"
[1] "rid"            "STRM_VAL"       "flow_accum_max" "Length"         "upDist"         "geometry"      
[1] "Site List Components:"
[1] "obs"
[1] "Updated Edge Attributes:"
[1] "rid"            "STRM_VAL"       "flow_accum_max" "Length"         "upDist"         "flow_accum_PI"  "afv_flow_accum" "geometry"      


SSN object is valid: TRUE

> # Create a distance matrix for spatial relationships
> # Purpose: Define spatial dependencies based on distances between sites
> ssn_create_distmat( .... [TRUNCATED] 

> # ----------------------------#
> # 4. Model Fitting and Output
> # ----------------------------#
> 
> # Redirect output to the specified file and a .... [TRUNCATED] 

> model_name
[1] "glm ch_sfm.erosion.norm Zuur VIF-3"

> model_formula
ch_sfm.erosion.norm ~ ch_slope.median + ch_curvature.median + 
    ch_valley_width + ch_central.slope.difference + ch_channel.width.over.valley.width + 
    ch_stream.power.central.diff + hs_eastness.median + hs_curvature.median + 
    hs_bare.earth.mean + hs_ndvi.range + hs_dnbr.median + hs_drainage_density

> ssn_mod <- ssn_glm(
+   formula = model_formula,
+   ssn.object = ET_ssn,
+   family = "Gamma",
+   tailup_type = "exponential",
+   taildown_type = .... [TRUNCATED] 

> # --------------------------------------------------
> # Spatial Statistical Modeling with SSN2
> # ------------------------------------------------ .... [TRUNCATED] 

> # Specify the input and output directories
> input_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/Inputs"

> output_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/SSN ET/ET LM2 error thresh"

> model_name <- "glm ch_sfm.erosion.norm Zuur VIF-3"

> read_ssn <- FALSE # whether to create a new ssn (FALSE) or read the pre-existing ssn (TRUE)

> # Use file.path to create platform-independent file paths
> streams_path <- file.path(input_dir, "streams_100k.gpkg")

> obs_points_path <- file.path(input_dir, "Individual Watersheds", "LM2 ssn points.gpkg")

> ssn_path <- file.path(output_dir, "1_ET_Full_logtrans_independent_vars.ssn")

> output_file <- file.path(output_dir, model_name, "Results.txt")

> lsn_out <- file.path(output_dir, "0_lsn")

> # Define whether to save graphs and the directory to save them
> save_graphs <- TRUE  # Set to TRUE to save graphs as PNG

> graph_save_dir <- file.path(output_dir, model_name)  # Directory to save graphs

> # ----------------------------#
> # 1. Load Necessary Libraries
> # ----------------------------#
> 
> # Load required libraries
> library(SSN2)

> library(SSNbler)

> library(sf)

> library(dplyr)

> library(purrr)

> library(ggplot2)

> library(lmtest)

> library(spdep)

> library(classInt)   # Required for knearneigh

> library(broom)      # For tidy() and glance() functions

> library(grid)       # For grid.newpage()

> if (!dir.exists(graph_save_dir)) {
+   dir.create(graph_save_dir, recursive = TRUE)
+ }

> # ----------------------------#
> # 2. Read Spatial Data
> # ----------------------------#
> 
> # Read the streams dataset
> ET_streams <- st_read(s .... [TRUNCATED] 
Reading layer `streams_100k' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\streams_100k.gpkg' using driver `GPKG'
Simple feature collection with 643 features and 2 fields
Geometry type: LINESTRING
Dimension:     XY
Bounding box:  xmin: 404042.6 ymin: 4447904 xmax: 414579.6 ymax: 4466669
Projected CRS: NAD83 / UTM zone 13N

> # Read the observation points dataset
> ET_obs <- st_read(obs_points_path)
Reading layer `LM2 ssn points' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\Individual Watersheds\LM2 ssn points.gpkg' using driver `GPKG'
Simple feature collection with 98 features and 59 fields
Geometry type: POINT
Dimension:     XY
Bounding box:  xmin: 412352.5 ymin: 4449827 xmax: 413050.2 ymax: 4450417
Projected CRS: NAD83 / UTM zone 13N

> # Uncomment the following line if you encounter an error about Multilinestrings
> # ET_streams <- st_cast(ET_streams, "LINESTRING")
> 
> # --------- .... [TRUNCATED] 
[1] "Edge Attributes:"
[1] "rid"            "STRM_VAL"       "flow_accum_max" "Length"         "upDist"         "geometry"      
[1] "Site List Components:"
[1] "obs"
[1] "Updated Edge Attributes:"
[1] "rid"            "STRM_VAL"       "flow_accum_max" "Length"         "upDist"         "flow_accum_PI"  "afv_flow_accum" "geometry"      


SSN object is valid: TRUE

> # Create a distance matrix for spatial relationships
> # Purpose: Define spatial dependencies based on distances between sites
> ssn_create_distmat( .... [TRUNCATED] 

> # ----------------------------#
> # 4. Model Fitting and Output
> # ----------------------------#
> 
> # Redirect output to the specified file and a .... [TRUNCATED] 

> model_name
[1] "glm ch_sfm.erosion.norm Zuur VIF-3"

> model_formula
ch_sfm.erosion.norm ~ ch_slope.median + ch_curvature.median + 
    ch_valley_width + ch_central.slope.difference + ch_channel.width.over.valley.width + 
    ch_stream.power.central.diff + hs_eastness.median + hs_curvature.median + 
    hs_bare.earth.mean + hs_ndvi.range + hs_dnbr.median + hs_drainage_density

> ssn_mod <- ssn_glm(
+   formula = model_formula,
+   ssn.object = ET_ssn,
+   family = "Gamma",
+   tailup_type = "exponential",
+   taildown_type = .... [TRUNCATED] 

> # --------------------------------------------------
> # Spatial Statistical Modeling with SSN2
> # ------------------------------------------------ .... [TRUNCATED] 

> # Specify the input and output directories
> input_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/Inputs"

> output_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/SSN ET/ET LM2 error thresh"

> model_name <- "glm ch_sfm.erosion.norm Zuur VIF-3"

> read_ssn <- FALSE # whether to create a new ssn (FALSE) or read the pre-existing ssn (TRUE)

> # Use file.path to create platform-independent file paths
> streams_path <- file.path(input_dir, "streams_100k.gpkg")

> obs_points_path <- file.path(input_dir, "Individual Watersheds", "LM2 ssn points.gpkg")

> ssn_path <- file.path(output_dir, "1_ET_Full_logtrans_independent_vars.ssn")

> output_file <- file.path(output_dir, model_name, "Results.txt")

> lsn_out <- file.path(output_dir, "0_lsn")

> # Define whether to save graphs and the directory to save them
> save_graphs <- TRUE  # Set to TRUE to save graphs as PNG

> graph_save_dir <- file.path(output_dir, model_name)  # Directory to save graphs

> # ----------------------------#
> # 1. Load Necessary Libraries
> # ----------------------------#
> 
> # Load required libraries
> library(SSN2)

> library(SSNbler)

> library(sf)

> library(dplyr)

> library(purrr)

> library(ggplot2)

> library(lmtest)

> library(spdep)

> library(classInt)   # Required for knearneigh

> library(broom)      # For tidy() and glance() functions

> library(grid)       # For grid.newpage()

> if (!dir.exists(graph_save_dir)) {
+   dir.create(graph_save_dir, recursive = TRUE)
+ }

> # ----------------------------#
> # 2. Read Spatial Data
> # ----------------------------#
> 
> # Read the streams dataset
> ET_streams <- st_read(s .... [TRUNCATED] 
Reading layer `streams_100k' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\streams_100k.gpkg' using driver `GPKG'
Simple feature collection with 643 features and 2 fields
Geometry type: LINESTRING
Dimension:     XY
Bounding box:  xmin: 404042.6 ymin: 4447904 xmax: 414579.6 ymax: 4466669
Projected CRS: NAD83 / UTM zone 13N

> # Read the observation points dataset
> ET_obs <- st_read(obs_points_path)
Reading layer `LM2 ssn points' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\Individual Watersheds\LM2 ssn points.gpkg' using driver `GPKG'
Simple feature collection with 88 features and 59 fields
Geometry type: POINT
Dimension:     XY
Bounding box:  xmin: 412357.5 ymin: 4449827 xmax: 413032.9 ymax: 4450389
Projected CRS: NAD83 / UTM zone 13N

> # Uncomment the following line if you encounter an error about Multilinestrings
> # ET_streams <- st_cast(ET_streams, "LINESTRING")
> 
> # --------- .... [TRUNCATED] 
[1] "Edge Attributes:"
[1] "rid"            "STRM_VAL"       "flow_accum_max" "Length"         "upDist"         "geometry"      
[1] "Site List Components:"
[1] "obs"
[1] "Updated Edge Attributes:"
[1] "rid"            "STRM_VAL"       "flow_accum_max" "Length"         "upDist"         "flow_accum_PI"  "afv_flow_accum" "geometry"      


SSN object is valid: TRUE

> # Create a distance matrix for spatial relationships
> # Purpose: Define spatial dependencies based on distances between sites
> ssn_create_distmat( .... [TRUNCATED] 

> # ----------------------------#
> # 4. Model Fitting and Output
> # ----------------------------#
> 
> # Redirect output to the specified file and a .... [TRUNCATED] 

> model_name
[1] "glm ch_sfm.erosion.norm Zuur VIF-3"

> model_formula
ch_sfm.erosion.norm ~ ch_slope.median + ch_curvature.median + 
    ch_valley_width + ch_change.in.slope.over.width + ch_channel.width.over.valley.width + 
    ch_slope.over.width.central.diff + hs_area + hs_eastness.median + 
    hs_curvature.median + hs_bare.earth.mean + hs_ndvi.range + 
    hs_dnbr.median + hs_drainage_density

> ssn_mod <- ssn_glm(
+   formula = model_formula,
+   ssn.object = ET_ssn,
+   family = "Gamma",
+   tailup_type = "exponential",
+   taildown_type = .... [TRUNCATED] 

> # --------------------------------------------------
> # Spatial Statistical Modeling with SSN2
> # ------------------------------------------------ .... [TRUNCATED] 

> # Specify the input and output directories
> input_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/Inputs"

> output_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/SSN ET/ET LM2 error thresh"

> model_name <- "glm ch_sfm.erosion.norm Zuur VIF-3"

> read_ssn <- TRUE # whether to create a new ssn (FALSE) or read the pre-existing ssn (TRUE)

> # Use file.path to create platform-independent file paths
> streams_path <- file.path(input_dir, "streams_100k.gpkg")

> obs_points_path <- file.path(input_dir, "Individual Watersheds", "LM2 ssn points.gpkg")

> ssn_path <- file.path(output_dir, "1_ET_Full_logtrans_independent_vars.ssn")

> output_file <- file.path(output_dir, model_name, "Results.txt")

> lsn_out <- file.path(output_dir, "0_lsn")

> # Define whether to save graphs and the directory to save them
> save_graphs <- TRUE  # Set to TRUE to save graphs as PNG

> graph_save_dir <- file.path(output_dir, model_name)  # Directory to save graphs

> # ----------------------------#
> # 1. Load Necessary Libraries
> # ----------------------------#
> 
> # Load required libraries
> library(SSN2)

> library(SSNbler)

> library(sf)

> library(dplyr)

> library(purrr)

> library(ggplot2)

> library(lmtest)

> library(spdep)

> library(classInt)   # Required for knearneigh

> library(broom)      # For tidy() and glance() functions

> library(grid)       # For grid.newpage()

> if (!dir.exists(graph_save_dir)) {
+   dir.create(graph_save_dir, recursive = TRUE)
+ }

> # ----------------------------#
> # 2. Read Spatial Data
> # ----------------------------#
> 
> # Read the streams dataset
> ET_streams <- st_read(s .... [TRUNCATED] 
Reading layer `streams_100k' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\streams_100k.gpkg' using driver `GPKG'
Simple feature collection with 643 features and 2 fields
Geometry type: LINESTRING
Dimension:     XY
Bounding box:  xmin: 404042.6 ymin: 4447904 xmax: 414579.6 ymax: 4466669
Projected CRS: NAD83 / UTM zone 13N

> # Read the observation points dataset
> ET_obs <- st_read(obs_points_path)
Reading layer `LM2 ssn points' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\Individual Watersheds\LM2 ssn points.gpkg' using driver `GPKG'
Simple feature collection with 88 features and 59 fields
Geometry type: POINT
Dimension:     XY
Bounding box:  xmin: 412357.5 ymin: 4449827 xmax: 413032.9 ymax: 4450389
Projected CRS: NAD83 / UTM zone 13N

> # Uncomment the following line if you encounter an error about Multilinestrings
> # ET_streams <- st_cast(ET_streams, "LINESTRING")
> 
> # --------- .... [TRUNCATED] 

> # Create a distance matrix for spatial relationships
> # Purpose: Define spatial dependencies based on distances between sites
> ssn_create_distmat( .... [TRUNCATED] 

> # ----------------------------#
> # 4. Model Fitting and Output
> # ----------------------------#
> 
> # Redirect output to the specified file and a .... [TRUNCATED] 

> model_name
[1] "glm ch_sfm.erosion.norm Zuur VIF-3"

> model_formula
ch_sfm.erosion.norm ~ ch_slope.median + ch_curvature.median + 
    ch_valley_width + ch_change.in.slope.over.width + ch_channel.width.over.valley.width + 
    ch_slope.over.width.central.diff + hs_area + hs_eastness.median + 
    hs_curvature.median + hs_bare.earth.mean + hs_ndvi.range + 
    hs_dnbr.median + hs_drainage_density

> ssn_mod <- ssn_glm(
+   formula = model_formula,
+   ssn.object = ET_ssn,
+   family = "Gamma",
+   tailup_type = "exponential",
+   taildown_type = .... [TRUNCATED] 

> # --------------------------------------------------
> # Spatial Statistical Modeling with SSN2
> # ------------------------------------------------ .... [TRUNCATED] 

> # Specify the input and output directories
> input_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/Inputs"

> output_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/SSN ET/ET LM2 error thresh"

> model_name <- "glm ch_sfm.erosion.norm Zuur VIF-3"

> read_ssn <- FALSE # whether to create a new ssn (FALSE) or read the pre-existing ssn (TRUE)

> # Use file.path to create platform-independent file paths
> streams_path <- file.path(input_dir, "streams_100k.gpkg")

> obs_points_path <- file.path(input_dir, "Individual Watersheds", "LM2 ssn points.gpkg")

> ssn_path <- file.path(output_dir, "1_ET_Full_logtrans_independent_vars.ssn")

> output_file <- file.path(output_dir, model_name, "Results.txt")

> lsn_out <- file.path(output_dir, "0_lsn")

> # Define whether to save graphs and the directory to save them
> save_graphs <- TRUE  # Set to TRUE to save graphs as PNG

> graph_save_dir <- file.path(output_dir, model_name)  # Directory to save graphs

> # ----------------------------#
> # 1. Load Necessary Libraries
> # ----------------------------#
> 
> # Load required libraries
> library(SSN2)

> library(SSNbler)

> library(sf)

> library(dplyr)

> library(purrr)

> library(ggplot2)

> library(lmtest)

> library(spdep)

> library(classInt)   # Required for knearneigh

> library(broom)      # For tidy() and glance() functions

> library(grid)       # For grid.newpage()

> if (!dir.exists(graph_save_dir)) {
+   dir.create(graph_save_dir, recursive = TRUE)
+ }

> # ----------------------------#
> # 2. Read Spatial Data
> # ----------------------------#
> 
> # Read the streams dataset
> ET_streams <- st_read(s .... [TRUNCATED] 
Reading layer `streams_100k' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\streams_100k.gpkg' using driver `GPKG'
Simple feature collection with 643 features and 2 fields
Geometry type: LINESTRING
Dimension:     XY
Bounding box:  xmin: 404042.6 ymin: 4447904 xmax: 414579.6 ymax: 4466669
Projected CRS: NAD83 / UTM zone 13N

> # Read the observation points dataset
> ET_obs <- st_read(obs_points_path)
Reading layer `LM2 ssn points' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\Individual Watersheds\LM2 ssn points.gpkg' using driver `GPKG'
Simple feature collection with 88 features and 59 fields
Geometry type: POINT
Dimension:     XY
Bounding box:  xmin: 412357.5 ymin: 4449827 xmax: 413032.9 ymax: 4450389
Projected CRS: NAD83 / UTM zone 13N

> # Uncomment the following line if you encounter an error about Multilinestrings
> # ET_streams <- st_cast(ET_streams, "LINESTRING")
> 
> # --------- .... [TRUNCATED] 
[1] "Edge Attributes:"
[1] "rid"            "STRM_VAL"       "flow_accum_max" "Length"         "upDist"         "geometry"      
[1] "Site List Components:"
[1] "obs"
[1] "Updated Edge Attributes:"
[1] "rid"            "STRM_VAL"       "flow_accum_max" "Length"         "upDist"         "flow_accum_PI"  "afv_flow_accum" "geometry"      


SSN object is valid: TRUE

> # Create a distance matrix for spatial relationships
> # Purpose: Define spatial dependencies based on distances between sites
> ssn_create_distmat( .... [TRUNCATED] 

> # ----------------------------#
> # 4. Model Fitting and Output
> # ----------------------------#
> 
> # Redirect output to the specified file and a .... [TRUNCATED] 

> model_name
[1] "glm ch_sfm.erosion.norm Zuur VIF-3"

> model_formula
ch_sfm.erosion.norm ~ ch_slope.median + ch_curvature.median + 
    ch_valley_width + ch_change.in.slope.over.width + ch_channel.width.over.valley.width + 
    ch_slope.over.width.central.diff + hs_area + hs_eastness.median + 
    hs_curvature.median + hs_bare.earth.mean + hs_ndvi.range + 
    hs_dnbr.median + hs_drainage_density

> ssn_mod <- ssn_glm(
+   formula = model_formula,
+   ssn.object = ET_ssn,
+   family = "Gamma",
+   tailup_type = "exponential",
+   taildown_type = .... [TRUNCATED] 

> # --------------------------------------------------
> # Spatial Statistical Modeling with SSN2
> # ------------------------------------------------ .... [TRUNCATED] 

> # Specify the input and output directories
> input_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/Inputs"

> output_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/SSN ET/ET LM2 error thresh"

> model_name <- "glm ch_sfm.erosion.norm Zuur VIF-3"

> read_ssn <- TRUE # whether to create a new ssn (FALSE) or read the pre-existing ssn (TRUE)

> # Use file.path to create platform-independent file paths
> streams_path <- file.path(input_dir, "streams_100k.gpkg")

> obs_points_path <- file.path(input_dir, "Individual Watersheds", "LM2 ssn points.gpkg")

> ssn_path <- file.path(output_dir, "1_ET_Full_logtrans_independent_vars.ssn")

> output_file <- file.path(output_dir, model_name, "Results.txt")

> lsn_out <- file.path(output_dir, "0_lsn")

> # Define whether to save graphs and the directory to save them
> save_graphs <- TRUE  # Set to TRUE to save graphs as PNG

> graph_save_dir <- file.path(output_dir, model_name)  # Directory to save graphs

> # ----------------------------#
> # 1. Load Necessary Libraries
> # ----------------------------#
> 
> # Load required libraries
> library(SSN2)

> library(SSNbler)

> library(sf)

> library(dplyr)

> library(purrr)

> library(ggplot2)

> library(lmtest)

> library(spdep)

> library(classInt)   # Required for knearneigh

> library(broom)      # For tidy() and glance() functions

> library(grid)       # For grid.newpage()

> if (!dir.exists(graph_save_dir)) {
+   dir.create(graph_save_dir, recursive = TRUE)
+ }

> # ----------------------------#
> # 2. Read Spatial Data
> # ----------------------------#
> 
> # Read the streams dataset
> ET_streams <- st_read(s .... [TRUNCATED] 
Reading layer `streams_100k' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\streams_100k.gpkg' using driver `GPKG'
Simple feature collection with 643 features and 2 fields
Geometry type: LINESTRING
Dimension:     XY
Bounding box:  xmin: 404042.6 ymin: 4447904 xmax: 414579.6 ymax: 4466669
Projected CRS: NAD83 / UTM zone 13N

> # Read the observation points dataset
> ET_obs <- st_read(obs_points_path)
Reading layer `LM2 ssn points' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\Individual Watersheds\LM2 ssn points.gpkg' using driver `GPKG'
Simple feature collection with 88 features and 59 fields
Geometry type: POINT
Dimension:     XY
Bounding box:  xmin: 412357.5 ymin: 4449827 xmax: 413032.9 ymax: 4450389
Projected CRS: NAD83 / UTM zone 13N

> # Uncomment the following line if you encounter an error about Multilinestrings
> # ET_streams <- st_cast(ET_streams, "LINESTRING")
> 
> # --------- .... [TRUNCATED] 

> # Create a distance matrix for spatial relationships
> # Purpose: Define spatial dependencies based on distances between sites
> ssn_create_distmat( .... [TRUNCATED] 

> # ----------------------------#
> # 4. Model Fitting and Output
> # ----------------------------#
> 
> # Redirect output to the specified file and a .... [TRUNCATED] 

> model_name
[1] "glm ch_sfm.erosion.norm Zuur VIF-3"

> model_formula
ch_sfm.erosion.norm ~ ch_slope.median + ch_curvature.median + 
    ch_valley_width + ch_change.in.slope.over.width + ch_channel.width.over.valley.width + 
    ch_slope.over.width.central.diff + hs_area + hs_eastness.median + 
    hs_curvature.median + hs_bare.earth.mean + hs_ndvi.range + 
    hs_dnbr.median + hs_drainage_density

> ssn_mod <- ssn_glm(
+   formula = model_formula,
+   ssn.object = ET_ssn,
+   family = "Gamma",
+   tailup_type = "exponential",
+   taildown_type = .... [TRUNCATED] 

> # --------------------------------------------------
> # Spatial Statistical Modeling with SSN2
> # ------------------------------------------------ .... [TRUNCATED] 

> # Specify the input and output directories
> input_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/Inputs"

> output_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/SSN ET/ET LM2 error thresh"

> model_name <- "glm ch_sfm.erosion.norm Zuur VIF-3"

> read_ssn <- FALSE # whether to create a new ssn (FALSE) or read the pre-existing ssn (TRUE)

> # Use file.path to create platform-independent file paths
> streams_path <- file.path(input_dir, "streams_100k.gpkg")

> obs_points_path <- file.path(input_dir, "Individual Watersheds", "LM2 ssn points.gpkg")

> ssn_path <- file.path(output_dir, "1_ET_Full_logtrans_independent_vars.ssn")

> output_file <- file.path(output_dir, model_name, "Results.txt")

> lsn_out <- file.path(output_dir, "0_lsn")

> # Define whether to save graphs and the directory to save them
> save_graphs <- TRUE  # Set to TRUE to save graphs as PNG

> graph_save_dir <- file.path(output_dir, model_name)  # Directory to save graphs

> # ----------------------------#
> # 1. Load Necessary Libraries
> # ----------------------------#
> 
> # Load required libraries
> library(SSN2)

> library(SSNbler)

> library(sf)

> library(dplyr)

> library(purrr)

> library(ggplot2)

> library(lmtest)

> library(spdep)

> library(classInt)   # Required for knearneigh

> library(broom)      # For tidy() and glance() functions

> library(grid)       # For grid.newpage()

> if (!dir.exists(graph_save_dir)) {
+   dir.create(graph_save_dir, recursive = TRUE)
+ }

> # ----------------------------#
> # 2. Read Spatial Data
> # ----------------------------#
> 
> # Read the streams dataset
> ET_streams <- st_read(s .... [TRUNCATED] 
Reading layer `streams_100k' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\streams_100k.gpkg' using driver `GPKG'
Simple feature collection with 643 features and 2 fields
Geometry type: LINESTRING
Dimension:     XY
Bounding box:  xmin: 404042.6 ymin: 4447904 xmax: 414579.6 ymax: 4466669
Projected CRS: NAD83 / UTM zone 13N

> # Read the observation points dataset
> ET_obs <- st_read(obs_points_path)
Reading layer `LM2 ssn points' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\Individual Watersheds\LM2 ssn points.gpkg' using driver `GPKG'
Simple feature collection with 88 features and 59 fields
Geometry type: POINT
Dimension:     XY
Bounding box:  xmin: 412357.5 ymin: 4449827 xmax: 413032.9 ymax: 4450389
Projected CRS: NAD83 / UTM zone 13N

> # Uncomment the following line if you encounter an error about Multilinestrings
> # ET_streams <- st_cast(ET_streams, "LINESTRING")
> 
> # --------- .... [TRUNCATED] 
[1] "Edge Attributes:"
[1] "rid"            "STRM_VAL"       "flow_accum_max" "Length"         "upDist"         "geometry"      
[1] "Site List Components:"
[1] "obs"
[1] "Updated Edge Attributes:"
[1] "rid"            "STRM_VAL"       "flow_accum_max" "Length"         "upDist"         "flow_accum_PI"  "afv_flow_accum" "geometry"      


SSN object is valid: TRUE

> # Create a distance matrix for spatial relationships
> # Purpose: Define spatial dependencies based on distances between sites
> ssn_create_distmat( .... [TRUNCATED] 

> # ----------------------------#
> # 4. Model Fitting and Output
> # ----------------------------#
> 
> # Redirect output to the specified file and a .... [TRUNCATED] 

> model_name
[1] "glm ch_sfm.erosion.norm Zuur VIF-3"

> model_formula
ch_sfm.erosion.norm ~ ch_slope.median + ch_curvature.median + 
    ch_valley_width + ch_change.in.slope.over.width + ch_channel.width.over.valley.width + 
    ch_slope.over.width.central.diff + hs_area + hs_eastness.median + 
    hs_curvature.median + hs_bare.earth.mean + hs_ndvi.range + 
    hs_dnbr.median + hs_drainage_density

> ssn_mod <- ssn_glm(
+   formula = model_formula,
+   ssn.object = ET_ssn,
+   family = "Gamma",
+   tailup_type = "exponential",
+   taildown_type = .... [TRUNCATED] 

> # Print the summary of the model to the file and console
> print(summary(ssn_mod))

Call:
ssn_glm(formula = model_formula, ssn.object = ET_ssn, family = "Gamma", 
    tailup_type = "exponential", taildown_type = "none", euclid_type = "gaussian", 
    additive = "afv_flow_accum")

Deviance Residuals:
    Min      1Q  Median      3Q     Max 
-1.2116 -0.3340 -0.0638  0.2624  0.9160 

Coefficients (fixed):
                                   Estimate Std. Error z value Pr(>|z|)   
(Intercept)                        -2.16046    0.72572  -2.977  0.00291 **
ch_slope.median                     0.66545    0.38703   1.719  0.08554 . 
ch_curvature.median                 0.14517    0.19071   0.761  0.44654   
ch_valley_width                    -0.02373    0.13857  -0.171  0.86401   
ch_change.in.slope.over.width      -0.12831    0.08049  -1.594  0.11094   
ch_channel.width.over.valley.width -0.05526    0.20096  -0.275  0.78331   
ch_slope.over.width.central.diff    0.15051    0.10213   1.474  0.14057   
hs_area                            -0.39806    0.21745  -1.831  0.06716 . 
hs_eastness.median                 -0.29871    0.20565  -1.453  0.14635   
hs_curvature.median                 0.12801    0.13106   0.977  0.32872   
hs_bare.earth.mean                 -0.11256    0.27953  -0.403  0.68718   
hs_ndvi.range                       0.20971    0.42766   0.490  0.62388   
hs_dnbr.median                     -0.49740    0.26585  -1.871  0.06135 . 
hs_drainage_density                81.51776   69.72823   1.169  0.24237   
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Pseudo R-squared: 0.2151

Coefficients (covariance):
              Effect     Parameter   Estimate
  tailup exponential  de (parsill)   0.006849
  tailup exponential         range   0.017927
     euclid gaussian  de (parsill)   3.600499
     euclid gaussian         range  82.283977
              nugget        nugget   0.197194
          dispersion    dispersion   2.579477


> # Print variance components of the model
> varcomp(ssn_mod)
# A tibble: 5 × 2
  varcomp            proportion
  <chr>                   <dbl>
1 Covariates (PR-sq)    0.215  
2 tailup_de             0.00141
3 taildown_de           0      
4 euclid_de             0.743  
5 nugget                0.0407 

> # Tidy the model output with confidence intervals and print
> print(tidy(ssn_mod, conf.int = TRUE))  
# A tibble: 14 × 7
   term                               estimate std.error statistic p.value conf.low conf.high
   <chr>                                 <dbl>     <dbl>     <dbl>   <dbl>    <dbl>     <dbl>
 1 (Intercept)                         -2.16      0.726     -2.98  0.00291  -3.58     -0.738 
 2 ch_change.in.slope.over.width       -0.128     0.0805    -1.59  0.111    -0.286     0.0295
 3 ch_channel.width.over.valley.width  -0.0553    0.201     -0.275 0.783    -0.449     0.339 
 4 ch_curvature.median                  0.145     0.191      0.761 0.447    -0.229     0.519 
 5 ch_slope.median                      0.665     0.387      1.72  0.0855   -0.0931    1.42  
 6 ch_slope.over.width.central.diff     0.151     0.102      1.47  0.141    -0.0497    0.351 
 7 ch_valley_width                     -0.0237    0.139     -0.171 0.864    -0.295     0.248 
 8 hs_area                             -0.398     0.217     -1.83  0.0672   -0.824     0.0281
 9 hs_bare.earth.mean                  -0.113     0.280     -0.403 0.687    -0.660     0.435 
10 hs_curvature.median                  0.128     0.131      0.977 0.329    -0.129     0.385 
11 hs_dnbr.median                      -0.497     0.266     -1.87  0.0613   -1.02      0.0237
12 hs_drainage_density                 81.5      69.7        1.17  0.242   -55.1     218.    
13 hs_eastness.median                  -0.299     0.206     -1.45  0.146    -0.702     0.104 
14 hs_ndvi.range                        0.210     0.428      0.490 0.624    -0.628     1.05  

> # Provide a glance summary of the model and print
> print(glance(ssn_mod))
# A tibble: 1 × 9
      n     p  npar value   AIC  AICc logLik deviance pseudo.r.squared
  <int> <dbl> <int> <dbl> <dbl> <dbl>  <dbl>    <dbl>            <dbl>
1    88    14     6  112.  124.  126.  -56.2     16.9            0.215

> # Perform Leave-One-Out Cross Validation and print
> print("Leave One Out Cross Validation")
[1] "Leave One Out Cross Validation"

> loocv_results <- loocv(ssn_mod)

> print(loocv_results)
# A tibble: 1 × 4
     bias  MSPE RMSPE   RAV
    <dbl> <dbl> <dbl> <dbl>
1 -0.0480 0.103 0.321 0.674

> # Stop redirecting output
> sink()

> # ----------------------------#
> # 5. Model Evaluation
> # ----------------------------#
> 
> # Extract residuals and fitted values from the model
 .... [TRUNCATED] 

> fitted_values <- fitted(ssn_mod)   

> # ----------------------------#
> # 6. Plotting and Saving Graphs
> # ----------------------------#
> 
> 
> # Create the graph save directory if sav .... [TRUNCATED] 

> # ----------------------------#
> # 7. Residuals vs Fitted Values Plot
> # ----------------------------#
> 
> # Purpose:
> #   - Linearity: Ensure t .... [TRUNCATED] 

> # Create the Residuals vs Fitted Values plot
> resid_fitted_plot <- ggplot(data.frame(Fitted = fitted_values, Residuals = residuals), aes(x = Fitted .... [TRUNCATED] 

> # Display the plot
> print(resid_fitted_plot)

> # Save the plot if saving is enabled
> if (save_graphs) {
+   ggsave(filename = file.path(graph_save_dir, "Residuals_vs_Fitted.png"), plot = resid_f .... [TRUNCATED] 
[1] "Saved Residuals vs Fitted Values plot."

> # ----------------------------#
> # 8. Q-Q Plot for Residuals
> # ----------------------------#
> 
> # Purpose:
> #   - Normality: Verify that resid .... [TRUNCATED] 

> # Enhanced Q-Q Plot using ggplot2
> qq_plot <- ggplot(data.frame(Residuals = residuals), aes(sample = Residuals)) +
+   stat_qq(color = "blue") +
+  .... [TRUNCATED] 

> # Display the ggplot2 Q-Q plot
> print(qq_plot)

> # Save the ggplot2 Q-Q plot if saving is enabled
> if (save_graphs) {
+   ggsave(filename = file.path(graph_save_dir, "QQ_Plot_Residuals_GGPlot2.png ..." ... [TRUNCATED] 
[1] "Saved ggplot2 Q-Q Plot of Residuals."

> # ----------------------------#
> # 9. Histogram of Residuals
> # ----------------------------#
> 
> # Purpose:
> #   - Normality
> #
> # What to Lo .... [TRUNCATED] 

> # Enhanced Histogram using ggplot2
> hist_plot <- ggplot(data.frame(Residuals = residuals), aes(x = Residuals)) +
+   geom_histogram(aes(y = ..densi .... [TRUNCATED] 

> # Display the ggplot2 histogram
> print(hist_plot)

> # Save the ggplot2 histogram if saving is enabled
> if (save_graphs) {
+   ggsave(filename = file.path(graph_save_dir, "Histogram_Residuals_GGPlot2. ..." ... [TRUNCATED] 
[1] "Saved ggplot2 Histogram of Residuals with Normal Curve."

> # Redirect output to the specified file and also print to console
> sink(output_file, append = TRUE, split = TRUE)

> print("")
[1] ""

> # ----------------------------#
> # 10. Statistical Tests
> # ----------------------------#
> 
> 
> # --------- Shapiro-Wilk Test for Normality ---- .... [TRUNCATED] 
[1] "-------- Shapiro-Wilk Test for Normality ---------"

> print("  - Normality: To check if the residuals are normally distributed.")
[1] "  - Normality: To check if the residuals are normally distributed."

> print("  - p-value > 0.05: Fail to reject null hypothesis (residuals are normally distributed).")
[1] "  - p-value > 0.05: Fail to reject null hypothesis (residuals are normally distributed)."

> print("  - p-value <= 0.05: Reject null hypothesis (residuals are not normally distributed).\n")
[1] "  - p-value <= 0.05: Reject null hypothesis (residuals are not normally distributed).\n"

> shapiro_test <- shapiro.test(residuals)

> print("Shapiro-Wilk Test Results:")
[1] "Shapiro-Wilk Test Results:"

> print(shapiro_test)

	Shapiro-Wilk normality test

data:  residuals
W = 0.9893, p-value = 0.6937


> # --------- Breusch-Pagan Test for Homoscedasticity ---------
> print("-------- Breusch-Pagan Test for Homoscedasticity ---------")
[1] "-------- Breusch-Pagan Test for Homoscedasticity ---------"

> print("  - Homoscedasticity: To check if residuals have constant variance across all levels of fitted values.")
[1] "  - Homoscedasticity: To check if residuals have constant variance across all levels of fitted values."

> print("  - p-value > 0.05: Fail to reject null hypothesis (homoscedasticity holds).")
[1] "  - p-value > 0.05: Fail to reject null hypothesis (homoscedasticity holds)."

> print("  - p-value <= 0.05: Reject null hypothesis (heteroscedasticity present).\n")
[1] "  - p-value <= 0.05: Reject null hypothesis (heteroscedasticity present).\n"

> # Extract the model frame from the ssn_lm model
> data_ssn <- model.frame(ssn_mod)

> # Perform Breusch-Pagan Test
> bp_test <- bptest(ssn_mod)

> print("Breusch-Pagan Test Results:")
[1] "Breusch-Pagan Test Results:"

> print(bp_test)

	studentized Breusch-Pagan test

data:  ssn_mod
BP = 12.372, df = 13, p-value = 0.4974


> # --------- Moran's I Test for Spatial Autocorrelation ---------
> print("\n-------- Moran's I Test for Spatial Autocorrelation ---------")
[1] "\n-------- Moran's I Test for Spatial Autocorrelation ---------"

> print("  - Spatial Autocorrelation: To determine if there is spatial autocorrelation in the residuals.")
[1] "  - Spatial Autocorrelation: To determine if there is spatial autocorrelation in the residuals."

> print("  - p-value > 0.05: Fail to reject null hypothesis (lack of spatial autocorrelation in residuals holds).")
[1] "  - p-value > 0.05: Fail to reject null hypothesis (lack of spatial autocorrelation in residuals holds)."

> print("  - p-value <= 0.05: Reject null hypothesis (spatial autocorrelation present).\n")
[1] "  - p-value <= 0.05: Reject null hypothesis (spatial autocorrelation present).\n"

> sink()

> # Extract spatial coordinates from the SSN object
> # Ensure that your SSN object has geometry information
> coords <- st_coordinates(ssn_get_data(s .... [TRUNCATED] 

> # Create a spatial weights matrix using k-nearest neighbors (k = 4 as an example)
> knn <- knearneigh(coords, k = 4)

> nb <- knn2nb(knn)

> lw <- nb2listw(nb, style = "W", zero.policy = TRUE)

> # Compute Moran's I
> moran_test <- moran.test(residuals, lw, zero.policy = TRUE)

> sink(output_file, append = TRUE, split = TRUE)

> print("Moran's I Test Results:")
[1] "Moran's I Test Results:"

> print(moran_test)

	Moran I test under randomisation

data:  residuals  
weights: lw    

Moran I statistic standard deviate = -2.5552, p-value = 0.9947
alternative hypothesis: greater
sample estimates:
Moran I statistic       Expectation          Variance 
     -0.197929558      -0.011494253       0.005323762 


> # Stop redirecting output
> sink()

> # --------------------------------------------------
> # End of Script
> # --------------------------------------------------
> 

> # --------------------------------------------------
> # Spatial Statistical Modeling with SSN2
> # ------------------------------------------------ .... [TRUNCATED] 

> # Specify the input and output directories
> input_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/Inputs"

> output_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/SSN ET/ET Lower error thresh"

> model_name <- "glm ch_sfm.erosion.norm Zuur VIF-3"

> read_ssn <- FALSE # whether to create a new ssn (FALSE) or read the pre-existing ssn (TRUE)

> # Use file.path to create platform-independent file paths
> streams_path <- file.path(input_dir, "streams_100k.gpkg")

> obs_points_path <- file.path(input_dir, "Individual Watersheds", "LM2 ssn points.gpkg")

> ssn_path <- file.path(output_dir, "1_ET_Full_logtrans_independent_vars.ssn")

> output_file <- file.path(output_dir, model_name, "Results.txt")

> lsn_out <- file.path(output_dir, "0_lsn")

> # Define whether to save graphs and the directory to save them
> save_graphs <- TRUE  # Set to TRUE to save graphs as PNG

> graph_save_dir <- file.path(output_dir, model_name)  # Directory to save graphs

> # ----------------------------#
> # 1. Load Necessary Libraries
> # ----------------------------#
> 
> # Load required libraries
> library(SSN2)

> library(SSNbler)

> library(sf)

> library(dplyr)

> library(purrr)

> library(ggplot2)

> library(lmtest)

> library(spdep)

> library(classInt)   # Required for knearneigh

> library(broom)      # For tidy() and glance() functions

> library(grid)       # For grid.newpage()

> if (!dir.exists(graph_save_dir)) {
+   dir.create(graph_save_dir, recursive = TRUE)
+ }

> # ----------------------------#
> # 2. Read Spatial Data
> # ----------------------------#
> 
> # Read the streams dataset
> ET_streams <- st_read(s .... [TRUNCATED] 
Reading layer `streams_100k' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\streams_100k.gpkg' using driver `GPKG'
Simple feature collection with 643 features and 2 fields
Geometry type: LINESTRING
Dimension:     XY
Bounding box:  xmin: 404042.6 ymin: 4447904 xmax: 414579.6 ymax: 4466669
Projected CRS: NAD83 / UTM zone 13N

> # Read the observation points dataset
> ET_obs <- st_read(obs_points_path)
Reading layer `LM2 ssn points' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\Individual Watersheds\LM2 ssn points.gpkg' using driver `GPKG'
Simple feature collection with 88 features and 59 fields
Geometry type: POINT
Dimension:     XY
Bounding box:  xmin: 412357.5 ymin: 4449827 xmax: 413032.9 ymax: 4450389
Projected CRS: NAD83 / UTM zone 13N

> # Uncomment the following line if you encounter an error about Multilinestrings
> # ET_streams <- st_cast(ET_streams, "LINESTRING")
> 
> # --------- .... [TRUNCATED] 
[1] "Edge Attributes:"
[1] "rid"            "STRM_VAL"       "flow_accum_max" "Length"         "upDist"         "geometry"      
[1] "Site List Components:"
[1] "obs"
[1] "Updated Edge Attributes:"
[1] "rid"            "STRM_VAL"       "flow_accum_max" "Length"         "upDist"         "flow_accum_PI"  "afv_flow_accum" "geometry"      


SSN object is valid: TRUE

> # Create a distance matrix for spatial relationships
> # Purpose: Define spatial dependencies based on distances between sites
> ssn_create_distmat( .... [TRUNCATED] 

> # ----------------------------#
> # 4. Model Fitting and Output
> # ----------------------------#
> 
> # Redirect output to the specified file and a .... [TRUNCATED] 

> model_name
[1] "glm ch_sfm.erosion.norm Zuur VIF-3"

> model_formula
ch_sfm.erosion.norm ~ ch_flow.accumulation.max + ch_curvature.median + 
    ch_slope.downstream + ch_change.in.slope.over.width + ch_stream.power + 
    ch_channel.width.over.valley.width + ch_stream.power.central.diff + 
    hs_hillslope.length + hs_slope.median + hs_eastness.median + 
    hs_curvature.median + hs_ndvi.range + hs_dnbr.median + hs_drainage_density

> ssn_mod <- ssn_glm(
+   formula = model_formula,
+   ssn.object = ET_ssn,
+   family = "Gamma",
+   tailup_type = "exponential",
+   taildown_type = .... [TRUNCATED] 

> # Print the summary of the model to the file and console
> print(summary(ssn_mod))

Call:
ssn_glm(formula = model_formula, ssn.object = ET_ssn, family = "Gamma", 
    tailup_type = "exponential", taildown_type = "none", euclid_type = "gaussian", 
    additive = "afv_flow_accum")

Deviance Residuals:
    Min      1Q  Median      3Q     Max 
-1.9590 -0.5638 -0.1357  0.2821  1.1713 

Coefficients (fixed):
                                   Estimate Std. Error z value Pr(>|z|)   
(Intercept)                        -1.79557    0.59045  -3.041  0.00236 **
ch_flow.accumulation.max           -0.36764    0.97649  -0.376  0.70656   
ch_curvature.median                 0.26024    0.19970   1.303  0.19253   
ch_slope.downstream                 0.17798    0.52620   0.338  0.73519   
ch_change.in.slope.over.width      -0.19345    0.10593  -1.826  0.06781 . 
ch_stream.power                     0.75458    0.31733   2.378  0.01741 * 
ch_channel.width.over.valley.width  0.28518    0.23475   1.215  0.22444   
ch_stream.power.central.diff        0.15734    0.09842   1.599  0.10989   
hs_hillslope.length                -0.39699    0.25333  -1.567  0.11710   
hs_slope.median                     0.01157    0.42591   0.027  0.97834   
hs_eastness.median                 -0.26333    0.22646  -1.163  0.24491   
hs_curvature.median                 0.16300    0.15000   1.087  0.27718   
hs_ndvi.range                       0.14061    0.42264   0.333  0.73937   
hs_dnbr.median                     -0.52436    0.28805  -1.820  0.06870 . 
hs_drainage_density                69.05488   74.28895   0.930  0.35261   
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Pseudo R-squared: 0.1836

Coefficients (covariance):
              Effect     Parameter   Estimate
  tailup exponential  de (parsill)   0.055584
  tailup exponential         range  41.085443
     euclid gaussian  de (parsill)   2.255462
     euclid gaussian         range  81.320942
              nugget        nugget   0.007074
          dispersion    dispersion   1.776056


> # Print variance components of the model
> varcomp(ssn_mod)
# A tibble: 5 × 2
  varcomp            proportion
  <chr>                   <dbl>
1 Covariates (PR-sq)    0.184  
2 tailup_de             0.0196 
3 taildown_de           0      
4 euclid_de             0.794  
5 nugget                0.00249

> # Tidy the model output with confidence intervals and print
> print(tidy(ssn_mod, conf.int = TRUE))  
# A tibble: 15 × 7
   term                               estimate std.error statistic p.value conf.low conf.high
   <chr>                                 <dbl>     <dbl>     <dbl>   <dbl>    <dbl>     <dbl>
 1 (Intercept)                         -1.80      0.590    -3.04   0.00236  -2.95     -0.638 
 2 ch_change.in.slope.over.width       -0.193     0.106    -1.83   0.0678   -0.401     0.0142
 3 ch_channel.width.over.valley.width   0.285     0.235     1.21   0.224    -0.175     0.745 
 4 ch_curvature.median                  0.260     0.200     1.30   0.193    -0.131     0.652 
 5 ch_flow.accumulation.max            -0.368     0.976    -0.376  0.707    -2.28      1.55  
 6 ch_slope.downstream                  0.178     0.526     0.338  0.735    -0.853     1.21  
 7 ch_stream.power                      0.755     0.317     2.38   0.0174    0.133     1.38  
 8 ch_stream.power.central.diff         0.157     0.0984    1.60   0.110    -0.0356    0.350 
 9 hs_curvature.median                  0.163     0.150     1.09   0.277    -0.131     0.457 
10 hs_dnbr.median                      -0.524     0.288    -1.82   0.0687   -1.09      0.0402
11 hs_drainage_density                 69.1      74.3       0.930  0.353   -76.5     215.    
12 hs_eastness.median                  -0.263     0.226    -1.16   0.245    -0.707     0.181 
13 hs_hillslope.length                 -0.397     0.253    -1.57   0.117    -0.894     0.0995
14 hs_ndvi.range                        0.141     0.423     0.333  0.739    -0.688     0.969 
15 hs_slope.median                      0.0116    0.426     0.0272 0.978    -0.823     0.846 

> # Provide a glance summary of the model and print
> print(glance(ssn_mod))
# A tibble: 1 × 9
      n     p  npar value   AIC  AICc logLik deviance pseudo.r.squared
  <int> <dbl> <int> <dbl> <dbl> <dbl>  <dbl>    <dbl>            <dbl>
1    88    15     6  106.  118.  119.  -53.0     37.5            0.184

> # Perform Leave-One-Out Cross Validation and print
> print("Leave One Out Cross Validation")
[1] "Leave One Out Cross Validation"

> loocv_results <- loocv(ssn_mod)

> print(loocv_results)
# A tibble: 1 × 4
     bias   MSPE RMSPE   RAV
    <dbl>  <dbl> <dbl> <dbl>
1 -0.0208 0.0739 0.272 0.267

> # Stop redirecting output
> sink()

> # ----------------------------#
> # 5. Model Evaluation
> # ----------------------------#
> 
> # Extract residuals and fitted values from the model
 .... [TRUNCATED] 

> fitted_values <- fitted(ssn_mod)   

> # ----------------------------#
> # 6. Plotting and Saving Graphs
> # ----------------------------#
> 
> 
> # Create the graph save directory if sav .... [TRUNCATED] 

> # ----------------------------#
> # 7. Residuals vs Fitted Values Plot
> # ----------------------------#
> 
> # Purpose:
> #   - Linearity: Ensure t .... [TRUNCATED] 

> # Create the Residuals vs Fitted Values plot
> resid_fitted_plot <- ggplot(data.frame(Fitted = fitted_values, Residuals = residuals), aes(x = Fitted .... [TRUNCATED] 

> # Display the plot
> print(resid_fitted_plot)

> # Save the plot if saving is enabled
> if (save_graphs) {
+   ggsave(filename = file.path(graph_save_dir, "Residuals_vs_Fitted.png"), plot = resid_f .... [TRUNCATED] 
[1] "Saved Residuals vs Fitted Values plot."

> # ----------------------------#
> # 8. Q-Q Plot for Residuals
> # ----------------------------#
> 
> # Purpose:
> #   - Normality: Verify that resid .... [TRUNCATED] 

> # Enhanced Q-Q Plot using ggplot2
> qq_plot <- ggplot(data.frame(Residuals = residuals), aes(sample = Residuals)) +
+   stat_qq(color = "blue") +
+  .... [TRUNCATED] 

> # Display the ggplot2 Q-Q plot
> print(qq_plot)

> # Save the ggplot2 Q-Q plot if saving is enabled
> if (save_graphs) {
+   ggsave(filename = file.path(graph_save_dir, "QQ_Plot_Residuals_GGPlot2.png ..." ... [TRUNCATED] 
[1] "Saved ggplot2 Q-Q Plot of Residuals."

> # ----------------------------#
> # 9. Histogram of Residuals
> # ----------------------------#
> 
> # Purpose:
> #   - Normality
> #
> # What to Lo .... [TRUNCATED] 

> # Enhanced Histogram using ggplot2
> hist_plot <- ggplot(data.frame(Residuals = residuals), aes(x = Residuals)) +
+   geom_histogram(aes(y = ..densi .... [TRUNCATED] 

> # Display the ggplot2 histogram
> print(hist_plot)

> # Save the ggplot2 histogram if saving is enabled
> if (save_graphs) {
+   ggsave(filename = file.path(graph_save_dir, "Histogram_Residuals_GGPlot2. ..." ... [TRUNCATED] 
[1] "Saved ggplot2 Histogram of Residuals with Normal Curve."

> # Redirect output to the specified file and also print to console
> sink(output_file, append = TRUE, split = TRUE)

> print("")
[1] ""

> # ----------------------------#
> # 10. Statistical Tests
> # ----------------------------#
> 
> 
> # --------- Shapiro-Wilk Test for Normality ---- .... [TRUNCATED] 
[1] "-------- Shapiro-Wilk Test for Normality ---------"

> print("  - Normality: To check if the residuals are normally distributed.")
[1] "  - Normality: To check if the residuals are normally distributed."

> print("  - p-value > 0.05: Fail to reject null hypothesis (residuals are normally distributed).")
[1] "  - p-value > 0.05: Fail to reject null hypothesis (residuals are normally distributed)."

> print("  - p-value <= 0.05: Reject null hypothesis (residuals are not normally distributed).\n")
[1] "  - p-value <= 0.05: Reject null hypothesis (residuals are not normally distributed).\n"

> shapiro_test <- shapiro.test(residuals)

> print("Shapiro-Wilk Test Results:")
[1] "Shapiro-Wilk Test Results:"

> print(shapiro_test)

	Shapiro-Wilk normality test

data:  residuals
W = 0.98947, p-value = 0.7064


> # --------- Breusch-Pagan Test for Homoscedasticity ---------
> print("-------- Breusch-Pagan Test for Homoscedasticity ---------")
[1] "-------- Breusch-Pagan Test for Homoscedasticity ---------"

> print("  - Homoscedasticity: To check if residuals have constant variance across all levels of fitted values.")
[1] "  - Homoscedasticity: To check if residuals have constant variance across all levels of fitted values."

> print("  - p-value > 0.05: Fail to reject null hypothesis (homoscedasticity holds).")
[1] "  - p-value > 0.05: Fail to reject null hypothesis (homoscedasticity holds)."

> print("  - p-value <= 0.05: Reject null hypothesis (heteroscedasticity present).\n")
[1] "  - p-value <= 0.05: Reject null hypothesis (heteroscedasticity present).\n"

> # Extract the model frame from the ssn_lm model
> data_ssn <- model.frame(ssn_mod)

> # Perform Breusch-Pagan Test
> bp_test <- bptest(ssn_mod)

> print("Breusch-Pagan Test Results:")
[1] "Breusch-Pagan Test Results:"

> print(bp_test)

	studentized Breusch-Pagan test

data:  ssn_mod
BP = 18.948, df = 14, p-value = 0.1669


> # --------- Moran's I Test for Spatial Autocorrelation ---------
> print("\n-------- Moran's I Test for Spatial Autocorrelation ---------")
[1] "\n-------- Moran's I Test for Spatial Autocorrelation ---------"

> print("  - Spatial Autocorrelation: To determine if there is spatial autocorrelation in the residuals.")
[1] "  - Spatial Autocorrelation: To determine if there is spatial autocorrelation in the residuals."

> print("  - p-value > 0.05: Fail to reject null hypothesis (lack of spatial autocorrelation in residuals holds).")
[1] "  - p-value > 0.05: Fail to reject null hypothesis (lack of spatial autocorrelation in residuals holds)."

> print("  - p-value <= 0.05: Reject null hypothesis (spatial autocorrelation present).\n")
[1] "  - p-value <= 0.05: Reject null hypothesis (spatial autocorrelation present).\n"

> sink()

> # Extract spatial coordinates from the SSN object
> # Ensure that your SSN object has geometry information
> coords <- st_coordinates(ssn_get_data(s .... [TRUNCATED] 

> # Create a spatial weights matrix using k-nearest neighbors (k = 4 as an example)
> knn <- knearneigh(coords, k = 4)

> nb <- knn2nb(knn)

> lw <- nb2listw(nb, style = "W", zero.policy = TRUE)

> # Compute Moran's I
> moran_test <- moran.test(residuals, lw, zero.policy = TRUE)

> sink(output_file, append = TRUE, split = TRUE)

> print("Moran's I Test Results:")
[1] "Moran's I Test Results:"

> print(moran_test)

	Moran I test under randomisation

data:  residuals  
weights: lw    

Moran I statistic standard deviate = -2.0355, p-value = 0.9791
alternative hypothesis: greater
sample estimates:
Moran I statistic       Expectation          Variance 
      -0.15978020       -0.01149425        0.00530727 


> # Stop redirecting output
> sink()

> # --------------------------------------------------
> # End of Script
> # --------------------------------------------------
> 

> # --------------------------------------------------
> # Spatial Statistical Modeling with SSN2
> # ------------------------------------------------ .... [TRUNCATED] 

> # Specify the input and output directories
> input_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/Inputs"

> output_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/SSN ET/ET Lower error thresh"

> model_name <- "glm ch_sfm.erosion.norm Zuur VIF-3"

> obs_points_path <- file.path(input_dir, "Combined Watersheds", "ET Lower ssn points.gpkg")

> read_ssn <- FALSE # whether to create a new ssn (FALSE) or read the pre-existing ssn (TRUE)

> # Use file.path to create platform-independent file paths
> streams_path <- file.path(input_dir, "streams_100k.gpkg")

> ssn_path <- file.path(output_dir, "1_ET_Full_logtrans_independent_vars.ssn")

> output_file <- file.path(output_dir, model_name, "Results.txt")

> lsn_out <- file.path(output_dir, "0_lsn")

> # Define whether to save graphs and the directory to save them
> save_graphs <- TRUE  # Set to TRUE to save graphs as PNG

> graph_save_dir <- file.path(output_dir, model_name)  # Directory to save graphs

> # ----------------------------#
> # 1. Load Necessary Libraries
> # ----------------------------#
> 
> # Load required libraries
> library(SSN2)

> library(SSNbler)

> library(sf)

> library(dplyr)

> library(purrr)

> library(ggplot2)

> library(lmtest)

> library(spdep)

> library(classInt)   # Required for knearneigh

> library(broom)      # For tidy() and glance() functions

> library(grid)       # For grid.newpage()

> if (!dir.exists(graph_save_dir)) {
+   dir.create(graph_save_dir, recursive = TRUE)
+ }

> # ----------------------------#
> # 2. Read Spatial Data
> # ----------------------------#
> 
> # Read the streams dataset
> ET_streams <- st_read(s .... [TRUNCATED] 
Reading layer `streams_100k' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\streams_100k.gpkg' using driver `GPKG'
Simple feature collection with 643 features and 2 fields
Geometry type: LINESTRING
Dimension:     XY
Bounding box:  xmin: 404042.6 ymin: 4447904 xmax: 414579.6 ymax: 4466669
Projected CRS: NAD83 / UTM zone 13N

> # Read the observation points dataset
> ET_obs <- st_read(obs_points_path)
Reading layer `ET Lower ssn points' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\Combined Watersheds\ET Lower ssn points.gpkg' using driver `GPKG'
Simple feature collection with 161 features and 59 fields
Geometry type: POINT
Dimension:     XY
Bounding box:  xmin: 411939.2 ymin: 4449827 xmax: 413032.9 ymax: 4450878
Projected CRS: NAD83 / UTM zone 13N

> # Uncomment the following line if you encounter an error about Multilinestrings
> # ET_streams <- st_cast(ET_streams, "LINESTRING")
> 
> # --------- .... [TRUNCATED] 
[1] "Edge Attributes:"
[1] "rid"            "STRM_VAL"       "flow_accum_max" "Length"         "upDist"         "geometry"      
[1] "Site List Components:"
[1] "obs"
[1] "Updated Edge Attributes:"
[1] "rid"            "STRM_VAL"       "flow_accum_max" "Length"         "upDist"         "flow_accum_PI"  "afv_flow_accum" "geometry"      


SSN object is valid: TRUE

> # Create a distance matrix for spatial relationships
> # Purpose: Define spatial dependencies based on distances between sites
> ssn_create_distmat( .... [TRUNCATED] 

> # ----------------------------#
> # 4. Model Fitting and Output
> # ----------------------------#
> 
> # Redirect output to the specified file and a .... [TRUNCATED] 

> model_name
[1] "glm ch_sfm.erosion.norm Zuur VIF-3"

> model_formula
ch_sfm.erosion.norm ~ ch_flow.accumulation.max + ch_curvature.median + 
    ch_slope.downstream + ch_change.in.slope.over.width + ch_stream.power + 
    ch_channel.width.over.valley.width + ch_slope.over.width.central.diff + 
    hs_hillslope.length + hs_slope.median + hs_eastness.median + 
    hs_curvature.median + hs_ndvi.range + hs_dnbr.median + hs_drainage_densit

> ssn_mod <- ssn_glm(
+   formula = model_formula,
+   ssn.object = ET_ssn,
+   family = "Gamma",
+   tailup_type = "exponential",
+   taildown_type = .... [TRUNCATED] 

> # --------------------------------------------------
> # Spatial Statistical Modeling with SSN2
> # ------------------------------------------------ .... [TRUNCATED] 

> # Specify the input and output directories
> input_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/Inputs"

> output_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/SSN ET/ET Lower error thresh"

> model_name <- "glm ch_sfm.erosion.norm Zuur VIF-3"

> obs_points_path <- file.path(input_dir, "Combined Watersheds", "ET Lower ssn points.gpkg")

> read_ssn <- TRUE # whether to create a new ssn (FALSE) or read the pre-existing ssn (TRUE)

> # Use file.path to create platform-independent file paths
> streams_path <- file.path(input_dir, "streams_100k.gpkg")

> ssn_path <- file.path(output_dir, "1_ET_Full_logtrans_independent_vars.ssn")

> output_file <- file.path(output_dir, model_name, "Results.txt")

> lsn_out <- file.path(output_dir, "0_lsn")

> # Define whether to save graphs and the directory to save them
> save_graphs <- TRUE  # Set to TRUE to save graphs as PNG

> graph_save_dir <- file.path(output_dir, model_name)  # Directory to save graphs

> # ----------------------------#
> # 1. Load Necessary Libraries
> # ----------------------------#
> 
> # Load required libraries
> library(SSN2)

> library(SSNbler)

> library(sf)

> library(dplyr)

> library(purrr)

> library(ggplot2)

> library(lmtest)

> library(spdep)

> library(classInt)   # Required for knearneigh

> library(broom)      # For tidy() and glance() functions

> library(grid)       # For grid.newpage()

> if (!dir.exists(graph_save_dir)) {
+   dir.create(graph_save_dir, recursive = TRUE)
+ }

> # ----------------------------#
> # 2. Read Spatial Data
> # ----------------------------#
> 
> # Read the streams dataset
> ET_streams <- st_read(s .... [TRUNCATED] 
Reading layer `streams_100k' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\streams_100k.gpkg' using driver `GPKG'
Simple feature collection with 643 features and 2 fields
Geometry type: LINESTRING
Dimension:     XY
Bounding box:  xmin: 404042.6 ymin: 4447904 xmax: 414579.6 ymax: 4466669
Projected CRS: NAD83 / UTM zone 13N

> # Read the observation points dataset
> ET_obs <- st_read(obs_points_path)
Reading layer `ET Lower ssn points' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\Combined Watersheds\ET Lower ssn points.gpkg' using driver `GPKG'
Simple feature collection with 161 features and 59 fields
Geometry type: POINT
Dimension:     XY
Bounding box:  xmin: 411939.2 ymin: 4449827 xmax: 413032.9 ymax: 4450878
Projected CRS: NAD83 / UTM zone 13N

> # Uncomment the following line if you encounter an error about Multilinestrings
> # ET_streams <- st_cast(ET_streams, "LINESTRING")
> 
> # --------- .... [TRUNCATED] 

> # Create a distance matrix for spatial relationships
> # Purpose: Define spatial dependencies based on distances between sites
> ssn_create_distmat( .... [TRUNCATED] 

> # ----------------------------#
> # 4. Model Fitting and Output
> # ----------------------------#
> 
> # Redirect output to the specified file and a .... [TRUNCATED] 

> model_name
[1] "glm ch_sfm.erosion.norm Zuur VIF-3"

> model_formula
ch_sfm.erosion.norm ~ ch_flow.accumulation.max + ch_curvature.median + 
    ch_slope.downstream + ch_change.in.slope.over.width + ch_stream.power + 
    ch_channel.width.over.valley.width + ch_slope.over.width.central.diff + 
    hs_hillslope.length + hs_slope.median + hs_eastness.median + 
    hs_curvature.median + hs_ndvi.range + hs_dnbr.median + hs_drainage_density

> ssn_mod <- ssn_glm(
+   formula = model_formula,
+   ssn.object = ET_ssn,
+   family = "Gamma",
+   tailup_type = "exponential",
+   taildown_type = .... [TRUNCATED] 

> # Print the summary of the model to the file and console
> print(summary(ssn_mod))

Call:
ssn_glm(formula = model_formula, ssn.object = ET_ssn, family = "Gamma", 
    tailup_type = "exponential", taildown_type = "none", euclid_type = "gaussian", 
    additive = "afv_flow_accum")

Deviance Residuals:
    Min      1Q  Median      3Q     Max 
-2.0811 -0.5776 -0.0768  0.2978  1.3314 

Coefficients (fixed):
                                   Estimate Std. Error z value Pr(>|z|)    
(Intercept)                        -1.59829    0.48117  -3.322 0.000895 ***
ch_flow.accumulation.max            1.85356    0.75399   2.458 0.013959 *  
ch_curvature.median                 0.16848    0.10868   1.550 0.121082    
ch_slope.downstream                 0.12197    0.22849   0.534 0.593471    
ch_change.in.slope.over.width      -0.08809    0.04524  -1.947 0.051519 .  
ch_stream.power                     0.53142    0.17982   2.955 0.003123 ** 
ch_channel.width.over.valley.width  0.38538    0.16780   2.297 0.021641 *  
ch_slope.over.width.central.diff    0.11806    0.05378   2.195 0.028159 *  
hs_hillslope.length                -0.12949    0.14934  -0.867 0.385872    
hs_slope.median                     0.03533    0.12870   0.274 0.783704    
hs_eastness.median                 -0.31197    0.15009  -2.079 0.037661 *  
hs_curvature.median                -0.02904    0.09177  -0.316 0.751688    
hs_ndvi.range                      -0.07783    0.16698  -0.466 0.641151    
hs_dnbr.median                     -0.46406    0.22077  -2.102 0.035549 *  
hs_drainage_density                20.81268   44.66568   0.466 0.641240    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Pseudo R-squared: 0.1246

Coefficients (covariance):
              Effect     Parameter   Estimate
  tailup exponential  de (parsill)  1.563e-01
  tailup exponential         range  1.212e+03
     euclid gaussian  de (parsill)  1.014e+00
     euclid gaussian         range  7.222e+01
              nugget        nugget  3.572e-02
          dispersion    dispersion  2.153e+00


> # Print variance components of the model
> varcomp(ssn_mod)
# A tibble: 5 × 2
  varcomp            proportion
  <chr>                   <dbl>
1 Covariates (PR-sq)     0.125 
2 tailup_de              0.113 
3 taildown_de            0     
4 euclid_de              0.736 
5 nugget                 0.0259

> # Tidy the model output with confidence intervals and print
> print(tidy(ssn_mod, conf.int = TRUE))  
# A tibble: 15 × 7
   term                               estimate std.error statistic  p.value conf.low  conf.high
   <chr>                                 <dbl>     <dbl>     <dbl>    <dbl>    <dbl>      <dbl>
 1 (Intercept)                         -1.60      0.481     -3.32  0.000895  -2.54    -0.655   
 2 ch_change.in.slope.over.width       -0.0881    0.0452    -1.95  0.0515    -0.177    0.000581
 3 ch_channel.width.over.valley.width   0.385     0.168      2.30  0.0216     0.0565   0.714   
 4 ch_curvature.median                  0.168     0.109      1.55  0.121     -0.0445   0.381   
 5 ch_flow.accumulation.max             1.85      0.754      2.46  0.0140     0.376    3.33    
 6 ch_slope.downstream                  0.122     0.228      0.534 0.593     -0.326    0.570   
 7 ch_slope.over.width.central.diff     0.118     0.0538     2.20  0.0282     0.0126   0.223   
 8 ch_stream.power                      0.531     0.180      2.96  0.00312    0.179    0.884   
 9 hs_curvature.median                 -0.0290    0.0918    -0.316 0.752     -0.209    0.151   
10 hs_dnbr.median                      -0.464     0.221     -2.10  0.0355    -0.897   -0.0314  
11 hs_drainage_density                 20.8      44.7        0.466 0.641    -66.7    108.      
12 hs_eastness.median                  -0.312     0.150     -2.08  0.0377    -0.606   -0.0178  
13 hs_hillslope.length                 -0.129     0.149     -0.867 0.386     -0.422    0.163   
14 hs_ndvi.range                       -0.0778    0.167     -0.466 0.641     -0.405    0.249   
15 hs_slope.median                      0.0353    0.129      0.274 0.784     -0.217    0.288   

> # Provide a glance summary of the model and print
> print(glance(ssn_mod))
# A tibble: 1 × 9
      n     p  npar value   AIC  AICc logLik deviance pseudo.r.squared
  <int> <dbl> <int> <dbl> <dbl> <dbl>  <dbl>    <dbl>            <dbl>
1   161    15     6  425.  437.  438.  -212.     59.3            0.125

> # Perform Leave-One-Out Cross Validation and print
> print("Leave One Out Cross Validation")
[1] "Leave One Out Cross Validation"

> loocv_results <- loocv(ssn_mod)

> print(loocv_results)
# A tibble: 1 × 4
     bias  MSPE RMSPE   RAV
    <dbl> <dbl> <dbl> <dbl>
1 -0.0429 0.263 0.512 0.315

> # Stop redirecting output
> sink()

> # ----------------------------#
> # 5. Model Evaluation
> # ----------------------------#
> 
> # Extract residuals and fitted values from the model
 .... [TRUNCATED] 

> fitted_values <- fitted(ssn_mod)   

> # ----------------------------#
> # 6. Plotting and Saving Graphs
> # ----------------------------#
> 
> 
> # Create the graph save directory if sav .... [TRUNCATED] 

> # ----------------------------#
> # 7. Residuals vs Fitted Values Plot
> # ----------------------------#
> 
> # Purpose:
> #   - Linearity: Ensure t .... [TRUNCATED] 

> # Create the Residuals vs Fitted Values plot
> resid_fitted_plot <- ggplot(data.frame(Fitted = fitted_values, Residuals = residuals), aes(x = Fitted .... [TRUNCATED] 

> # Display the plot
> print(resid_fitted_plot)

> # Save the plot if saving is enabled
> if (save_graphs) {
+   ggsave(filename = file.path(graph_save_dir, "Residuals_vs_Fitted.png"), plot = resid_f .... [TRUNCATED] 
[1] "Saved Residuals vs Fitted Values plot."

> # ----------------------------#
> # 8. Q-Q Plot for Residuals
> # ----------------------------#
> 
> # Purpose:
> #   - Normality: Verify that resid .... [TRUNCATED] 

> # Enhanced Q-Q Plot using ggplot2
> qq_plot <- ggplot(data.frame(Residuals = residuals), aes(sample = Residuals)) +
+   stat_qq(color = "blue") +
+  .... [TRUNCATED] 

> # Display the ggplot2 Q-Q plot
> print(qq_plot)

> # Save the ggplot2 Q-Q plot if saving is enabled
> if (save_graphs) {
+   ggsave(filename = file.path(graph_save_dir, "QQ_Plot_Residuals_GGPlot2.png ..." ... [TRUNCATED] 
[1] "Saved ggplot2 Q-Q Plot of Residuals."

> # ----------------------------#
> # 9. Histogram of Residuals
> # ----------------------------#
> 
> # Purpose:
> #   - Normality
> #
> # What to Lo .... [TRUNCATED] 

> # Enhanced Histogram using ggplot2
> hist_plot <- ggplot(data.frame(Residuals = residuals), aes(x = Residuals)) +
+   geom_histogram(aes(y = ..densi .... [TRUNCATED] 

> # Display the ggplot2 histogram
> print(hist_plot)

> # Save the ggplot2 histogram if saving is enabled
> if (save_graphs) {
+   ggsave(filename = file.path(graph_save_dir, "Histogram_Residuals_GGPlot2. ..." ... [TRUNCATED] 
[1] "Saved ggplot2 Histogram of Residuals with Normal Curve."

> # Redirect output to the specified file and also print to console
> sink(output_file, append = TRUE, split = TRUE)

> print("")
[1] ""

> # ----------------------------#
> # 10. Statistical Tests
> # ----------------------------#
> 
> 
> # --------- Shapiro-Wilk Test for Normality ---- .... [TRUNCATED] 
[1] "-------- Shapiro-Wilk Test for Normality ---------"

> print("  - Normality: To check if the residuals are normally distributed.")
[1] "  - Normality: To check if the residuals are normally distributed."

> print("  - p-value > 0.05: Fail to reject null hypothesis (residuals are normally distributed).")
[1] "  - p-value > 0.05: Fail to reject null hypothesis (residuals are normally distributed)."

> print("  - p-value <= 0.05: Reject null hypothesis (residuals are not normally distributed).\n")
[1] "  - p-value <= 0.05: Reject null hypothesis (residuals are not normally distributed).\n"

> shapiro_test <- shapiro.test(residuals)

> print("Shapiro-Wilk Test Results:")
[1] "Shapiro-Wilk Test Results:"

> print(shapiro_test)

	Shapiro-Wilk normality test

data:  residuals
W = 0.98967, p-value = 0.2887


> # --------- Breusch-Pagan Test for Homoscedasticity ---------
> print("-------- Breusch-Pagan Test for Homoscedasticity ---------")
[1] "-------- Breusch-Pagan Test for Homoscedasticity ---------"

> print("  - Homoscedasticity: To check if residuals have constant variance across all levels of fitted values.")
[1] "  - Homoscedasticity: To check if residuals have constant variance across all levels of fitted values."

> print("  - p-value > 0.05: Fail to reject null hypothesis (homoscedasticity holds).")
[1] "  - p-value > 0.05: Fail to reject null hypothesis (homoscedasticity holds)."

> print("  - p-value <= 0.05: Reject null hypothesis (heteroscedasticity present).\n")
[1] "  - p-value <= 0.05: Reject null hypothesis (heteroscedasticity present).\n"

> # Extract the model frame from the ssn_lm model
> data_ssn <- model.frame(ssn_mod)

> # Perform Breusch-Pagan Test
> bp_test <- bptest(ssn_mod)

> print("Breusch-Pagan Test Results:")
[1] "Breusch-Pagan Test Results:"

> print(bp_test)

	studentized Breusch-Pagan test

data:  ssn_mod
BP = 33.714, df = 14, p-value = 0.00227


> # --------- Moran's I Test for Spatial Autocorrelation ---------
> print("\n-------- Moran's I Test for Spatial Autocorrelation ---------")
[1] "\n-------- Moran's I Test for Spatial Autocorrelation ---------"

> print("  - Spatial Autocorrelation: To determine if there is spatial autocorrelation in the residuals.")
[1] "  - Spatial Autocorrelation: To determine if there is spatial autocorrelation in the residuals."

> print("  - p-value > 0.05: Fail to reject null hypothesis (lack of spatial autocorrelation in residuals holds).")
[1] "  - p-value > 0.05: Fail to reject null hypothesis (lack of spatial autocorrelation in residuals holds)."

> print("  - p-value <= 0.05: Reject null hypothesis (spatial autocorrelation present).\n")
[1] "  - p-value <= 0.05: Reject null hypothesis (spatial autocorrelation present).\n"

> sink()

> # Extract spatial coordinates from the SSN object
> # Ensure that your SSN object has geometry information
> coords <- st_coordinates(ssn_get_data(s .... [TRUNCATED] 

> # Create a spatial weights matrix using k-nearest neighbors (k = 4 as an example)
> knn <- knearneigh(coords, k = 4)

> nb <- knn2nb(knn)

> lw <- nb2listw(nb, style = "W", zero.policy = TRUE)

> # Compute Moran's I
> moran_test <- moran.test(residuals, lw, zero.policy = TRUE)

> sink(output_file, append = TRUE, split = TRUE)

> print("Moran's I Test Results:")
[1] "Moran's I Test Results:"

> print(moran_test)

	Moran I test under randomisation

data:  residuals  
weights: lw    

Moran I statistic standard deviate = -2.2623, p-value = 0.9882
alternative hypothesis: greater
sample estimates:
Moran I statistic       Expectation          Variance 
     -0.129614935      -0.006250000       0.002973482 


> # Stop redirecting output
> sink()

> # --------------------------------------------------
> # End of Script
> # --------------------------------------------------
> 

> # --------------------------------------------------
> # Spatial Statistical Modeling with SSN2
> # ------------------------------------------------ .... [TRUNCATED] 

> # Specify the input and output directories
> input_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/Inputs"

> output_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/SSN ET/ET Lower error thresh"

> model_name <- "glm ch_sfm.erosion.norm ~ ch_flow.accumulation.max corr07"

> obs_points_path <- file.path(input_dir, "Combined Watersheds", "ET Lower ssn points.gpkg")

> read_ssn <- TRUE # whether to create a new ssn (FALSE) or read the pre-existing ssn (TRUE)

> # Use file.path to create platform-independent file paths
> streams_path <- file.path(input_dir, "streams_100k.gpkg")

> ssn_path <- file.path(output_dir, "1_ET_Full_logtrans_independent_vars.ssn")

> output_file <- file.path(output_dir, model_name, "Results.txt")

> lsn_out <- file.path(output_dir, "0_lsn")

> # Define whether to save graphs and the directory to save them
> save_graphs <- TRUE  # Set to TRUE to save graphs as PNG

> graph_save_dir <- file.path(output_dir, model_name)  # Directory to save graphs

> # ----------------------------#
> # 1. Load Necessary Libraries
> # ----------------------------#
> 
> # Load required libraries
> library(SSN2)

> library(SSNbler)

> library(sf)

> library(dplyr)

> library(purrr)

> library(ggplot2)

> library(lmtest)

> library(spdep)

> library(classInt)   # Required for knearneigh

> library(broom)      # For tidy() and glance() functions

> library(grid)       # For grid.newpage()

> if (!dir.exists(graph_save_dir)) {
+   dir.create(graph_save_dir, recursive = TRUE)
+ }

> # ----------------------------#
> # 2. Read Spatial Data
> # ----------------------------#
> 
> # Read the streams dataset
> ET_streams <- st_read(s .... [TRUNCATED] 
Reading layer `streams_100k' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\streams_100k.gpkg' using driver `GPKG'
Simple feature collection with 643 features and 2 fields
Geometry type: LINESTRING
Dimension:     XY
Bounding box:  xmin: 404042.6 ymin: 4447904 xmax: 414579.6 ymax: 4466669
Projected CRS: NAD83 / UTM zone 13N

> # Read the observation points dataset
> ET_obs <- st_read(obs_points_path)
Reading layer `ET Lower ssn points' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\Combined Watersheds\ET Lower ssn points.gpkg' using driver `GPKG'
Simple feature collection with 161 features and 59 fields
Geometry type: POINT
Dimension:     XY
Bounding box:  xmin: 411939.2 ymin: 4449827 xmax: 413032.9 ymax: 4450878
Projected CRS: NAD83 / UTM zone 13N

> # Uncomment the following line if you encounter an error about Multilinestrings
> # ET_streams <- st_cast(ET_streams, "LINESTRING")
> 
> # --------- .... [TRUNCATED] 

> # Create a distance matrix for spatial relationships
> # Purpose: Define spatial dependencies based on distances between sites
> ssn_create_distmat( .... [TRUNCATED] 

> # ----------------------------#
> # 4. Model Fitting and Output
> # ----------------------------#
> 
> # Redirect output to the specified file and a .... [TRUNCATED] 

> model_name
[1] "glm ch_sfm.erosion.norm ~ ch_flow.accumulation.max corr07"

> model_formula
ch_sfm.erosion.norm ~ ch_flow.accumulation.max + ch_stream.power + 
    hs_hillslope.length + ch_channel.width.over.valley.width + 
    hs_curvature.median + ch_curvature.median + ch_valley_width + 
    ws_dnbr.mean + hs_slope.median + hs_northness.median + ws_bare.earth.mean + 
    ch_slope.median + hs_dnbr.median + hs_ndvi.mean + ch_slope.over.width.central.diff + 
    ch_elevation.mean + hs_eastness.median + ch_change.in.slope.over.width

> ssn_mod <- ssn_glm(
+   formula = model_formula,
+   ssn.object = ET_ssn,
+   family = "Gamma",
+   tailup_type = "exponential",
+   taildown_type = .... [TRUNCATED] 

> # Print the summary of the model to the file and console
> print(summary(ssn_mod))

Call:
ssn_glm(formula = model_formula, ssn.object = ET_ssn, family = "Gamma", 
    tailup_type = "exponential", taildown_type = "none", euclid_type = "gaussian", 
    additive = "afv_flow_accum")

Deviance Residuals:
     Min       1Q   Median       3Q      Max 
-1.65695 -0.45107 -0.05094  0.28315  1.10339 

Coefficients (fixed):
                                    Estimate Std. Error z value Pr(>|z|)   
(Intercept)                        -1.814118   0.644045  -2.817  0.00485 **
ch_flow.accumulation.max            2.268671   1.456026   1.558  0.11920   
ch_stream.power                     0.689306   0.354106   1.947  0.05158 . 
hs_hillslope.length                -0.217915   0.157722  -1.382  0.16708   
ch_channel.width.over.valley.width  0.536461   0.270706   1.982  0.04751 * 
hs_curvature.median                 0.008951   0.098195   0.091  0.92737   
ch_curvature.median                 0.150670   0.116110   1.298  0.19441   
ch_valley_width                     0.293049   0.297683   0.984  0.32490   
ws_dnbr.mean                        0.041431   0.590942   0.070  0.94411   
hs_slope.median                    -0.016868   0.131219  -0.129  0.89772   
hs_northness.median                -0.248826   0.312721  -0.796  0.42622   
ws_bare.earth.mean                  0.081265   0.455378   0.178  0.85837   
ch_slope.median                    -0.049439   0.319838  -0.155  0.87716   
hs_dnbr.median                     -0.483923   0.259262  -1.867  0.06197 . 
hs_ndvi.mean                       -0.099750   0.198099  -0.504  0.61459   
ch_slope.over.width.central.diff    0.117029   0.054053   2.165  0.03038 * 
ch_elevation.mean                   1.028720   0.817877   1.258  0.20847   
hs_eastness.median                 -0.498167   0.205054  -2.429  0.01512 * 
ch_change.in.slope.over.width      -0.075748   0.038595  -1.963  0.04969 * 
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Pseudo R-squared: 0.1462

Coefficients (covariance):
              Effect     Parameter  Estimate
  tailup exponential  de (parsill)   0.32619
  tailup exponential         range  58.66642
     euclid gaussian  de (parsill)   1.13910
     euclid gaussian         range  81.05794
              nugget        nugget   0.01608
          dispersion    dispersion   2.35749


> # Print variance components of the model
> varcomp(ssn_mod)
# A tibble: 5 × 2
  varcomp            proportion
  <chr>                   <dbl>
1 Covariates (PR-sq)    0.146  
2 tailup_de             0.188  
3 taildown_de           0      
4 euclid_de             0.657  
5 nugget                0.00927

> # Tidy the model output with confidence intervals and print
> print(tidy(ssn_mod, conf.int = TRUE))  
# A tibble: 19 × 7
   term                               estimate std.error statistic p.value conf.low conf.high
   <chr>                                 <dbl>     <dbl>     <dbl>   <dbl>    <dbl>     <dbl>
 1 (Intercept)                        -1.81       0.644    -2.82   0.00485 -3.08    -0.552   
 2 ch_change.in.slope.over.width      -0.0757     0.0386   -1.96   0.0497  -0.151   -0.000102
 3 ch_channel.width.over.valley.width  0.536      0.271     1.98   0.0475   0.00589  1.07    
 4 ch_curvature.median                 0.151      0.116     1.30   0.194   -0.0769   0.378   
 5 ch_elevation.mean                   1.03       0.818     1.26   0.208   -0.574    2.63    
 6 ch_flow.accumulation.max            2.27       1.46      1.56   0.119   -0.585    5.12    
 7 ch_slope.median                    -0.0494     0.320    -0.155  0.877   -0.676    0.577   
 8 ch_slope.over.width.central.diff    0.117      0.0541    2.17   0.0304   0.0111   0.223   
 9 ch_stream.power                     0.689      0.354     1.95   0.0516  -0.00473  1.38    
10 ch_valley_width                     0.293      0.298     0.984  0.325   -0.290    0.876   
11 hs_curvature.median                 0.00895    0.0982    0.0912 0.927   -0.184    0.201   
12 hs_dnbr.median                     -0.484      0.259    -1.87   0.0620  -0.992    0.0242  
13 hs_eastness.median                 -0.498      0.205    -2.43   0.0151  -0.900   -0.0963  
14 hs_hillslope.length                -0.218      0.158    -1.38   0.167   -0.527    0.0912  
15 hs_ndvi.mean                       -0.0998     0.198    -0.504  0.615   -0.488    0.289   
16 hs_northness.median                -0.249      0.313    -0.796  0.426   -0.862    0.364   
17 hs_slope.median                    -0.0169     0.131    -0.129  0.898   -0.274    0.240   
18 ws_bare.earth.mean                  0.0813     0.455     0.178  0.858   -0.811    0.974   
19 ws_dnbr.mean                        0.0414     0.591     0.0701 0.944   -1.12     1.20    

> # Provide a glance summary of the model and print
> print(glance(ssn_mod))
# A tibble: 1 × 9
      n     p  npar value   AIC  AICc logLik deviance pseudo.r.squared
  <int> <dbl> <int> <dbl> <dbl> <dbl>  <dbl>    <dbl>            <dbl>
1   161    19     6  430.  442.  442.  -215.     46.4            0.146

> # Perform Leave-One-Out Cross Validation and print
> print("Leave One Out Cross Validation")
[1] "Leave One Out Cross Validation"

> loocv_results <- loocv(ssn_mod)

> print(loocv_results)
# A tibble: 1 × 4
     bias  MSPE RMSPE   RAV
    <dbl> <dbl> <dbl> <dbl>
1 -0.0576 0.233 0.483 0.413

> # Stop redirecting output
> sink()

> # ----------------------------#
> # 5. Model Evaluation
> # ----------------------------#
> 
> # Extract residuals and fitted values from the model
 .... [TRUNCATED] 

> fitted_values <- fitted(ssn_mod)   

> # ----------------------------#
> # 6. Plotting and Saving Graphs
> # ----------------------------#
> 
> 
> # Create the graph save directory if sav .... [TRUNCATED] 

> # ----------------------------#
> # 7. Residuals vs Fitted Values Plot
> # ----------------------------#
> 
> # Purpose:
> #   - Linearity: Ensure t .... [TRUNCATED] 

> # Create the Residuals vs Fitted Values plot
> resid_fitted_plot <- ggplot(data.frame(Fitted = fitted_values, Residuals = residuals), aes(x = Fitted .... [TRUNCATED] 

> # Display the plot
> print(resid_fitted_plot)

> # Save the plot if saving is enabled
> if (save_graphs) {
+   ggsave(filename = file.path(graph_save_dir, "Residuals_vs_Fitted.png"), plot = resid_f .... [TRUNCATED] 
[1] "Saved Residuals vs Fitted Values plot."

> # ----------------------------#
> # 8. Q-Q Plot for Residuals
> # ----------------------------#
> 
> # Purpose:
> #   - Normality: Verify that resid .... [TRUNCATED] 

> # Enhanced Q-Q Plot using ggplot2
> qq_plot <- ggplot(data.frame(Residuals = residuals), aes(sample = Residuals)) +
+   stat_qq(color = "blue") +
+  .... [TRUNCATED] 

> # Display the ggplot2 Q-Q plot
> print(qq_plot)

> # Save the ggplot2 Q-Q plot if saving is enabled
> if (save_graphs) {
+   ggsave(filename = file.path(graph_save_dir, "QQ_Plot_Residuals_GGPlot2.png ..." ... [TRUNCATED] 
[1] "Saved ggplot2 Q-Q Plot of Residuals."

> # ----------------------------#
> # 9. Histogram of Residuals
> # ----------------------------#
> 
> # Purpose:
> #   - Normality
> #
> # What to Lo .... [TRUNCATED] 

> # Enhanced Histogram using ggplot2
> hist_plot <- ggplot(data.frame(Residuals = residuals), aes(x = Residuals)) +
+   geom_histogram(aes(y = ..densi .... [TRUNCATED] 

> # Display the ggplot2 histogram
> print(hist_plot)

> # Save the ggplot2 histogram if saving is enabled
> if (save_graphs) {
+   ggsave(filename = file.path(graph_save_dir, "Histogram_Residuals_GGPlot2. ..." ... [TRUNCATED] 
[1] "Saved ggplot2 Histogram of Residuals with Normal Curve."

> # Redirect output to the specified file and also print to console
> sink(output_file, append = TRUE, split = TRUE)

> print("")
[1] ""

> # ----------------------------#
> # 10. Statistical Tests
> # ----------------------------#
> 
> 
> # --------- Shapiro-Wilk Test for Normality ---- .... [TRUNCATED] 
[1] "-------- Shapiro-Wilk Test for Normality ---------"

> print("  - Normality: To check if the residuals are normally distributed.")
[1] "  - Normality: To check if the residuals are normally distributed."

> print("  - p-value > 0.05: Fail to reject null hypothesis (residuals are normally distributed).")
[1] "  - p-value > 0.05: Fail to reject null hypothesis (residuals are normally distributed)."

> print("  - p-value <= 0.05: Reject null hypothesis (residuals are not normally distributed).\n")
[1] "  - p-value <= 0.05: Reject null hypothesis (residuals are not normally distributed).\n"

> shapiro_test <- shapiro.test(residuals)

> print("Shapiro-Wilk Test Results:")
[1] "Shapiro-Wilk Test Results:"

> print(shapiro_test)

	Shapiro-Wilk normality test

data:  residuals
W = 0.98701, p-value = 0.1405


> # --------- Breusch-Pagan Test for Homoscedasticity ---------
> print("-------- Breusch-Pagan Test for Homoscedasticity ---------")
[1] "-------- Breusch-Pagan Test for Homoscedasticity ---------"

> print("  - Homoscedasticity: To check if residuals have constant variance across all levels of fitted values.")
[1] "  - Homoscedasticity: To check if residuals have constant variance across all levels of fitted values."

> print("  - p-value > 0.05: Fail to reject null hypothesis (homoscedasticity holds).")
[1] "  - p-value > 0.05: Fail to reject null hypothesis (homoscedasticity holds)."

> print("  - p-value <= 0.05: Reject null hypothesis (heteroscedasticity present).\n")
[1] "  - p-value <= 0.05: Reject null hypothesis (heteroscedasticity present).\n"

> # Extract the model frame from the ssn_lm model
> data_ssn <- model.frame(ssn_mod)

> # Perform Breusch-Pagan Test
> bp_test <- bptest(ssn_mod)

> print("Breusch-Pagan Test Results:")
[1] "Breusch-Pagan Test Results:"

> print(bp_test)

	studentized Breusch-Pagan test

data:  ssn_mod
BP = 38.676, df = 18, p-value = 0.003149


> # --------- Moran's I Test for Spatial Autocorrelation ---------
> print("\n-------- Moran's I Test for Spatial Autocorrelation ---------")
[1] "\n-------- Moran's I Test for Spatial Autocorrelation ---------"

> print("  - Spatial Autocorrelation: To determine if there is spatial autocorrelation in the residuals.")
[1] "  - Spatial Autocorrelation: To determine if there is spatial autocorrelation in the residuals."

> print("  - p-value > 0.05: Fail to reject null hypothesis (lack of spatial autocorrelation in residuals holds).")
[1] "  - p-value > 0.05: Fail to reject null hypothesis (lack of spatial autocorrelation in residuals holds)."

> print("  - p-value <= 0.05: Reject null hypothesis (spatial autocorrelation present).\n")
[1] "  - p-value <= 0.05: Reject null hypothesis (spatial autocorrelation present).\n"

> sink()

> # Extract spatial coordinates from the SSN object
> # Ensure that your SSN object has geometry information
> coords <- st_coordinates(ssn_get_data(s .... [TRUNCATED] 

> # Create a spatial weights matrix using k-nearest neighbors (k = 4 as an example)
> knn <- knearneigh(coords, k = 4)

> nb <- knn2nb(knn)

> lw <- nb2listw(nb, style = "W", zero.policy = TRUE)

> # Compute Moran's I
> moran_test <- moran.test(residuals, lw, zero.policy = TRUE)

> sink(output_file, append = TRUE, split = TRUE)

> print("Moran's I Test Results:")
[1] "Moran's I Test Results:"

> print(moran_test)

	Moran I test under randomisation

data:  residuals  
weights: lw    

Moran I statistic standard deviate = -3.273, p-value = 0.9995
alternative hypothesis: greater
sample estimates:
Moran I statistic       Expectation          Variance 
     -0.184844335      -0.006250000       0.002977373 


> # Stop redirecting output
> sink()

> # --------------------------------------------------
> # End of Script
> # --------------------------------------------------
> 

> # --------------------------------------------------
> # Spatial Statistical Modeling with SSN2
> # ------------------------------------------------ .... [TRUNCATED] 

> # Specify the input and output directories
> input_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/Inputs"

> output_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/SSN ET/ET Lower error thresh"

> model_name <- "glm ch_sfm.erosion.norm VIF 3 100ct thresh"

> obs_points_path <- file.path(input_dir, "Combined Watersheds", "ET Lower ssn points.gpkg")

> read_ssn <- FALSE # whether to create a new ssn (FALSE) or read the pre-existing ssn (TRUE)

> # Use file.path to create platform-independent file paths
> streams_path <- file.path(input_dir, "streams_100k.gpkg")

> ssn_path <- file.path(output_dir, "1_ET_Full_logtrans_independent_vars.ssn")

> output_file <- file.path(output_dir, model_name, "Results.txt")

> lsn_out <- file.path(output_dir, "0_lsn")

> # Define whether to save graphs and the directory to save them
> save_graphs <- TRUE  # Set to TRUE to save graphs as PNG

> graph_save_dir <- file.path(output_dir, model_name)  # Directory to save graphs

> # ----------------------------#
> # 1. Load Necessary Libraries
> # ----------------------------#
> 
> # Load required libraries
> library(SSN2)

> library(SSNbler)

> library(sf)

> library(dplyr)

> library(purrr)

> library(ggplot2)

> library(lmtest)

> library(spdep)

> library(classInt)   # Required for knearneigh

> library(broom)      # For tidy() and glance() functions

> library(grid)       # For grid.newpage()

> if (!dir.exists(graph_save_dir)) {
+   dir.create(graph_save_dir, recursive = TRUE)
+ }

> # ----------------------------#
> # 2. Read Spatial Data
> # ----------------------------#
> 
> # Read the streams dataset
> ET_streams <- st_read(s .... [TRUNCATED] 
Reading layer `streams_100k' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\streams_100k.gpkg' using driver `GPKG'
Simple feature collection with 643 features and 2 fields
Geometry type: LINESTRING
Dimension:     XY
Bounding box:  xmin: 404042.6 ymin: 4447904 xmax: 414579.6 ymax: 4466669
Projected CRS: NAD83 / UTM zone 13N

> # Read the observation points dataset
> ET_obs <- st_read(obs_points_path)
Reading layer `ET Lower ssn points' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\Combined Watersheds\ET Lower ssn points.gpkg' using driver `GPKG'
Simple feature collection with 107 features and 59 fields
Geometry type: POINT
Dimension:     XY
Bounding box:  xmin: 411943.5 ymin: 4449827 xmax: 412955.4 ymax: 4450878
Projected CRS: NAD83 / UTM zone 13N

> # Uncomment the following line if you encounter an error about Multilinestrings
> # ET_streams <- st_cast(ET_streams, "LINESTRING")
> 
> # --------- .... [TRUNCATED] 
[1] "Edge Attributes:"
[1] "rid"            "STRM_VAL"       "flow_accum_max" "Length"         "upDist"         "geometry"      
[1] "Site List Components:"
[1] "obs"
[1] "Updated Edge Attributes:"
[1] "rid"            "STRM_VAL"       "flow_accum_max" "Length"         "upDist"         "flow_accum_PI"  "afv_flow_accum" "geometry"      


SSN object is valid: TRUE

> # Create a distance matrix for spatial relationships
> # Purpose: Define spatial dependencies based on distances between sites
> ssn_create_distmat( .... [TRUNCATED] 

> # ----------------------------#
> # 4. Model Fitting and Output
> # ----------------------------#
> 
> # Redirect output to the specified file and a .... [TRUNCATED] 

> model_name
[1] "glm ch_sfm.erosion.norm VIF 3 100ct thresh"

> model_formula
ch_sfm.erosion.norm ~ ch_slope.median + ch_flow.accumulation.max + 
    ch_curvature.median + ch_channel_width + ch_change.in.slope.over.width + 
    ch_channel.width.over.valley.width + ch_slope.over.width.central.diff + 
    hs_area + hs_slope.median + hs_eastness.median + hs_curvature.median + 
    hs_ndvi.range + hs_dnbr.median + hs_drainage_density

> ssn_mod <- ssn_glm(
+   formula = model_formula,
+   ssn.object = ET_ssn,
+   family = "Gamma",
+   tailup_type = "exponential",
+   taildown_type = .... [TRUNCATED] 

> # Print the summary of the model to the file and console
> print(summary(ssn_mod))

Call:
ssn_glm(formula = model_formula, ssn.object = ET_ssn, family = "Gamma", 
    tailup_type = "exponential", taildown_type = "none", euclid_type = "gaussian", 
    additive = "afv_flow_accum")

Deviance Residuals:
       Min         1Q     Median         3Q        Max 
-2.311e-03 -7.081e-04  3.821e-05  6.401e-04  2.403e-03 

Coefficients (fixed):
                                     Estimate Std. Error z value Pr(>|z|)    
(Intercept)                          0.079275   0.134372   0.590   0.5552    
ch_slope.median                      0.162290   0.136543   1.189   0.2346    
ch_flow.accumulation.max             1.372506   0.239731   5.725 1.03e-08 ***
ch_curvature.median                  0.174952   0.108718   1.609   0.1076    
ch_channel_width                    -0.603617   0.130405  -4.629 3.68e-06 ***
ch_change.in.slope.over.width        0.022200   0.082848   0.268   0.7887    
ch_channel.width.over.valley.width   0.211821   0.163054   1.299   0.1939    
ch_slope.over.width.central.diff     0.053927   0.076372   0.706   0.4801    
hs_area                             -0.001325   0.111872  -0.012   0.9905    
hs_slope.median                     -0.165978   0.106744  -1.555   0.1200    
hs_eastness.median                  -0.130313   0.137579  -0.947   0.3435    
hs_curvature.median                  0.031254   0.101434   0.308   0.7580    
hs_ndvi.range                        0.058051   0.145873   0.398   0.6907    
hs_dnbr.median                      -0.409874   0.185672  -2.208   0.0273 *  
hs_drainage_density                -18.497266  43.952175  -0.421   0.6739    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Pseudo R-squared: 0.2742

Coefficients (covariance):
              Effect     Parameter   Estimate
  tailup exponential  de (parsill)  5.416e-01
  tailup exponential         range  1.104e+01
     euclid gaussian  de (parsill)  1.199e-03
     euclid gaussian         range  1.580e+18
              nugget        nugget  6.702e-19
          dispersion    dispersion  1.473e+03


> # Print variance components of the model
> varcomp(ssn_mod)
# A tibble: 5 × 2
  varcomp            proportion
  <chr>                   <dbl>
1 Covariates (PR-sq)   2.74e- 1
2 tailup_de            7.24e- 1
3 taildown_de          0       
4 euclid_de            1.60e- 3
5 nugget               8.96e-19

> # Tidy the model output with confidence intervals and print
> print(tidy(ssn_mod, conf.int = TRUE))  
# A tibble: 15 × 7
   term                                estimate std.error statistic      p.value  conf.low conf.high
   <chr>                                  <dbl>     <dbl>     <dbl>        <dbl>     <dbl>     <dbl>
 1 (Intercept)                          0.0793     0.134     0.590  0.555          -0.184     0.343 
 2 ch_change.in.slope.over.width        0.0222     0.0828    0.268  0.789          -0.140     0.185 
 3 ch_channel.width.over.valley.width   0.212      0.163     1.30   0.194          -0.108     0.531 
 4 ch_channel_width                    -0.604      0.130    -4.63   0.00000368     -0.859    -0.348 
 5 ch_curvature.median                  0.175      0.109     1.61   0.108          -0.0381    0.388 
 6 ch_flow.accumulation.max             1.37       0.240     5.73   0.0000000103    0.903     1.84  
 7 ch_slope.median                      0.162      0.137     1.19   0.235          -0.105     0.430 
 8 ch_slope.over.width.central.diff     0.0539     0.0764    0.706  0.480          -0.0958    0.204 
 9 hs_area                             -0.00133    0.112    -0.0118 0.991          -0.221     0.218 
10 hs_curvature.median                  0.0313     0.101     0.308  0.758          -0.168     0.230 
11 hs_dnbr.median                      -0.410      0.186    -2.21   0.0273         -0.774    -0.0460
12 hs_drainage_density                -18.5       44.0      -0.421  0.674        -105.       67.6   
13 hs_eastness.median                  -0.130      0.138    -0.947  0.344          -0.400     0.139 
14 hs_ndvi.range                        0.0581     0.146     0.398  0.691          -0.228     0.344 
15 hs_slope.median                     -0.166      0.107    -1.55   0.120          -0.375     0.0432

> # Provide a glance summary of the model and print
> print(glance(ssn_mod))
# A tibble: 1 × 9
      n     p  npar value   AIC  AICc logLik  deviance pseudo.r.squared
  <int> <dbl> <int> <dbl> <dbl> <dbl>  <dbl>     <dbl>            <dbl>
1   107    15     6  359.  371.  372.  -180. 0.0000991            0.274

> # Perform Leave-One-Out Cross Validation and print
> print("Leave One Out Cross Validation")
[1] "Leave One Out Cross Validation"

> loocv_results <- loocv(ssn_mod)

> print(loocv_results)
# A tibble: 1 × 4
    bias  MSPE RMSPE   RAV
   <dbl> <dbl> <dbl> <dbl>
1 -0.101 0.997 0.998 0.706

> # Stop redirecting output
> sink()

> # ----------------------------#
> # 5. Model Evaluation
> # ----------------------------#
> 
> # Extract residuals and fitted values from the model
 .... [TRUNCATED] 

> fitted_values <- fitted(ssn_mod)   

> # ----------------------------#
> # 6. Plotting and Saving Graphs
> # ----------------------------#
> 
> 
> # Create the graph save directory if sav .... [TRUNCATED] 

> # ----------------------------#
> # 7. Residuals vs Fitted Values Plot
> # ----------------------------#
> 
> # Purpose:
> #   - Linearity: Ensure t .... [TRUNCATED] 

> # Create the Residuals vs Fitted Values plot
> resid_fitted_plot <- ggplot(data.frame(Fitted = fitted_values, Residuals = residuals), aes(x = Fitted .... [TRUNCATED] 

> # Display the plot
> print(resid_fitted_plot)

> # Save the plot if saving is enabled
> if (save_graphs) {
+   ggsave(filename = file.path(graph_save_dir, "Residuals_vs_Fitted.png"), plot = resid_f .... [TRUNCATED] 
[1] "Saved Residuals vs Fitted Values plot."

> # ----------------------------#
> # 8. Q-Q Plot for Residuals
> # ----------------------------#
> 
> # Purpose:
> #   - Normality: Verify that resid .... [TRUNCATED] 

> # Enhanced Q-Q Plot using ggplot2
> qq_plot <- ggplot(data.frame(Residuals = residuals), aes(sample = Residuals)) +
+   stat_qq(color = "blue") +
+  .... [TRUNCATED] 

> # Display the ggplot2 Q-Q plot
> print(qq_plot)

> # Save the ggplot2 Q-Q plot if saving is enabled
> if (save_graphs) {
+   ggsave(filename = file.path(graph_save_dir, "QQ_Plot_Residuals_GGPlot2.png ..." ... [TRUNCATED] 
[1] "Saved ggplot2 Q-Q Plot of Residuals."

> # ----------------------------#
> # 9. Histogram of Residuals
> # ----------------------------#
> 
> # Purpose:
> #   - Normality
> #
> # What to Lo .... [TRUNCATED] 

> # Enhanced Histogram using ggplot2
> hist_plot <- ggplot(data.frame(Residuals = residuals), aes(x = Residuals)) +
+   geom_histogram(aes(y = ..densi .... [TRUNCATED] 

> # Display the ggplot2 histogram
> print(hist_plot)

> # Save the ggplot2 histogram if saving is enabled
> if (save_graphs) {
+   ggsave(filename = file.path(graph_save_dir, "Histogram_Residuals_GGPlot2. ..." ... [TRUNCATED] 
[1] "Saved ggplot2 Histogram of Residuals with Normal Curve."

> # Redirect output to the specified file and also print to console
> sink(output_file, append = TRUE, split = TRUE)

> print("")
[1] ""

> # ----------------------------#
> # 10. Statistical Tests
> # ----------------------------#
> 
> 
> # --------- Shapiro-Wilk Test for Normality ---- .... [TRUNCATED] 
[1] "-------- Shapiro-Wilk Test for Normality ---------"

> print("  - Normality: To check if the residuals are normally distributed.")
[1] "  - Normality: To check if the residuals are normally distributed."

> print("  - p-value > 0.05: Fail to reject null hypothesis (residuals are normally distributed).")
[1] "  - p-value > 0.05: Fail to reject null hypothesis (residuals are normally distributed)."

> print("  - p-value <= 0.05: Reject null hypothesis (residuals are not normally distributed).\n")
[1] "  - p-value <= 0.05: Reject null hypothesis (residuals are not normally distributed).\n"

> shapiro_test <- shapiro.test(residuals)

> print("Shapiro-Wilk Test Results:")
[1] "Shapiro-Wilk Test Results:"

> print(shapiro_test)

	Shapiro-Wilk normality test

data:  residuals
W = 0.99402, p-value = 0.9259


> # --------- Breusch-Pagan Test for Homoscedasticity ---------
> print("-------- Breusch-Pagan Test for Homoscedasticity ---------")
[1] "-------- Breusch-Pagan Test for Homoscedasticity ---------"

> print("  - Homoscedasticity: To check if residuals have constant variance across all levels of fitted values.")
[1] "  - Homoscedasticity: To check if residuals have constant variance across all levels of fitted values."

> print("  - p-value > 0.05: Fail to reject null hypothesis (homoscedasticity holds).")
[1] "  - p-value > 0.05: Fail to reject null hypothesis (homoscedasticity holds)."

> print("  - p-value <= 0.05: Reject null hypothesis (heteroscedasticity present).\n")
[1] "  - p-value <= 0.05: Reject null hypothesis (heteroscedasticity present).\n"

> # Extract the model frame from the ssn_lm model
> data_ssn <- model.frame(ssn_mod)

> # Perform Breusch-Pagan Test
> bp_test <- bptest(ssn_mod)

> print("Breusch-Pagan Test Results:")
[1] "Breusch-Pagan Test Results:"

> print(bp_test)

	studentized Breusch-Pagan test

data:  ssn_mod
BP = 19.714, df = 14, p-value = 0.1394


> # --------- Moran's I Test for Spatial Autocorrelation ---------
> print("\n-------- Moran's I Test for Spatial Autocorrelation ---------")
[1] "\n-------- Moran's I Test for Spatial Autocorrelation ---------"

> print("  - Spatial Autocorrelation: To determine if there is spatial autocorrelation in the residuals.")
[1] "  - Spatial Autocorrelation: To determine if there is spatial autocorrelation in the residuals."

> print("  - p-value > 0.05: Fail to reject null hypothesis (lack of spatial autocorrelation in residuals holds).")
[1] "  - p-value > 0.05: Fail to reject null hypothesis (lack of spatial autocorrelation in residuals holds)."

> print("  - p-value <= 0.05: Reject null hypothesis (spatial autocorrelation present).\n")
[1] "  - p-value <= 0.05: Reject null hypothesis (spatial autocorrelation present).\n"

> sink()

> # Extract spatial coordinates from the SSN object
> # Ensure that your SSN object has geometry information
> coords <- st_coordinates(ssn_get_data(s .... [TRUNCATED] 

> # Create a spatial weights matrix using k-nearest neighbors (k = 4 as an example)
> knn <- knearneigh(coords, k = 4)

> nb <- knn2nb(knn)

> lw <- nb2listw(nb, style = "W", zero.policy = TRUE)

> # Compute Moran's I
> moran_test <- moran.test(residuals, lw, zero.policy = TRUE)

> sink(output_file, append = TRUE, split = TRUE)

> print("Moran's I Test Results:")
[1] "Moran's I Test Results:"

> print(moran_test)

	Moran I test under randomisation

data:  residuals  
weights: lw    

Moran I statistic standard deviate = -2.2457, p-value = 0.9876
alternative hypothesis: greater
sample estimates:
Moran I statistic       Expectation          Variance 
     -0.155371159      -0.009433962       0.004223150 


> # Stop redirecting output
> sink()

> # --------------------------------------------------
> # End of Script
> # --------------------------------------------------
> 

> # --------------------------------------------------
> # Spatial Statistical Modeling with SSN2
> # ------------------------------------------------ .... [TRUNCATED] 

> # Specify the input and output directories
> input_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/Inputs"

> output_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/SSN ET/ET Lower error thresh"

> model_name <- "glm ch_sfm.erosion.norm VIF 3 100ct thresh"

> obs_points_path <- file.path(input_dir, "Combined Watersheds", "ET Lower ssn points.gpkg")

> read_ssn <- FALSE # whether to create a new ssn (FALSE) or read the pre-existing ssn (TRUE)

> # Use file.path to create platform-independent file paths
> streams_path <- file.path(input_dir, "streams_100k.gpkg")

> ssn_path <- file.path(output_dir, "1_ET_Full_logtrans_independent_vars.ssn")

> output_file <- file.path(output_dir, model_name, "Results.txt")

> lsn_out <- file.path(output_dir, "0_lsn")

> # Define whether to save graphs and the directory to save them
> save_graphs <- TRUE  # Set to TRUE to save graphs as PNG

> graph_save_dir <- file.path(output_dir, model_name)  # Directory to save graphs

> # ----------------------------#
> # 1. Load Necessary Libraries
> # ----------------------------#
> 
> # Load required libraries
> library(SSN2)

> library(SSNbler)

> library(sf)

> library(dplyr)

> library(purrr)

> library(ggplot2)

> library(lmtest)

> library(spdep)

> library(classInt)   # Required for knearneigh

> library(broom)      # For tidy() and glance() functions

> library(grid)       # For grid.newpage()

> if (!dir.exists(graph_save_dir)) {
+   dir.create(graph_save_dir, recursive = TRUE)
+ }

> # ----------------------------#
> # 2. Read Spatial Data
> # ----------------------------#
> 
> # Read the streams dataset
> ET_streams <- st_read(s .... [TRUNCATED] 
Reading layer `streams_100k' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\streams_100k.gpkg' using driver `GPKG'
Simple feature collection with 643 features and 2 fields
Geometry type: LINESTRING
Dimension:     XY
Bounding box:  xmin: 404042.6 ymin: 4447904 xmax: 414579.6 ymax: 4466669
Projected CRS: NAD83 / UTM zone 13N

> # Read the observation points dataset
> ET_obs <- st_read(obs_points_path)
Reading layer `ET Lower ssn points' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\Combined Watersheds\ET Lower ssn points.gpkg' using driver `GPKG'
Simple feature collection with 107 features and 59 fields
Geometry type: POINT
Dimension:     XY
Bounding box:  xmin: 411943.5 ymin: 4449827 xmax: 412955.4 ymax: 4450878
Projected CRS: NAD83 / UTM zone 13N

> # Uncomment the following line if you encounter an error about Multilinestrings
> # ET_streams <- st_cast(ET_streams, "LINESTRING")
> 
> # --------- .... [TRUNCATED] 
[1] "Edge Attributes:"
[1] "rid"            "STRM_VAL"       "flow_accum_max" "Length"         "upDist"         "geometry"      
[1] "Site List Components:"
[1] "obs"
[1] "Updated Edge Attributes:"
[1] "rid"            "STRM_VAL"       "flow_accum_max" "Length"         "upDist"         "flow_accum_PI"  "afv_flow_accum" "geometry"      


SSN object is valid: TRUE

> # Create a distance matrix for spatial relationships
> # Purpose: Define spatial dependencies based on distances between sites
> ssn_create_distmat( .... [TRUNCATED] 

> # ----------------------------#
> # 4. Model Fitting and Output
> # ----------------------------#
> 
> # Redirect output to the specified file and a .... [TRUNCATED] 

> model_name
[1] "glm ch_sfm.erosion.norm VIF 3 100ct thresh"

> model_formula
ch_sfm.erosion.norm ~ ch_slope.median + ch_flow.accumulation.max + 
    ch_curvature.median + ch_valley_width + ch_central.slope.difference + 
    ch_channel.width.over.valley.width + ch_slope.over.width.central.diff + 
    hs_area + hs_slope.median + hs_eastness.median + hs_curvature.median + 
    hs_ndvi.range + hs_dnbr.median + hs_drainage_density

> ssn_mod <- ssn_glm(
+   formula = model_formula,
+   ssn.object = ET_ssn,
+   family = "Gamma",
+   tailup_type = "exponential",
+   taildown_type = .... [TRUNCATED] 

> # Print the summary of the model to the file and console
> print(summary(ssn_mod))

Call:
ssn_glm(formula = model_formula, ssn.object = ET_ssn, family = "Gamma", 
    tailup_type = "exponential", taildown_type = "none", euclid_type = "gaussian", 
    additive = "afv_flow_accum")

Deviance Residuals:
       Min         1Q     Median         3Q        Max 
-0.0070917 -0.0016667  0.0000772  0.0015103  0.0068540 

Coefficients (fixed):
                                    Estimate Std. Error z value Pr(>|z|)    
(Intercept)                          0.07162    0.16155   0.443  0.65751    
ch_slope.median                      0.21851    0.15029   1.454  0.14596    
ch_flow.accumulation.max             1.30897    0.28874   4.533 5.81e-06 ***
ch_curvature.median                  0.02483    0.10655   0.233  0.81576    
ch_valley_width                     -0.41059    0.15866  -2.588  0.00966 ** 
ch_central.slope.difference          0.07123    0.07860   0.906  0.36476    
ch_channel.width.over.valley.width  -0.28161    0.17129  -1.644  0.10017    
ch_slope.over.width.central.diff     0.02645    0.07671   0.345  0.73026    
hs_area                              0.01978    0.11720   0.169  0.86597    
hs_slope.median                     -0.12173    0.11210  -1.086  0.27753    
hs_eastness.median                  -0.10291    0.14229  -0.723  0.46951    
hs_curvature.median                  0.06978    0.10336   0.675  0.49962    
hs_ndvi.range                        0.06150    0.15706   0.392  0.69537    
hs_dnbr.median                      -0.39137    0.20229  -1.935  0.05303 .  
hs_drainage_density                -36.29232   45.59787  -0.796  0.42608    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Pseudo R-squared: 0.1683

Coefficients (covariance):
              Effect     Parameter   Estimate
  tailup exponential  de (parsill)  6.465e-01
  tailup exponential         range  1.565e+01
     euclid gaussian  de (parsill)  2.372e-08
     euclid gaussian         range  8.643e+04
              nugget        nugget  2.164e-02
          dispersion    dispersion  5.548e+02


> # Print variance components of the model
> varcomp(ssn_mod)
# A tibble: 5 × 2
  varcomp              proportion
  <chr>                     <dbl>
1 Covariates (PR-sq) 0.168       
2 tailup_de          0.805       
3 taildown_de        0           
4 euclid_de          0.0000000295
5 nugget             0.0269      

> # Tidy the model output with confidence intervals and print
> print(tidy(ssn_mod, conf.int = TRUE))  
# A tibble: 15 × 7
   term                               estimate std.error statistic    p.value  conf.low conf.high
   <chr>                                 <dbl>     <dbl>     <dbl>      <dbl>     <dbl>     <dbl>
 1 (Intercept)                          0.0716    0.162      0.443 0.658        -0.245    0.388  
 2 ch_central.slope.difference          0.0712    0.0786     0.906 0.365        -0.0828   0.225  
 3 ch_channel.width.over.valley.width  -0.282     0.171     -1.64  0.100        -0.617    0.0541 
 4 ch_curvature.median                  0.0248    0.107      0.233 0.816        -0.184    0.234  
 5 ch_flow.accumulation.max             1.31      0.289      4.53  0.00000581    0.743    1.87   
 6 ch_slope.median                      0.219     0.150      1.45  0.146        -0.0760   0.513  
 7 ch_slope.over.width.central.diff     0.0264    0.0767     0.345 0.730        -0.124    0.177  
 8 ch_valley_width                     -0.411     0.159     -2.59  0.00966      -0.722   -0.0996 
 9 hs_area                              0.0198    0.117      0.169 0.866        -0.210    0.249  
10 hs_curvature.median                  0.0698    0.103      0.675 0.500        -0.133    0.272  
11 hs_dnbr.median                      -0.391     0.202     -1.93  0.0530       -0.788    0.00511
12 hs_drainage_density                -36.3      45.6       -0.796 0.426      -126.      53.1    
13 hs_eastness.median                  -0.103     0.142     -0.723 0.470        -0.382    0.176  
14 hs_ndvi.range                        0.0615    0.157      0.392 0.695        -0.246    0.369  
15 hs_slope.median                     -0.122     0.112     -1.09  0.278        -0.341    0.0980 

> # Provide a glance summary of the model and print
> print(glance(ssn_mod))
# A tibble: 1 × 9
      n     p  npar value   AIC  AICc logLik deviance pseudo.r.squared
  <int> <dbl> <int> <dbl> <dbl> <dbl>  <dbl>    <dbl>            <dbl>
1   107    15     6  369.  381.  381.  -184. 0.000664            0.168

> # Perform Leave-One-Out Cross Validation and print
> print("Leave One Out Cross Validation")
[1] "Leave One Out Cross Validation"

> loocv_results <- loocv(ssn_mod)

> print(loocv_results)
# A tibble: 1 × 4
    bias  MSPE RMSPE   RAV
   <dbl> <dbl> <dbl> <dbl>
1 -0.120 0.723 0.850 0.728

> # Stop redirecting output
> sink()

> # ----------------------------#
> # 5. Model Evaluation
> # ----------------------------#
> 
> # Extract residuals and fitted values from the model
 .... [TRUNCATED] 

> fitted_values <- fitted(ssn_mod)   

> # ----------------------------#
> # 6. Plotting and Saving Graphs
> # ----------------------------#
> 
> 
> # Create the graph save directory if sav .... [TRUNCATED] 

> # ----------------------------#
> # 7. Residuals vs Fitted Values Plot
> # ----------------------------#
> 
> # Purpose:
> #   - Linearity: Ensure t .... [TRUNCATED] 

> # Create the Residuals vs Fitted Values plot
> resid_fitted_plot <- ggplot(data.frame(Fitted = fitted_values, Residuals = residuals), aes(x = Fitted .... [TRUNCATED] 

> # Display the plot
> print(resid_fitted_plot)

> # Save the plot if saving is enabled
> if (save_graphs) {
+   ggsave(filename = file.path(graph_save_dir, "Residuals_vs_Fitted.png"), plot = resid_f .... [TRUNCATED] 
[1] "Saved Residuals vs Fitted Values plot."

> # ----------------------------#
> # 8. Q-Q Plot for Residuals
> # ----------------------------#
> 
> # Purpose:
> #   - Normality: Verify that resid .... [TRUNCATED] 

> # Enhanced Q-Q Plot using ggplot2
> qq_plot <- ggplot(data.frame(Residuals = residuals), aes(sample = Residuals)) +
+   stat_qq(color = "blue") +
+  .... [TRUNCATED] 

> # Display the ggplot2 Q-Q plot
> print(qq_plot)

> # Save the ggplot2 Q-Q plot if saving is enabled
> if (save_graphs) {
+   ggsave(filename = file.path(graph_save_dir, "QQ_Plot_Residuals_GGPlot2.png ..." ... [TRUNCATED] 
[1] "Saved ggplot2 Q-Q Plot of Residuals."

> # ----------------------------#
> # 9. Histogram of Residuals
> # ----------------------------#
> 
> # Purpose:
> #   - Normality
> #
> # What to Lo .... [TRUNCATED] 

> # Enhanced Histogram using ggplot2
> hist_plot <- ggplot(data.frame(Residuals = residuals), aes(x = Residuals)) +
+   geom_histogram(aes(y = ..densi .... [TRUNCATED] 

> # Display the ggplot2 histogram
> print(hist_plot)

> # Save the ggplot2 histogram if saving is enabled
> if (save_graphs) {
+   ggsave(filename = file.path(graph_save_dir, "Histogram_Residuals_GGPlot2. ..." ... [TRUNCATED] 
[1] "Saved ggplot2 Histogram of Residuals with Normal Curve."

> # Redirect output to the specified file and also print to console
> sink(output_file, append = TRUE, split = TRUE)

> print("")
[1] ""

> # ----------------------------#
> # 10. Statistical Tests
> # ----------------------------#
> 
> 
> # --------- Shapiro-Wilk Test for Normality ---- .... [TRUNCATED] 
[1] "-------- Shapiro-Wilk Test for Normality ---------"

> print("  - Normality: To check if the residuals are normally distributed.")
[1] "  - Normality: To check if the residuals are normally distributed."

> print("  - p-value > 0.05: Fail to reject null hypothesis (residuals are normally distributed).")
[1] "  - p-value > 0.05: Fail to reject null hypothesis (residuals are normally distributed)."

> print("  - p-value <= 0.05: Reject null hypothesis (residuals are not normally distributed).\n")
[1] "  - p-value <= 0.05: Reject null hypothesis (residuals are not normally distributed).\n"

> shapiro_test <- shapiro.test(residuals)

> print("Shapiro-Wilk Test Results:")
[1] "Shapiro-Wilk Test Results:"

> print(shapiro_test)

	Shapiro-Wilk normality test

data:  residuals
W = 0.98881, p-value = 0.52


> # --------- Breusch-Pagan Test for Homoscedasticity ---------
> print("-------- Breusch-Pagan Test for Homoscedasticity ---------")
[1] "-------- Breusch-Pagan Test for Homoscedasticity ---------"

> print("  - Homoscedasticity: To check if residuals have constant variance across all levels of fitted values.")
[1] "  - Homoscedasticity: To check if residuals have constant variance across all levels of fitted values."

> print("  - p-value > 0.05: Fail to reject null hypothesis (homoscedasticity holds).")
[1] "  - p-value > 0.05: Fail to reject null hypothesis (homoscedasticity holds)."

> print("  - p-value <= 0.05: Reject null hypothesis (heteroscedasticity present).\n")
[1] "  - p-value <= 0.05: Reject null hypothesis (heteroscedasticity present).\n"

> # Extract the model frame from the ssn_lm model
> data_ssn <- model.frame(ssn_mod)

> # Perform Breusch-Pagan Test
> bp_test <- bptest(ssn_mod)

> print("Breusch-Pagan Test Results:")
[1] "Breusch-Pagan Test Results:"

> print(bp_test)

	studentized Breusch-Pagan test

data:  ssn_mod
BP = 20.444, df = 14, p-value = 0.1167


> # --------- Moran's I Test for Spatial Autocorrelation ---------
> print("\n-------- Moran's I Test for Spatial Autocorrelation ---------")
[1] "\n-------- Moran's I Test for Spatial Autocorrelation ---------"

> print("  - Spatial Autocorrelation: To determine if there is spatial autocorrelation in the residuals.")
[1] "  - Spatial Autocorrelation: To determine if there is spatial autocorrelation in the residuals."

> print("  - p-value > 0.05: Fail to reject null hypothesis (lack of spatial autocorrelation in residuals holds).")
[1] "  - p-value > 0.05: Fail to reject null hypothesis (lack of spatial autocorrelation in residuals holds)."

> print("  - p-value <= 0.05: Reject null hypothesis (spatial autocorrelation present).\n")
[1] "  - p-value <= 0.05: Reject null hypothesis (spatial autocorrelation present).\n"

> sink()

> # Extract spatial coordinates from the SSN object
> # Ensure that your SSN object has geometry information
> coords <- st_coordinates(ssn_get_data(s .... [TRUNCATED] 

> # Create a spatial weights matrix using k-nearest neighbors (k = 4 as an example)
> knn <- knearneigh(coords, k = 4)

> nb <- knn2nb(knn)

> lw <- nb2listw(nb, style = "W", zero.policy = TRUE)

> # Compute Moran's I
> moran_test <- moran.test(residuals, lw, zero.policy = TRUE)

> sink(output_file, append = TRUE, split = TRUE)

> print("Moran's I Test Results:")
[1] "Moran's I Test Results:"

> print(moran_test)

	Moran I test under randomisation

data:  residuals  
weights: lw    

Moran I statistic standard deviate = -2.5563, p-value = 0.9947
alternative hypothesis: greater
sample estimates:
Moran I statistic       Expectation          Variance 
     -0.175219908      -0.009433962       0.004205943 


> # Stop redirecting output
> sink()

> # --------------------------------------------------
> # End of Script
> # --------------------------------------------------
> 

> # --------------------------------------------------
> # Spatial Statistical Modeling with SSN2
> # ------------------------------------------------ .... [TRUNCATED] 

> # Specify the input and output directories
> input_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/Inputs"

> output_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/SSN ET/ET Lower error thresh"

> model_name <- "glm ch_sfm.erosion.norm VIF 3 100ct thresh ws_re"

> obs_points_path <- file.path(input_dir, "Combined Watersheds", "ET Lower ssn points.gpkg")

> read_ssn <- TRUE # whether to create a new ssn (FALSE) or read the pre-existing ssn (TRUE)

> # Use file.path to create platform-independent file paths
> streams_path <- file.path(input_dir, "streams_100k.gpkg")

> ssn_path <- file.path(output_dir, "1_ET_Full_logtrans_independent_vars.ssn")

> output_file <- file.path(output_dir, model_name, "Results.txt")

> lsn_out <- file.path(output_dir, "0_lsn")

> # Define whether to save graphs and the directory to save them
> save_graphs <- TRUE  # Set to TRUE to save graphs as PNG

> graph_save_dir <- file.path(output_dir, model_name)  # Directory to save graphs

> # ----------------------------#
> # 1. Load Necessary Libraries
> # ----------------------------#
> 
> # Load required libraries
> library(SSN2)

> library(SSNbler)

> library(sf)

> library(dplyr)

> library(purrr)

> library(ggplot2)

> library(lmtest)

> library(spdep)

> library(classInt)   # Required for knearneigh

> library(broom)      # For tidy() and glance() functions

> library(grid)       # For grid.newpage()

> if (!dir.exists(graph_save_dir)) {
+   dir.create(graph_save_dir, recursive = TRUE)
+ }

> # ----------------------------#
> # 2. Read Spatial Data
> # ----------------------------#
> 
> # Read the streams dataset
> ET_streams <- st_read(s .... [TRUNCATED] 
Reading layer `streams_100k' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\streams_100k.gpkg' using driver `GPKG'
Simple feature collection with 643 features and 2 fields
Geometry type: LINESTRING
Dimension:     XY
Bounding box:  xmin: 404042.6 ymin: 4447904 xmax: 414579.6 ymax: 4466669
Projected CRS: NAD83 / UTM zone 13N

> # Read the observation points dataset
> ET_obs <- st_read(obs_points_path)
Reading layer `ET Lower ssn points' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\Combined Watersheds\ET Lower ssn points.gpkg' using driver `GPKG'
Simple feature collection with 107 features and 59 fields
Geometry type: POINT
Dimension:     XY
Bounding box:  xmin: 411943.5 ymin: 4449827 xmax: 412955.4 ymax: 4450878
Projected CRS: NAD83 / UTM zone 13N

> # Uncomment the following line if you encounter an error about Multilinestrings
> # ET_streams <- st_cast(ET_streams, "LINESTRING")
> 
> # --------- .... [TRUNCATED] 

> # Create a distance matrix for spatial relationships
> # Purpose: Define spatial dependencies based on distances between sites
> ssn_create_distmat( .... [TRUNCATED] 

> # ----------------------------#
> # 4. Model Fitting and Output
> # ----------------------------#
> 
> # Redirect output to the specified file and a .... [TRUNCATED] 

> model_name
[1] "glm ch_sfm.erosion.norm VIF 3 100ct thresh ws_re"

> model_formula
ch_sfm.erosion.norm ~ ch_slope.median + ch_flow.accumulation.max + 
    ch_curvature.median + ch_valley_width + ch_central.slope.difference + 
    ch_channel.width.over.valley.width + ch_slope.over.width.central.diff + 
    hs_area + hs_slope.median + hs_eastness.median + hs_curvature.median + 
    hs_ndvi.range + hs_dnbr.median + hs_drainage_density + (1 | 
    ch_watershed)

> ssn_mod <- ssn_glm(
+   formula = model_formula,
+   ssn.object = ET_ssn,
+   family = "Gamma",
+   tailup_type = "exponential",
+   taildown_type = .... [TRUNCATED] 

> # --------------------------------------------------
> # Spatial Statistical Modeling with SSN2
> # ------------------------------------------------ .... [TRUNCATED] 

> # --------------------------------------------------
> # Spatial Statistical Modeling with SSN2
> # ------------------------------------------------ .... [TRUNCATED] 

> # Specify the input and output directories
> input_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/Inputs"

> output_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/SSN ET/ET Lower error thresh"

> model_name <- "glm ch_sfm.erosion.norm VIF 3 100ct thresh ws_re"

> obs_points_path <- file.path(input_dir, "Combined Watersheds", "ET Lower ssn points.gpkg")

> read_ssn <- TRUE # whether to create a new ssn (FALSE) or read the pre-existing ssn (TRUE)

> # Use file.path to create platform-independent file paths
> streams_path <- file.path(input_dir, "streams_100k.gpkg")

> ssn_path <- file.path(output_dir, "1_ET_Full_logtrans_independent_vars.ssn")

> output_file <- file.path(output_dir, model_name, "Results.txt")

> lsn_out <- file.path(output_dir, "0_lsn")

> # Define whether to save graphs and the directory to save them
> save_graphs <- TRUE  # Set to TRUE to save graphs as PNG

> graph_save_dir <- file.path(output_dir, model_name)  # Directory to save graphs

> # ----------------------------#
> # 1. Load Necessary Libraries
> # ----------------------------#
> 
> # Load required libraries
> library(SSN2)

> library(SSNbler)

> library(sf)

> library(dplyr)

> library(purrr)

> library(ggplot2)

> library(lmtest)

> library(spdep)

> library(classInt)   # Required for knearneigh

> library(broom)      # For tidy() and glance() functions

> library(grid)       # For grid.newpage()

> if (!dir.exists(graph_save_dir)) {
+   dir.create(graph_save_dir, recursive = TRUE)
+ }

> # ----------------------------#
> # 2. Read Spatial Data
> # ----------------------------#
> 
> # Read the streams dataset
> ET_streams <- st_read(s .... [TRUNCATED] 
Reading layer `streams_100k' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\streams_100k.gpkg' using driver `GPKG'
Simple feature collection with 643 features and 2 fields
Geometry type: LINESTRING
Dimension:     XY
Bounding box:  xmin: 404042.6 ymin: 4447904 xmax: 414579.6 ymax: 4466669
Projected CRS: NAD83 / UTM zone 13N

> # Read the observation points dataset
> ET_obs <- st_read(obs_points_path)
Reading layer `ET Lower ssn points' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\Combined Watersheds\ET Lower ssn points.gpkg' using driver `GPKG'
Simple feature collection with 107 features and 59 fields
Geometry type: POINT
Dimension:     XY
Bounding box:  xmin: 411943.5 ymin: 4449827 xmax: 412955.4 ymax: 4450878
Projected CRS: NAD83 / UTM zone 13N

> # Uncomment the following line if you encounter an error about Multilinestrings
> # ET_streams <- st_cast(ET_streams, "LINESTRING")
> 
> # --------- .... [TRUNCATED] 

> # Create a distance matrix for spatial relationships
> # Purpose: Define spatial dependencies based on distances between sites
> ssn_create_distmat( .... [TRUNCATED] 

> # ----------------------------#
> # 4. Model Fitting and Output
> # ----------------------------#
> 
> # Redirect output to the specified file and a .... [TRUNCATED] 

> model_name
[1] "glm ch_sfm.erosion.norm VIF 3 100ct thresh ws_re"

> model_formula
ch_sfm.erosion.norm ~ ch_slope.median + ch_flow.accumulation.max + 
    ch_curvature.median + ch_valley_width + ch_central.slope.difference + 
    ch_channel.width.over.valley.width + ch_slope.over.width.central.diff + 
    hs_area + hs_slope.median + hs_eastness.median + hs_curvature.median + 
    hs_ndvi.range + hs_dnbr.median + hs_drainage_density

> ssn_mod <- ssn_glm(
+   formula = model_formula,
+   ssn.object = ET_ssn,
+   family = "Gamma",
+   tailup_type = "exponential",
+   taildown_type = .... [TRUNCATED] 

> # Print the summary of the model to the file and console
> print(summary(ssn_mod))

Call:
ssn_glm(formula = model_formula, ssn.object = ET_ssn, family = "Gamma", 
    tailup_type = "exponential", taildown_type = "none", euclid_type = "gaussian", 
    additive = "afv_flow_accum")

Deviance Residuals:
       Min         1Q     Median         3Q        Max 
-0.0070917 -0.0016667  0.0000772  0.0015103  0.0068540 

Coefficients (fixed):
                                    Estimate Std. Error z value Pr(>|z|)    
(Intercept)                          0.07162    0.16155   0.443  0.65751    
ch_slope.median                      0.21851    0.15029   1.454  0.14596    
ch_flow.accumulation.max             1.30897    0.28874   4.533 5.81e-06 ***
ch_curvature.median                  0.02483    0.10655   0.233  0.81576    
ch_valley_width                     -0.41059    0.15866  -2.588  0.00966 ** 
ch_central.slope.difference          0.07123    0.07860   0.906  0.36476    
ch_channel.width.over.valley.width  -0.28161    0.17129  -1.644  0.10017    
ch_slope.over.width.central.diff     0.02645    0.07671   0.345  0.73026    
hs_area                              0.01978    0.11720   0.169  0.86597    
hs_slope.median                     -0.12173    0.11210  -1.086  0.27753    
hs_eastness.median                  -0.10291    0.14229  -0.723  0.46951    
hs_curvature.median                  0.06978    0.10336   0.675  0.49962    
hs_ndvi.range                        0.06150    0.15706   0.392  0.69537    
hs_dnbr.median                      -0.39137    0.20229  -1.935  0.05303 .  
hs_drainage_density                -36.29232   45.59787  -0.796  0.42608    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Pseudo R-squared: 0.1683

Coefficients (covariance):
              Effect     Parameter   Estimate
  tailup exponential  de (parsill)  6.465e-01
  tailup exponential         range  1.565e+01
     euclid gaussian  de (parsill)  2.372e-08
     euclid gaussian         range  8.643e+04
              nugget        nugget  2.164e-02
          dispersion    dispersion  5.548e+02


> # Print variance components of the model
> varcomp(ssn_mod)
# A tibble: 5 × 2
  varcomp              proportion
  <chr>                     <dbl>
1 Covariates (PR-sq) 0.168       
2 tailup_de          0.805       
3 taildown_de        0           
4 euclid_de          0.0000000295
5 nugget             0.0269      

> # Tidy the model output with confidence intervals and print
> print(tidy(ssn_mod, conf.int = TRUE))  
# A tibble: 15 × 7
   term                               estimate std.error statistic    p.value  conf.low conf.high
   <chr>                                 <dbl>     <dbl>     <dbl>      <dbl>     <dbl>     <dbl>
 1 (Intercept)                          0.0716    0.162      0.443 0.658        -0.245    0.388  
 2 ch_central.slope.difference          0.0712    0.0786     0.906 0.365        -0.0828   0.225  
 3 ch_channel.width.over.valley.width  -0.282     0.171     -1.64  0.100        -0.617    0.0541 
 4 ch_curvature.median                  0.0248    0.107      0.233 0.816        -0.184    0.234  
 5 ch_flow.accumulation.max             1.31      0.289      4.53  0.00000581    0.743    1.87   
 6 ch_slope.median                      0.219     0.150      1.45  0.146        -0.0760   0.513  
 7 ch_slope.over.width.central.diff     0.0264    0.0767     0.345 0.730        -0.124    0.177  
 8 ch_valley_width                     -0.411     0.159     -2.59  0.00966      -0.722   -0.0996 
 9 hs_area                              0.0198    0.117      0.169 0.866        -0.210    0.249  
10 hs_curvature.median                  0.0698    0.103      0.675 0.500        -0.133    0.272  
11 hs_dnbr.median                      -0.391     0.202     -1.93  0.0530       -0.788    0.00511
12 hs_drainage_density                -36.3      45.6       -0.796 0.426      -126.      53.1    
13 hs_eastness.median                  -0.103     0.142     -0.723 0.470        -0.382    0.176  
14 hs_ndvi.range                        0.0615    0.157      0.392 0.695        -0.246    0.369  
15 hs_slope.median                     -0.122     0.112     -1.09  0.278        -0.341    0.0980 

> # Provide a glance summary of the model and print
> print(glance(ssn_mod))
# A tibble: 1 × 9
      n     p  npar value   AIC  AICc logLik deviance pseudo.r.squared
  <int> <dbl> <int> <dbl> <dbl> <dbl>  <dbl>    <dbl>            <dbl>
1   107    15     6  369.  381.  381.  -184. 0.000664            0.168

> # Perform Leave-One-Out Cross Validation and print
> print("Leave One Out Cross Validation")
[1] "Leave One Out Cross Validation"

> loocv_results <- loocv(ssn_mod)

> print(loocv_results)
# A tibble: 1 × 4
    bias  MSPE RMSPE   RAV
   <dbl> <dbl> <dbl> <dbl>
1 -0.120 0.723 0.850 0.728

> # Stop redirecting output
> sink()

> # ----------------------------#
> # 5. Model Evaluation
> # ----------------------------#
> 
> # Extract residuals and fitted values from the model
 .... [TRUNCATED] 

> fitted_values <- fitted(ssn_mod)   

> # ----------------------------#
> # 6. Plotting and Saving Graphs
> # ----------------------------#
> 
> 
> # Create the graph save directory if sav .... [TRUNCATED] 

> # ----------------------------#
> # 7. Residuals vs Fitted Values Plot
> # ----------------------------#
> 
> # Purpose:
> #   - Linearity: Ensure t .... [TRUNCATED] 

> # Create the Residuals vs Fitted Values plot
> resid_fitted_plot <- ggplot(data.frame(Fitted = fitted_values, Residuals = residuals), aes(x = Fitted .... [TRUNCATED] 

> # Display the plot
> print(resid_fitted_plot)

> # Save the plot if saving is enabled
> if (save_graphs) {
+   ggsave(filename = file.path(graph_save_dir, "Residuals_vs_Fitted.png"), plot = resid_f .... [TRUNCATED] 
[1] "Saved Residuals vs Fitted Values plot."

> # ----------------------------#
> # 8. Q-Q Plot for Residuals
> # ----------------------------#
> 
> # Purpose:
> #   - Normality: Verify that resid .... [TRUNCATED] 

> # Enhanced Q-Q Plot using ggplot2
> qq_plot <- ggplot(data.frame(Residuals = residuals), aes(sample = Residuals)) +
+   stat_qq(color = "blue") +
+  .... [TRUNCATED] 

> # Display the ggplot2 Q-Q plot
> print(qq_plot)

> # Save the ggplot2 Q-Q plot if saving is enabled
> if (save_graphs) {
+   ggsave(filename = file.path(graph_save_dir, "QQ_Plot_Residuals_GGPlot2.png ..." ... [TRUNCATED] 
[1] "Saved ggplot2 Q-Q Plot of Residuals."

> # ----------------------------#
> # 9. Histogram of Residuals
> # ----------------------------#
> 
> # Purpose:
> #   - Normality
> #
> # What to Lo .... [TRUNCATED] 

> # Enhanced Histogram using ggplot2
> hist_plot <- ggplot(data.frame(Residuals = residuals), aes(x = Residuals)) +
+   geom_histogram(aes(y = ..densi .... [TRUNCATED] 

> # Display the ggplot2 histogram
> print(hist_plot)

> # Save the ggplot2 histogram if saving is enabled
> if (save_graphs) {
+   ggsave(filename = file.path(graph_save_dir, "Histogram_Residuals_GGPlot2. ..." ... [TRUNCATED] 
[1] "Saved ggplot2 Histogram of Residuals with Normal Curve."

> # Redirect output to the specified file and also print to console
> sink(output_file, append = TRUE, split = TRUE)

> print("")
[1] ""

> # ----------------------------#
> # 10. Statistical Tests
> # ----------------------------#
> 
> 
> # --------- Shapiro-Wilk Test for Normality ---- .... [TRUNCATED] 
[1] "-------- Shapiro-Wilk Test for Normality ---------"

> print("  - Normality: To check if the residuals are normally distributed.")
[1] "  - Normality: To check if the residuals are normally distributed."

> print("  - p-value > 0.05: Fail to reject null hypothesis (residuals are normally distributed).")
[1] "  - p-value > 0.05: Fail to reject null hypothesis (residuals are normally distributed)."

> print("  - p-value <= 0.05: Reject null hypothesis (residuals are not normally distributed).\n")
[1] "  - p-value <= 0.05: Reject null hypothesis (residuals are not normally distributed).\n"

> shapiro_test <- shapiro.test(residuals)

> print("Shapiro-Wilk Test Results:")
[1] "Shapiro-Wilk Test Results:"

> print(shapiro_test)

	Shapiro-Wilk normality test

data:  residuals
W = 0.98881, p-value = 0.52


> # --------- Breusch-Pagan Test for Homoscedasticity ---------
> print("-------- Breusch-Pagan Test for Homoscedasticity ---------")
[1] "-------- Breusch-Pagan Test for Homoscedasticity ---------"

> print("  - Homoscedasticity: To check if residuals have constant variance across all levels of fitted values.")
[1] "  - Homoscedasticity: To check if residuals have constant variance across all levels of fitted values."

> print("  - p-value > 0.05: Fail to reject null hypothesis (homoscedasticity holds).")
[1] "  - p-value > 0.05: Fail to reject null hypothesis (homoscedasticity holds)."

> print("  - p-value <= 0.05: Reject null hypothesis (heteroscedasticity present).\n")
[1] "  - p-value <= 0.05: Reject null hypothesis (heteroscedasticity present).\n"

> # Extract the model frame from the ssn_lm model
> data_ssn <- model.frame(ssn_mod)

> # Perform Breusch-Pagan Test
> bp_test <- bptest(ssn_mod)

> print("Breusch-Pagan Test Results:")
[1] "Breusch-Pagan Test Results:"

> print(bp_test)

	studentized Breusch-Pagan test

data:  ssn_mod
BP = 20.444, df = 14, p-value = 0.1167


> # --------- Moran's I Test for Spatial Autocorrelation ---------
> print("\n-------- Moran's I Test for Spatial Autocorrelation ---------")
[1] "\n-------- Moran's I Test for Spatial Autocorrelation ---------"

> print("  - Spatial Autocorrelation: To determine if there is spatial autocorrelation in the residuals.")
[1] "  - Spatial Autocorrelation: To determine if there is spatial autocorrelation in the residuals."

> print("  - p-value > 0.05: Fail to reject null hypothesis (lack of spatial autocorrelation in residuals holds).")
[1] "  - p-value > 0.05: Fail to reject null hypothesis (lack of spatial autocorrelation in residuals holds)."

> print("  - p-value <= 0.05: Reject null hypothesis (spatial autocorrelation present).\n")
[1] "  - p-value <= 0.05: Reject null hypothesis (spatial autocorrelation present).\n"

> sink()

> # Extract spatial coordinates from the SSN object
> # Ensure that your SSN object has geometry information
> coords <- st_coordinates(ssn_get_data(s .... [TRUNCATED] 

> # Create a spatial weights matrix using k-nearest neighbors (k = 4 as an example)
> knn <- knearneigh(coords, k = 4)

> nb <- knn2nb(knn)

> lw <- nb2listw(nb, style = "W", zero.policy = TRUE)

> # Compute Moran's I
> moran_test <- moran.test(residuals, lw, zero.policy = TRUE)

> sink(output_file, append = TRUE, split = TRUE)

> print("Moran's I Test Results:")
[1] "Moran's I Test Results:"

> print(moran_test)

	Moran I test under randomisation

data:  residuals  
weights: lw    

Moran I statistic standard deviate = -2.5563, p-value = 0.9947
alternative hypothesis: greater
sample estimates:
Moran I statistic       Expectation          Variance 
     -0.175219908      -0.009433962       0.004205943 


> # Stop redirecting output
> sink()

> # --------------------------------------------------
> # End of Script
> # --------------------------------------------------
> 

> # --------------------------------------------------
> # Spatial Statistical Modeling with SSN2
> # ------------------------------------------------ .... [TRUNCATED] 

> # Specify the input and output directories
> input_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/Inputs"

> output_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/SSN ET/ET Full ws_re"

> model_name <- "glm ch_sfm.erosion.norm VIF 3 ws_re"

> obs_points_path <- file.path(input_dir, "Combined Watersheds", "ET Full ssn points.gpkg")

> read_ssn <- FALSE # whether to create a new ssn (FALSE) or read the pre-existing ssn (TRUE)

> # Use file.path to create platform-independent file paths
> streams_path <- file.path(input_dir, "streams_100k.gpkg")

> ssn_path <- file.path(output_dir, "1_ET_Full_logtrans_independent_vars.ssn")

> output_file <- file.path(output_dir, model_name, "Results.txt")

> lsn_out <- file.path(output_dir, "0_lsn")

> # Define whether to save graphs and the directory to save them
> save_graphs <- TRUE  # Set to TRUE to save graphs as PNG

> graph_save_dir <- file.path(output_dir, model_name)  # Directory to save graphs

> # ----------------------------#
> # 1. Load Necessary Libraries
> # ----------------------------#
> 
> # Load required libraries
> library(SSN2)

> library(SSNbler)

> library(sf)

> library(dplyr)

> library(purrr)

> library(ggplot2)

> library(lmtest)

> library(spdep)

> library(classInt)   # Required for knearneigh

> library(broom)      # For tidy() and glance() functions

> library(grid)       # For grid.newpage()

> if (!dir.exists(graph_save_dir)) {
+   dir.create(graph_save_dir, recursive = TRUE)
+ }

> # ----------------------------#
> # 2. Read Spatial Data
> # ----------------------------#
> 
> # Read the streams dataset
> ET_streams <- st_read(s .... [TRUNCATED] 
Reading layer `streams_100k' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\streams_100k.gpkg' using driver `GPKG'
Simple feature collection with 643 features and 2 fields
Geometry type: LINESTRING
Dimension:     XY
Bounding box:  xmin: 404042.6 ymin: 4447904 xmax: 414579.6 ymax: 4466669
Projected CRS: NAD83 / UTM zone 13N

> # Read the observation points dataset
> ET_obs <- st_read(obs_points_path)
Reading layer `ET Full ssn points' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\Combined Watersheds\ET Full ssn points.gpkg' using driver `GPKG'
Simple feature collection with 645 features and 60 fields
Geometry type: POINT
Dimension:     XY
Bounding box:  xmin: 407401.1 ymin: 4449827 xmax: 413032.9 ymax: 4464548
Projected CRS: NAD83 / UTM zone 13N

> # Uncomment the following line if you encounter an error about Multilinestrings
> # ET_streams <- st_cast(ET_streams, "LINESTRING")
> 
> # --------- .... [TRUNCATED] 
[1] "Edge Attributes:"
[1] "rid"            "STRM_VAL"       "flow_accum_max" "Length"         "upDist"         "geometry"      
[1] "Site List Components:"
[1] "obs"
[1] "Updated Edge Attributes:"
[1] "rid"            "STRM_VAL"       "flow_accum_max" "Length"         "upDist"         "flow_accum_PI"  "afv_flow_accum" "geometry"      


SSN object is valid: TRUE

> # Create a distance matrix for spatial relationships
> # Purpose: Define spatial dependencies based on distances between sites
> ssn_create_distmat( .... [TRUNCATED] 

> # ----------------------------#
> # 4. Model Fitting and Output
> # ----------------------------#
> 
> # Redirect output to the specified file and a .... [TRUNCATED] 

> model_name
[1] "glm ch_sfm.erosion.norm VIF 3 ws_re"

> model_formula
ch_sfm.erosion.norm ~ ch_slope.median + ch_flow.accumulation.max + 
    ch_curvature.median + ch_valley_width + ch_central.slope.difference + 
    ch_channel.width.over.valley.width + ch_slope.over.width.central.diff + 
    hs_area + hs_slope.median + hs_eastness.median + hs_curvature.median + 
    hs_ndvi.range + hs_dnbr.median + hs_drainage_density + (1 | 
    ch_watershed)

> ssn_mod <- ssn_glm(
+   formula = model_formula,
+   ssn.object = ET_ssn,
+   family = "Gamma",
+   tailup_type = "exponential",
+   taildown_type = .... [TRUNCATED] 

> # --------------------------------------------------
> # Spatial Statistical Modeling with SSN2
> # ------------------------------------------------ .... [TRUNCATED] 

> # Specify the input and output directories
> input_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/Inputs"

> output_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/SSN ET/ET Full ws_re"

> model_name <- "glm ch_sfm.erosion.norm VIF 3 ws_re"

> obs_points_path <- file.path(input_dir, "Combined Watersheds", "ET Full ssn points.gpkg")

> read_ssn <- TRUE # whether to create a new ssn (FALSE) or read the pre-existing ssn (TRUE)

> # Use file.path to create platform-independent file paths
> streams_path <- file.path(input_dir, "streams_100k.gpkg")

> ssn_path <- file.path(output_dir, "1_ET_Full_logtrans_independent_vars.ssn")

> output_file <- file.path(output_dir, model_name, "Results.txt")

> lsn_out <- file.path(output_dir, "0_lsn")

> # Define whether to save graphs and the directory to save them
> save_graphs <- TRUE  # Set to TRUE to save graphs as PNG

> graph_save_dir <- file.path(output_dir, model_name)  # Directory to save graphs

> # ----------------------------#
> # 1. Load Necessary Libraries
> # ----------------------------#
> 
> # Load required libraries
> library(SSN2)

> library(SSNbler)

> library(sf)

> library(dplyr)

> library(purrr)

> library(ggplot2)

> library(lmtest)

> library(spdep)

> library(classInt)   # Required for knearneigh

> library(broom)      # For tidy() and glance() functions

> library(grid)       # For grid.newpage()

> if (!dir.exists(graph_save_dir)) {
+   dir.create(graph_save_dir, recursive = TRUE)
+ }

> # ----------------------------#
> # 2. Read Spatial Data
> # ----------------------------#
> 
> # Read the streams dataset
> ET_streams <- st_read(s .... [TRUNCATED] 
Reading layer `streams_100k' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\streams_100k.gpkg' using driver `GPKG'
Simple feature collection with 643 features and 2 fields
Geometry type: LINESTRING
Dimension:     XY
Bounding box:  xmin: 404042.6 ymin: 4447904 xmax: 414579.6 ymax: 4466669
Projected CRS: NAD83 / UTM zone 13N

> # Read the observation points dataset
> ET_obs <- st_read(obs_points_path)
Reading layer `ET Full ssn points' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\Combined Watersheds\ET Full ssn points.gpkg' using driver `GPKG'
Simple feature collection with 645 features and 60 fields
Geometry type: POINT
Dimension:     XY
Bounding box:  xmin: 407401.1 ymin: 4449827 xmax: 413032.9 ymax: 4464548
Projected CRS: NAD83 / UTM zone 13N

> # Uncomment the following line if you encounter an error about Multilinestrings
> # ET_streams <- st_cast(ET_streams, "LINESTRING")
> 
> # --------- .... [TRUNCATED] 

> # Create a distance matrix for spatial relationships
> # Purpose: Define spatial dependencies based on distances between sites
> ssn_create_distmat( .... [TRUNCATED] 

> # ----------------------------#
> # 4. Model Fitting and Output
> # ----------------------------#
> 
> # Redirect output to the specified file and a .... [TRUNCATED] 

> model_name
[1] "glm ch_sfm.erosion.norm VIF 3 ws_re"

> model_formula
ch_sfm.erosion.norm ~ ch_slope.median + ch_curvature.median + 
    ch_valley_width + ch_central.slope.difference + ch_channel.width.over.valley.width + 
    ch_slope.over.width.central.diff + hs_area + hs_slope.median + 
    hs_eastness.median + hs_curvature.median + hs_ndvi.range + 
    hs_dnbr.median + hs_drainage_density + (1 | ch_watershed)

> ssn_mod <- ssn_glm(
+   formula = model_formula,
+   ssn.object = ET_ssn,
+   family = "Gamma",
+   tailup_type = "exponential",
+   taildown_type = .... [TRUNCATED] 

> # --------------------------------------------------
> # Spatial Statistical Modeling with SSN2
> # ------------------------------------------------ .... [TRUNCATED] 

> # Specify the input and output directories
> input_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/Inputs"

> output_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/SSN ET/ET Full ws_re"

> model_name <- "glm ch_sfm.erosion.norm VIF 3 ws_re"

> obs_points_path <- file.path(input_dir, "Combined Watersheds", "ET Full ssn points.gpkg")

> read_ssn <- TRUE # whether to create a new ssn (FALSE) or read the pre-existing ssn (TRUE)

> # Use file.path to create platform-independent file paths
> streams_path <- file.path(input_dir, "streams_100k.gpkg")

> ssn_path <- file.path(output_dir, "1_ET_Full_logtrans_independent_vars.ssn")

> output_file <- file.path(output_dir, model_name, "Results.txt")

> lsn_out <- file.path(output_dir, "0_lsn")

> # Define whether to save graphs and the directory to save them
> save_graphs <- TRUE  # Set to TRUE to save graphs as PNG

> graph_save_dir <- file.path(output_dir, model_name)  # Directory to save graphs

> # ----------------------------#
> # 1. Load Necessary Libraries
> # ----------------------------#
> 
> # Load required libraries
> library(SSN2)

> library(SSNbler)

> library(sf)

> library(dplyr)

> library(purrr)

> library(ggplot2)

> library(lmtest)

> library(spdep)

> library(classInt)   # Required for knearneigh

> library(broom)      # For tidy() and glance() functions

> library(grid)       # For grid.newpage()

> if (!dir.exists(graph_save_dir)) {
+   dir.create(graph_save_dir, recursive = TRUE)
+ }

> # ----------------------------#
> # 2. Read Spatial Data
> # ----------------------------#
> 
> # Read the streams dataset
> ET_streams <- st_read(s .... [TRUNCATED] 
Reading layer `streams_100k' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\streams_100k.gpkg' using driver `GPKG'
Simple feature collection with 643 features and 2 fields
Geometry type: LINESTRING
Dimension:     XY
Bounding box:  xmin: 404042.6 ymin: 4447904 xmax: 414579.6 ymax: 4466669
Projected CRS: NAD83 / UTM zone 13N

> # Read the observation points dataset
> ET_obs <- st_read(obs_points_path)
Reading layer `ET Full ssn points' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\Combined Watersheds\ET Full ssn points.gpkg' using driver `GPKG'
Simple feature collection with 645 features and 60 fields
Geometry type: POINT
Dimension:     XY
Bounding box:  xmin: 407401.1 ymin: 4449827 xmax: 413032.9 ymax: 4464548
Projected CRS: NAD83 / UTM zone 13N

> # Uncomment the following line if you encounter an error about Multilinestrings
> # ET_streams <- st_cast(ET_streams, "LINESTRING")
> 
> # --------- .... [TRUNCATED] 

> # Create a distance matrix for spatial relationships
> # Purpose: Define spatial dependencies based on distances between sites
> ssn_create_distmat( .... [TRUNCATED] 

> # ----------------------------#
> # 4. Model Fitting and Output
> # ----------------------------#
> 
> # Redirect output to the specified file and a .... [TRUNCATED] 

> model_name
[1] "glm ch_sfm.erosion.norm VIF 3 ws_re"

> model_formula
ch_sfm.erosion.norm ~ ch_slope.median + ch_curvature.median + 
    ch_valley_width + ch_central.slope.difference + ch_channel.width.over.valley.width + 
    ch_slope.over.width.central.diff + hs_area + hs_slope.median + 
    hs_eastness.median + hs_curvature.median + hs_ndvi.range + 
    hs_dnbr.median + hs_drainage_density

> ssn_mod <- ssn_glm(
+   formula = model_formula,
+   ssn.object = ET_ssn,
+   family = "Gamma",
+   tailup_type = "exponential",
+   taildown_type = .... [TRUNCATED] 

> # --------------------------------------------------
> # Spatial Statistical Modeling with SSN2
> # ------------------------------------------------ .... [TRUNCATED] 

> # Specify the input and output directories
> input_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/Inputs"

> output_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/SSN ET/ET Full ws_re"

> model_name <- "glm ch_sfm.erosion.norm VIF 3 ws_re"

> obs_points_path <- file.path(input_dir, "Combined Watersheds", "ET Full ssn points.gpkg")

> read_ssn <- TRUE # whether to create a new ssn (FALSE) or read the pre-existing ssn (TRUE)

> # Use file.path to create platform-independent file paths
> streams_path <- file.path(input_dir, "streams_100k.gpkg")

> ssn_path <- file.path(output_dir, "1_ET_Full_logtrans_independent_vars.ssn")

> output_file <- file.path(output_dir, model_name, "Results.txt")

> lsn_out <- file.path(output_dir, "0_lsn")

> # Define whether to save graphs and the directory to save them
> save_graphs <- TRUE  # Set to TRUE to save graphs as PNG

> graph_save_dir <- file.path(output_dir, model_name)  # Directory to save graphs

> # ----------------------------#
> # 1. Load Necessary Libraries
> # ----------------------------#
> 
> # Load required libraries
> library(SSN2)

> library(SSNbler)

> library(sf)

> library(dplyr)

> library(purrr)

> library(ggplot2)

> library(lmtest)

> library(spdep)

> library(classInt)   # Required for knearneigh

> library(broom)      # For tidy() and glance() functions

> library(grid)       # For grid.newpage()

> if (!dir.exists(graph_save_dir)) {
+   dir.create(graph_save_dir, recursive = TRUE)
+ }

> # ----------------------------#
> # 2. Read Spatial Data
> # ----------------------------#
> 
> # Read the streams dataset
> ET_streams <- st_read(s .... [TRUNCATED] 
Reading layer `streams_100k' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\streams_100k.gpkg' using driver `GPKG'
Simple feature collection with 643 features and 2 fields
Geometry type: LINESTRING
Dimension:     XY
Bounding box:  xmin: 404042.6 ymin: 4447904 xmax: 414579.6 ymax: 4466669
Projected CRS: NAD83 / UTM zone 13N

> # Read the observation points dataset
> ET_obs <- st_read(obs_points_path)
Reading layer `ET Full ssn points' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\Combined Watersheds\ET Full ssn points.gpkg' using driver `GPKG'
Simple feature collection with 645 features and 60 fields
Geometry type: POINT
Dimension:     XY
Bounding box:  xmin: 407401.1 ymin: 4449827 xmax: 413032.9 ymax: 4464548
Projected CRS: NAD83 / UTM zone 13N

> # Uncomment the following line if you encounter an error about Multilinestrings
> # ET_streams <- st_cast(ET_streams, "LINESTRING")
> 
> # --------- .... [TRUNCATED] 

> # Create a distance matrix for spatial relationships
> # Purpose: Define spatial dependencies based on distances between sites
> ssn_create_distmat( .... [TRUNCATED] 

> # ----------------------------#
> # 4. Model Fitting and Output
> # ----------------------------#
> 
> # Redirect output to the specified file and a .... [TRUNCATED] 

> model_name
[1] "glm ch_sfm.erosion.norm VIF 3 ws_re"

> model_formula
ch_sfm.erosion.norm ~ ch_slope.median + ch_flow.accumulation.max + 
    ch_valley_width + ch_central.slope.difference + hs_ndvi.range + 
    (1 | ch_watershed)

> ssn_mod <- ssn_glm(
+   formula = model_formula,
+   ssn.object = ET_ssn,
+   family = "Gamma",
+   tailup_type = "exponential",
+   taildown_type = .... [TRUNCATED] 

> # --------------------------------------------------
> # Spatial Statistical Modeling with SSN2
> # ------------------------------------------------ .... [TRUNCATED] 

> # Specify the input and output directories
> input_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/Inputs"

> output_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/SSN ET/ET Full ws_re"

> model_name <- "glm ch_sfm.erosion.norm VIF 3 ws_re"

> obs_points_path <- file.path(input_dir, "Combined Watersheds", "ET Full ssn points.gpkg")

> read_ssn <- TRUE # whether to create a new ssn (FALSE) or read the pre-existing ssn (TRUE)

> # Use file.path to create platform-independent file paths
> streams_path <- file.path(input_dir, "streams_100k.gpkg")

> ssn_path <- file.path(output_dir, "1_ET_Full_logtrans_independent_vars.ssn")

> output_file <- file.path(output_dir, model_name, "Results.txt")

> lsn_out <- file.path(output_dir, "0_lsn")

> # Define whether to save graphs and the directory to save them
> save_graphs <- TRUE  # Set to TRUE to save graphs as PNG

> graph_save_dir <- file.path(output_dir, model_name)  # Directory to save graphs

> # ----------------------------#
> # 1. Load Necessary Libraries
> # ----------------------------#
> 
> # Load required libraries
> library(SSN2)

> library(SSNbler)

> library(sf)

> library(dplyr)

> library(purrr)

> library(ggplot2)

> library(lmtest)

> library(spdep)

> library(classInt)   # Required for knearneigh

> library(broom)      # For tidy() and glance() functions

> library(grid)       # For grid.newpage()

> if (!dir.exists(graph_save_dir)) {
+   dir.create(graph_save_dir, recursive = TRUE)
+ }

> # ----------------------------#
> # 2. Read Spatial Data
> # ----------------------------#
> 
> # Read the streams dataset
> ET_streams <- st_read(s .... [TRUNCATED] 
Reading layer `streams_100k' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\streams_100k.gpkg' using driver `GPKG'
Simple feature collection with 643 features and 2 fields
Geometry type: LINESTRING
Dimension:     XY
Bounding box:  xmin: 404042.6 ymin: 4447904 xmax: 414579.6 ymax: 4466669
Projected CRS: NAD83 / UTM zone 13N

> # Read the observation points dataset
> ET_obs <- st_read(obs_points_path)
Reading layer `ET Full ssn points' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\Combined Watersheds\ET Full ssn points.gpkg' using driver `GPKG'
Simple feature collection with 645 features and 60 fields
Geometry type: POINT
Dimension:     XY
Bounding box:  xmin: 407401.1 ymin: 4449827 xmax: 413032.9 ymax: 4464548
Projected CRS: NAD83 / UTM zone 13N

> # Uncomment the following line if you encounter an error about Multilinestrings
> # ET_streams <- st_cast(ET_streams, "LINESTRING")
> 
> # --------- .... [TRUNCATED] 

> # Create a distance matrix for spatial relationships
> # Purpose: Define spatial dependencies based on distances between sites
> ssn_create_distmat( .... [TRUNCATED] 

> # ----------------------------#
> # 4. Model Fitting and Output
> # ----------------------------#
> 
> # Redirect output to the specified file and a .... [TRUNCATED] 

> # --------------------------------------------------
> # Spatial Statistical Modeling with SSN2
> # ------------------------------------------------ .... [TRUNCATED] 

> # Specify the input and output directories
> input_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/Inputs"

> output_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/SSN ET/ET Full ws_re"

> model_name <- "glm ch_sfm.erosion.norm VIF 3 ws_re"

> obs_points_path <- file.path(input_dir, "Combined Watersheds", "ET Full ssn points.gpkg")

> read_ssn <- TRUE # whether to create a new ssn (FALSE) or read the pre-existing ssn (TRUE)

> # Use file.path to create platform-independent file paths
> streams_path <- file.path(input_dir, "streams_100k.gpkg")

> ssn_path <- file.path(output_dir, "1_ET_Full_logtrans_independent_vars.ssn")

> output_file <- file.path(output_dir, model_name, "Results.txt")

> lsn_out <- file.path(output_dir, "0_lsn")

> # Define whether to save graphs and the directory to save them
> save_graphs <- TRUE  # Set to TRUE to save graphs as PNG

> graph_save_dir <- file.path(output_dir, model_name)  # Directory to save graphs

> # ----------------------------#
> # 1. Load Necessary Libraries
> # ----------------------------#
> 
> # Load required libraries
> library(SSN2)

> library(SSNbler)

> library(sf)

> library(dplyr)

> library(purrr)

> library(ggplot2)

> library(lmtest)

> library(spdep)

> library(classInt)   # Required for knearneigh

> library(broom)      # For tidy() and glance() functions

> library(grid)       # For grid.newpage()

> if (!dir.exists(graph_save_dir)) {
+   dir.create(graph_save_dir, recursive = TRUE)
+ }

> # ----------------------------#
> # 2. Read Spatial Data
> # ----------------------------#
> 
> # Read the streams dataset
> ET_streams <- st_read(s .... [TRUNCATED] 
Reading layer `streams_100k' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\streams_100k.gpkg' using driver `GPKG'
Simple feature collection with 643 features and 2 fields
Geometry type: LINESTRING
Dimension:     XY
Bounding box:  xmin: 404042.6 ymin: 4447904 xmax: 414579.6 ymax: 4466669
Projected CRS: NAD83 / UTM zone 13N

> # Read the observation points dataset
> ET_obs <- st_read(obs_points_path)
Reading layer `ET Full ssn points' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\Combined Watersheds\ET Full ssn points.gpkg' using driver `GPKG'
Simple feature collection with 645 features and 60 fields
Geometry type: POINT
Dimension:     XY
Bounding box:  xmin: 407401.1 ymin: 4449827 xmax: 413032.9 ymax: 4464548
Projected CRS: NAD83 / UTM zone 13N

> # Uncomment the following line if you encounter an error about Multilinestrings
> # ET_streams <- st_cast(ET_streams, "LINESTRING")
> 
> # --------- .... [TRUNCATED] 

> # Create a distance matrix for spatial relationships
> # Purpose: Define spatial dependencies based on distances between sites
> ssn_create_distmat( .... [TRUNCATED] 

> # ----------------------------#
> # 4. Model Fitting and Output
> # ----------------------------#
> 
> # Redirect output to the specified file and a .... [TRUNCATED] 

> # --------------------------------------------------
> # Spatial Statistical Modeling with SSN2
> # ------------------------------------------------ .... [TRUNCATED] 

> # Define the formula for the ssn_lm function
> # You can modify this formula as needed for different analyses
> model_formula <- as.formula(
+   "ch ..." ... [TRUNCATED] 

> # Specify the input and output directories
> input_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/Inputs"

> output_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/SSN ET/ET Full ws_re"

> model_name <- "glm ch_sfm.erosion.norm VIF 3 ws_re"

> obs_points_path <- file.path(input_dir, "Combined Watersheds", "ET Full ssn points.gpkg")

> read_ssn <- TRUE # whether to create a new ssn (FALSE) or read the pre-existing ssn (TRUE)

> # Use file.path to create platform-independent file paths
> streams_path <- file.path(input_dir, "streams_100k.gpkg")

> ssn_path <- file.path(output_dir, "1_ET_Full_logtrans_independent_vars.ssn")

> output_file <- file.path(output_dir, model_name, "Results.txt")

> lsn_out <- file.path(output_dir, "0_lsn")

> # Define whether to save graphs and the directory to save them
> save_graphs <- TRUE  # Set to TRUE to save graphs as PNG

> graph_save_dir <- file.path(output_dir, model_name)  # Directory to save graphs

> # ----------------------------#
> # 1. Load Necessary Libraries
> # ----------------------------#
> 
> # Load required libraries
> library(SSN2)

> library(SSNbler)

> library(sf)

> library(dplyr)

> library(purrr)

> library(ggplot2)

> library(lmtest)

> library(spdep)

> library(classInt)   # Required for knearneigh

> library(broom)      # For tidy() and glance() functions

> library(grid)       # For grid.newpage()

> if (!dir.exists(graph_save_dir)) {
+   dir.create(graph_save_dir, recursive = TRUE)
+ }

> # ----------------------------#
> # 2. Read Spatial Data
> # ----------------------------#
> 
> # Read the streams dataset
> ET_streams <- st_read(s .... [TRUNCATED] 
Reading layer `streams_100k' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\streams_100k.gpkg' using driver `GPKG'
Simple feature collection with 643 features and 2 fields
Geometry type: LINESTRING
Dimension:     XY
Bounding box:  xmin: 404042.6 ymin: 4447904 xmax: 414579.6 ymax: 4466669
Projected CRS: NAD83 / UTM zone 13N

> # Read the observation points dataset
> ET_obs <- st_read(obs_points_path)
Reading layer `ET Full ssn points' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\Combined Watersheds\ET Full ssn points.gpkg' using driver `GPKG'
Simple feature collection with 645 features and 60 fields
Geometry type: POINT
Dimension:     XY
Bounding box:  xmin: 407401.1 ymin: 4449827 xmax: 413032.9 ymax: 4464548
Projected CRS: NAD83 / UTM zone 13N

> # Uncomment the following line if you encounter an error about Multilinestrings
> # ET_streams <- st_cast(ET_streams, "LINESTRING")
> 
> # --------- .... [TRUNCATED] 

> # Create a distance matrix for spatial relationships
> # Purpose: Define spatial dependencies based on distances between sites
> ssn_create_distmat( .... [TRUNCATED] 

> # ----------------------------#
> # 4. Model Fitting and Output
> # ----------------------------#
> 
> # Redirect output to the specified file and a .... [TRUNCATED] 

> model_name
[1] "glm ch_sfm.erosion.norm VIF 3 ws_re"

> model_formula
ch_sfm.erosion.norm ~ ch_slope.median + (1 | ch_watershed)

> ssn_mod <- ssn_glm(
+   formula = model_formula,
+   ssn.object = ET_ssn,
+   family = "Gamma",
+   tailup_type = "exponential",
+   taildown_type = .... [TRUNCATED] 

> # --------------------------------------------------
> # Spatial Statistical Modeling with SSN2
> # ------------------------------------------------ .... [TRUNCATED] 

> # Define the formula for the ssn_lm function
> # You can modify this formula as needed for different analyses
> model_formula <- as.formula(
+   "ch ..." ... [TRUNCATED] 

> # Specify the input and output directories
> input_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/Inputs"

> output_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/SSN ET/ET Full ws_re"

> model_name <- "glm ch_sfm.erosion.norm VIF 3 ws_re"

> obs_points_path <- file.path(input_dir, "Combined Watersheds", "ET Full ssn points.gpkg")

> read_ssn <- TRUE # whether to create a new ssn (FALSE) or read the pre-existing ssn (TRUE)

> # Use file.path to create platform-independent file paths
> streams_path <- file.path(input_dir, "streams_100k.gpkg")

> ssn_path <- file.path(output_dir, "1_ET_Full_logtrans_independent_vars.ssn")

> output_file <- file.path(output_dir, model_name, "Results.txt")

> lsn_out <- file.path(output_dir, "0_lsn")

> # Define whether to save graphs and the directory to save them
> save_graphs <- TRUE  # Set to TRUE to save graphs as PNG

> graph_save_dir <- file.path(output_dir, model_name)  # Directory to save graphs

> # ----------------------------#
> # 1. Load Necessary Libraries
> # ----------------------------#
> 
> # Load required libraries
> library(SSN2)

> library(SSNbler)

> library(sf)

> library(dplyr)

> library(purrr)

> library(ggplot2)

> library(lmtest)

> library(spdep)

> library(classInt)   # Required for knearneigh

> library(broom)      # For tidy() and glance() functions

> library(grid)       # For grid.newpage()

> if (!dir.exists(graph_save_dir)) {
+   dir.create(graph_save_dir, recursive = TRUE)
+ }

> # ----------------------------#
> # 2. Read Spatial Data
> # ----------------------------#
> 
> # Read the streams dataset
> ET_streams <- st_read(s .... [TRUNCATED] 
Reading layer `streams_100k' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\streams_100k.gpkg' using driver `GPKG'
Simple feature collection with 643 features and 2 fields
Geometry type: LINESTRING
Dimension:     XY
Bounding box:  xmin: 404042.6 ymin: 4447904 xmax: 414579.6 ymax: 4466669
Projected CRS: NAD83 / UTM zone 13N

> # Read the observation points dataset
> ET_obs <- st_read(obs_points_path)
Reading layer `ET Full ssn points' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\Combined Watersheds\ET Full ssn points.gpkg' using driver `GPKG'
Simple feature collection with 645 features and 60 fields
Geometry type: POINT
Dimension:     XY
Bounding box:  xmin: 407401.1 ymin: 4449827 xmax: 413032.9 ymax: 4464548
Projected CRS: NAD83 / UTM zone 13N

> # Uncomment the following line if you encounter an error about Multilinestrings
> # ET_streams <- st_cast(ET_streams, "LINESTRING")
> 
> # --------- .... [TRUNCATED] 

> # Create a distance matrix for spatial relationships
> # Purpose: Define spatial dependencies based on distances between sites
> ssn_create_distmat( .... [TRUNCATED] 

> # ----------------------------#
> # 4. Model Fitting and Output
> # ----------------------------#
> 
> # Redirect output to the specified file and a .... [TRUNCATED] 

> model_name
[1] "glm ch_sfm.erosion.norm VIF 3 ws_re"

> model_formula
ch_sfm.erosion.norm ~ (1 | ch_watershed)

> ssn_mod <- ssn_glm(
+   formula = model_formula,
+   ssn.object = ET_ssn,
+   family = "Gamma",
+   tailup_type = "exponential",
+   taildown_type = .... [TRUNCATED] 
NULL
< table of extent 0 >

> # --------------------------------------------------
> # Spatial Statistical Modeling with SSN2
> # ------------------------------------------------ .... [TRUNCATED] 

> # Specify the input and output directories
> input_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/Inputs"

> output_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/SSN ET/ET Full ws_re"

> model_name <- "glm ch_sfm.erosion.norm VIF 3 ws_re"

> obs_points_path <- file.path(input_dir, "Combined Watersheds", "ET Full ssn points.gpkg")

> read_ssn <- TRUE # whether to create a new ssn (FALSE) or read the pre-existing ssn (TRUE)

> # Use file.path to create platform-independent file paths
> streams_path <- file.path(input_dir, "streams_100k.gpkg")

> ssn_path <- file.path(output_dir, "1_ET_Full_logtrans_independent_vars.ssn")

> output_file <- file.path(output_dir, model_name, "Results.txt")

> lsn_out <- file.path(output_dir, "0_lsn")

> # Define whether to save graphs and the directory to save them
> save_graphs <- TRUE  # Set to TRUE to save graphs as PNG

> graph_save_dir <- file.path(output_dir, model_name)  # Directory to save graphs

> # ----------------------------#
> # 1. Load Necessary Libraries
> # ----------------------------#
> 
> # Load required libraries
> library(SSN2)

> library(SSNbler)

> library(sf)

> library(dplyr)

> library(purrr)

> library(ggplot2)

> library(lmtest)

> library(spdep)

> library(classInt)   # Required for knearneigh

> library(broom)      # For tidy() and glance() functions

> library(grid)       # For grid.newpage()

> if (!dir.exists(graph_save_dir)) {
+   dir.create(graph_save_dir, recursive = TRUE)
+ }

> # ----------------------------#
> # 2. Read Spatial Data
> # ----------------------------#
> 
> # Read the streams dataset
> ET_streams <- st_read(s .... [TRUNCATED] 
Reading layer `streams_100k' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\streams_100k.gpkg' using driver `GPKG'
Simple feature collection with 643 features and 2 fields
Geometry type: LINESTRING
Dimension:     XY
Bounding box:  xmin: 404042.6 ymin: 4447904 xmax: 414579.6 ymax: 4466669
Projected CRS: NAD83 / UTM zone 13N

> # Read the observation points dataset
> ET_obs <- st_read(obs_points_path)
Reading layer `ET Full ssn points' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\Combined Watersheds\ET Full ssn points.gpkg' using driver `GPKG'
Simple feature collection with 645 features and 60 fields
Geometry type: POINT
Dimension:     XY
Bounding box:  xmin: 407401.1 ymin: 4449827 xmax: 413032.9 ymax: 4464548
Projected CRS: NAD83 / UTM zone 13N

> # Uncomment the following line if you encounter an error about Multilinestrings
> # ET_streams <- st_cast(ET_streams, "LINESTRING")
> 
> # --------- .... [TRUNCATED] 

> # Create a distance matrix for spatial relationships
> # Purpose: Define spatial dependencies based on distances between sites
> ssn_create_distmat( .... [TRUNCATED] 

> # ----------------------------#
> # 4. Model Fitting and Output
> # ----------------------------#
> 
> # Redirect output to the specified file and a .... [TRUNCATED] 

> # --------------------------------------------------
> # Spatial Statistical Modeling with SSN2
> # ------------------------------------------------ .... [TRUNCATED] 

> # Define the formula for the ssn_lm function
> # You can modify this formula as needed for different analyses
> model_formula <- as.formula(
+   "ch ..." ... [TRUNCATED] 

> # Specify the input and output directories
> input_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/Inputs"

> output_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/SSN ET/ET Full ws_re"

> model_name <- "glm ch_sfm.erosion.norm VIF 3 ws_re"

> obs_points_path <- file.path(input_dir, "Combined Watersheds", "ET Full ssn points.gpkg")

> read_ssn <- TRUE # whether to create a new ssn (FALSE) or read the pre-existing ssn (TRUE)

> # Use file.path to create platform-independent file paths
> streams_path <- file.path(input_dir, "streams_100k.gpkg")

> ssn_path <- file.path(output_dir, "1_ET_Full_logtrans_independent_vars.ssn")

> output_file <- file.path(output_dir, model_name, "Results.txt")

> lsn_out <- file.path(output_dir, "0_lsn")

> # Define whether to save graphs and the directory to save them
> save_graphs <- TRUE  # Set to TRUE to save graphs as PNG

> graph_save_dir <- file.path(output_dir, model_name)  # Directory to save graphs

> # ----------------------------#
> # 1. Load Necessary Libraries
> # ----------------------------#
> 
> # Load required libraries
> library(SSN2)

> library(SSNbler)

> library(sf)

> library(dplyr)

> library(purrr)

> library(ggplot2)

> library(lmtest)

> library(spdep)

> library(classInt)   # Required for knearneigh

> library(broom)      # For tidy() and glance() functions

> library(grid)       # For grid.newpage()

> if (!dir.exists(graph_save_dir)) {
+   dir.create(graph_save_dir, recursive = TRUE)
+ }

> # ----------------------------#
> # 2. Read Spatial Data
> # ----------------------------#
> 
> # Read the streams dataset
> ET_streams <- st_read(s .... [TRUNCATED] 
Reading layer `streams_100k' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\streams_100k.gpkg' using driver `GPKG'
Simple feature collection with 643 features and 2 fields
Geometry type: LINESTRING
Dimension:     XY
Bounding box:  xmin: 404042.6 ymin: 4447904 xmax: 414579.6 ymax: 4466669
Projected CRS: NAD83 / UTM zone 13N

> # Read the observation points dataset
> ET_obs <- st_read(obs_points_path)
Reading layer `ET Full ssn points' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\Combined Watersheds\ET Full ssn points.gpkg' using driver `GPKG'
Simple feature collection with 645 features and 60 fields
Geometry type: POINT
Dimension:     XY
Bounding box:  xmin: 407401.1 ymin: 4449827 xmax: 413032.9 ymax: 4464548
Projected CRS: NAD83 / UTM zone 13N

> # Uncomment the following line if you encounter an error about Multilinestrings
> # ET_streams <- st_cast(ET_streams, "LINESTRING")
> 
> # --------- .... [TRUNCATED] 

> # Create a distance matrix for spatial relationships
> # Purpose: Define spatial dependencies based on distances between sites
> ssn_create_distmat( .... [TRUNCATED] 

> # ----------------------------#
> # 4. Model Fitting and Output
> # ----------------------------#
> 
> # Redirect output to the specified file and a .... [TRUNCATED] 

> model_name
[1] "glm ch_sfm.erosion.norm VIF 3 ws_re"

> model_formula
ch_sfm.erosion.norm ~ ch_slope.median + ch_curvature.median + 
    ch_valley_width + ch_central.slope.difference + ch_channel.width.over.valley.width + 
    ch_slope.over.width.central.diff + hs_area + hs_slope.median + 
    hs_eastness.median + hs_curvature.median + hs_ndvi.range + 
    hs_dnbr.median + hs_drainage_density + ch_watershed

> ssn_mod <- ssn_glm(
+   formula = model_formula,
+   ssn.object = ET_ssn,
+   family = "Gamma",
+   tailup_type = "exponential",
+   taildown_type = .... [TRUNCATED] 

> # Print the summary of the model to the file and console
> print(summary(ssn_mod))

Call:
ssn_glm(formula = model_formula, ssn.object = ET_ssn, family = "Gamma", 
    tailup_type = "exponential", taildown_type = "none", euclid_type = "gaussian", 
    additive = "afv_flow_accum")

Deviance Residuals:
     Min       1Q   Median       3Q      Max 
-1.97575 -0.29152 -0.01429  0.22337  1.14741 

Coefficients (fixed):
                                    Estimate Std. Error z value Pr(>|z|)   
(Intercept)                         0.081420   1.391434   0.059  0.95334   
ch_slope.median                     0.151747   0.070068   2.166  0.03033 * 
ch_curvature.median                 0.009959   0.066831   0.149  0.88154   
ch_valley_width                    -0.054263   0.075628  -0.717  0.47307   
ch_central.slope.difference        -0.051828   0.030209  -1.716  0.08622 . 
ch_channel.width.over.valley.width  0.082748   0.075513   1.096  0.27316   
ch_slope.over.width.central.diff    0.056676   0.021293   2.662  0.00777 **
hs_area                            -0.021892   0.041007  -0.534  0.59344   
hs_slope.median                     0.078084   0.089237   0.875  0.38156   
hs_eastness.median                 -0.002436   0.043498  -0.056  0.95535   
hs_curvature.median                 0.008276   0.029486   0.281  0.77896   
hs_ndvi.range                      -0.060944   0.063676  -0.957  0.33852   
hs_dnbr.median                     -0.030411   0.074332  -0.409  0.68244   
hs_drainage_density                 2.149034  13.965222   0.154  0.87770   
ch_watershed                       -0.612585   0.222942  -2.748  0.00600 **
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Pseudo R-squared: 0.01247

Coefficients (covariance):
              Effect     Parameter   Estimate
  tailup exponential  de (parsill)  2.514e+00
  tailup exponential         range  2.041e+02
     euclid gaussian  de (parsill)  1.219e+00
     euclid gaussian         range  3.394e+04
              nugget        nugget  3.303e-04
          dispersion    dispersion  2.975e+00


> # Print variance components of the model
> varcomp(ssn_mod)
# A tibble: 5 × 2
  varcomp            proportion
  <chr>                   <dbl>
1 Covariates (PR-sq)  0.0125   
2 tailup_de           0.665    
3 taildown_de         0        
4 euclid_de           0.322    
5 nugget              0.0000874

> # Tidy the model output with confidence intervals and print
> print(tidy(ssn_mod, conf.int = TRUE))  
# A tibble: 15 × 7
   term                               estimate std.error statistic p.value conf.low conf.high
   <chr>                                 <dbl>     <dbl>     <dbl>   <dbl>    <dbl>     <dbl>
 1 (Intercept)                         0.0814     1.39      0.0585 0.953    -2.65     2.81   
 2 ch_central.slope.difference        -0.0518     0.0302   -1.72   0.0862   -0.111    0.00738
 3 ch_channel.width.over.valley.width  0.0827     0.0755    1.10   0.273    -0.0653   0.231  
 4 ch_curvature.median                 0.00996    0.0668    0.149  0.882    -0.121    0.141  
 5 ch_slope.median                     0.152      0.0701    2.17   0.0303    0.0144   0.289  
 6 ch_slope.over.width.central.diff    0.0567     0.0213    2.66   0.00777   0.0149   0.0984 
 7 ch_valley_width                    -0.0543     0.0756   -0.717  0.473    -0.202    0.0940 
 8 ch_watershed                       -0.613      0.223    -2.75   0.00600  -1.05    -0.176  
 9 hs_area                            -0.0219     0.0410   -0.534  0.593    -0.102    0.0585 
10 hs_curvature.median                 0.00828    0.0295    0.281  0.779    -0.0495   0.0661 
11 hs_dnbr.median                     -0.0304     0.0743   -0.409  0.682    -0.176    0.115  
12 hs_drainage_density                 2.15      14.0       0.154  0.878   -25.2     29.5    
13 hs_eastness.median                 -0.00244    0.0435   -0.0560 0.955    -0.0877   0.0828 
14 hs_ndvi.range                      -0.0609     0.0637   -0.957  0.339    -0.186    0.0639 
15 hs_slope.median                     0.0781     0.0892    0.875  0.382    -0.0968   0.253  

> # Provide a glance summary of the model and print
> print(glance(ssn_mod))
# A tibble: 1 × 9
      n     p  npar value   AIC  AICc logLik deviance pseudo.r.squared
  <int> <dbl> <int> <dbl> <dbl> <dbl>  <dbl>    <dbl>            <dbl>
1   645    15     6 1017. 1029. 1029.  -508.     131.           0.0125

> # Perform Leave-One-Out Cross Validation and print
> print("Leave One Out Cross Validation")
[1] "Leave One Out Cross Validation"

> loocv_results <- loocv(ssn_mod)

> print(loocv_results)
# A tibble: 1 × 4
     bias  MSPE RMSPE   RAV
    <dbl> <dbl> <dbl> <dbl>
1 -0.0674 0.154 0.392 0.493

> # Stop redirecting output
> sink()

> # ----------------------------#
> # 5. Model Evaluation
> # ----------------------------#
> 
> # Extract residuals and fitted values from the model
 .... [TRUNCATED] 

> fitted_values <- fitted(ssn_mod)   

> # ----------------------------#
> # 6. Plotting and Saving Graphs
> # ----------------------------#
> 
> 
> # Create the graph save directory if sav .... [TRUNCATED] 

> # ----------------------------#
> # 7. Residuals vs Fitted Values Plot
> # ----------------------------#
> 
> # Purpose:
> #   - Linearity: Ensure t .... [TRUNCATED] 

> # Create the Residuals vs Fitted Values plot
> resid_fitted_plot <- ggplot(data.frame(Fitted = fitted_values, Residuals = residuals), aes(x = Fitted .... [TRUNCATED] 

> # Display the plot
> print(resid_fitted_plot)

> # Save the plot if saving is enabled
> if (save_graphs) {
+   ggsave(filename = file.path(graph_save_dir, "Residuals_vs_Fitted.png"), plot = resid_f .... [TRUNCATED] 
[1] "Saved Residuals vs Fitted Values plot."

> # ----------------------------#
> # 8. Q-Q Plot for Residuals
> # ----------------------------#
> 
> # Purpose:
> #   - Normality: Verify that resid .... [TRUNCATED] 

> # Enhanced Q-Q Plot using ggplot2
> qq_plot <- ggplot(data.frame(Residuals = residuals), aes(sample = Residuals)) +
+   stat_qq(color = "blue") +
+  .... [TRUNCATED] 

> # Display the ggplot2 Q-Q plot
> print(qq_plot)

> # Save the ggplot2 Q-Q plot if saving is enabled
> if (save_graphs) {
+   ggsave(filename = file.path(graph_save_dir, "QQ_Plot_Residuals_GGPlot2.png ..." ... [TRUNCATED] 
[1] "Saved ggplot2 Q-Q Plot of Residuals."

> # ----------------------------#
> # 9. Histogram of Residuals
> # ----------------------------#
> 
> # Purpose:
> #   - Normality
> #
> # What to Lo .... [TRUNCATED] 

> # Enhanced Histogram using ggplot2
> hist_plot <- ggplot(data.frame(Residuals = residuals), aes(x = Residuals)) +
+   geom_histogram(aes(y = ..densi .... [TRUNCATED] 

> # Display the ggplot2 histogram
> print(hist_plot)

> # Save the ggplot2 histogram if saving is enabled
> if (save_graphs) {
+   ggsave(filename = file.path(graph_save_dir, "Histogram_Residuals_GGPlot2. ..." ... [TRUNCATED] 
[1] "Saved ggplot2 Histogram of Residuals with Normal Curve."

> # Redirect output to the specified file and also print to console
> sink(output_file, append = TRUE, split = TRUE)

> print("")
[1] ""

> # ----------------------------#
> # 10. Statistical Tests
> # ----------------------------#
> 
> 
> # --------- Shapiro-Wilk Test for Normality ---- .... [TRUNCATED] 
[1] "-------- Shapiro-Wilk Test for Normality ---------"

> print("  - Normality: To check if the residuals are normally distributed.")
[1] "  - Normality: To check if the residuals are normally distributed."

> print("  - p-value > 0.05: Fail to reject null hypothesis (residuals are normally distributed).")
[1] "  - p-value > 0.05: Fail to reject null hypothesis (residuals are normally distributed)."

> print("  - p-value <= 0.05: Reject null hypothesis (residuals are not normally distributed).\n")
[1] "  - p-value <= 0.05: Reject null hypothesis (residuals are not normally distributed).\n"

> shapiro_test <- shapiro.test(residuals)

> print("Shapiro-Wilk Test Results:")
[1] "Shapiro-Wilk Test Results:"

> print(shapiro_test)

	Shapiro-Wilk normality test

data:  residuals
W = 0.97505, p-value = 5e-09


> # --------- Breusch-Pagan Test for Homoscedasticity ---------
> print("-------- Breusch-Pagan Test for Homoscedasticity ---------")
[1] "-------- Breusch-Pagan Test for Homoscedasticity ---------"

> print("  - Homoscedasticity: To check if residuals have constant variance across all levels of fitted values.")
[1] "  - Homoscedasticity: To check if residuals have constant variance across all levels of fitted values."

> print("  - p-value > 0.05: Fail to reject null hypothesis (homoscedasticity holds).")
[1] "  - p-value > 0.05: Fail to reject null hypothesis (homoscedasticity holds)."

> print("  - p-value <= 0.05: Reject null hypothesis (heteroscedasticity present).\n")
[1] "  - p-value <= 0.05: Reject null hypothesis (heteroscedasticity present).\n"

> # Extract the model frame from the ssn_lm model
> data_ssn <- model.frame(ssn_mod)

> # Perform Breusch-Pagan Test
> bp_test <- bptest(ssn_mod)

> print("Breusch-Pagan Test Results:")
[1] "Breusch-Pagan Test Results:"

> print(bp_test)

	studentized Breusch-Pagan test

data:  ssn_mod
BP = 53.915, df = 14, p-value = 1.328e-06


> # --------- Moran's I Test for Spatial Autocorrelation ---------
> print("\n-------- Moran's I Test for Spatial Autocorrelation ---------")
[1] "\n-------- Moran's I Test for Spatial Autocorrelation ---------"

> print("  - Spatial Autocorrelation: To determine if there is spatial autocorrelation in the residuals.")
[1] "  - Spatial Autocorrelation: To determine if there is spatial autocorrelation in the residuals."

> print("  - p-value > 0.05: Fail to reject null hypothesis (lack of spatial autocorrelation in residuals holds).")
[1] "  - p-value > 0.05: Fail to reject null hypothesis (lack of spatial autocorrelation in residuals holds)."

> print("  - p-value <= 0.05: Reject null hypothesis (spatial autocorrelation present).\n")
[1] "  - p-value <= 0.05: Reject null hypothesis (spatial autocorrelation present).\n"

> sink()

> # Extract spatial coordinates from the SSN object
> # Ensure that your SSN object has geometry information
> coords <- st_coordinates(ssn_get_data(s .... [TRUNCATED] 

> # Create a spatial weights matrix using k-nearest neighbors (k = 4 as an example)
> knn <- knearneigh(coords, k = 4)

> nb <- knn2nb(knn)

> lw <- nb2listw(nb, style = "W", zero.policy = TRUE)

> # Compute Moran's I
> moran_test <- moran.test(residuals, lw, zero.policy = TRUE)

> sink(output_file, append = TRUE, split = TRUE)

> print("Moran's I Test Results:")
[1] "Moran's I Test Results:"

> print(moran_test)

	Moran I test under randomisation

data:  residuals  
weights: lw    

Moran I statistic standard deviate = -6.569, p-value = 1
alternative hypothesis: greater
sample estimates:
Moran I statistic       Expectation          Variance 
    -0.1795996935     -0.0015527950      0.0007346234 


> # Stop redirecting output
> sink()

> # --------------------------------------------------
> # End of Script
> # --------------------------------------------------
> 
> 
> library(car)

> vif_result <- vif(lm(ch_sfm.erosion.norm ~ 
+                        ch_slope.median +
+                        ch_curvature.median +
+              .... [TRUNCATED] 

> # --------------------------------------------------
> # Spatial Statistical Modeling with SSN2
> # ------------------------------------------------ .... [TRUNCATED] 

> # Define the formula for the ssn_lm function
> # You can modify this formula as needed for different analyses
> model_formula <- as.formula(
+   "ch ..." ... [TRUNCATED] 

> # Specify the input and output directories
> input_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/Inputs"

> output_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/SSN ET/ET Full ws_re"

> model_name <- "glm ch_sfm.erosion.norm VIF 3 100 ct thresh ws_re"

> obs_points_path <- file.path(input_dir, "Combined Watersheds", "ET Full ssn points.gpkg")

> read_ssn <- FALSE # whether to create a new ssn (FALSE) or read the pre-existing ssn (TRUE)

> # Use file.path to create platform-independent file paths
> streams_path <- file.path(input_dir, "streams_100k.gpkg")

> ssn_path <- file.path(output_dir, "1_ET_Full_logtrans_independent_vars.ssn")

> output_file <- file.path(output_dir, model_name, "Results.txt")

> lsn_out <- file.path(output_dir, "0_lsn")

> # Define whether to save graphs and the directory to save them
> save_graphs <- TRUE  # Set to TRUE to save graphs as PNG

> graph_save_dir <- file.path(output_dir, model_name)  # Directory to save graphs

> # ----------------------------#
> # 1. Load Necessary Libraries
> # ----------------------------#
> 
> # Load required libraries
> library(SSN2)

> library(SSNbler)

> library(sf)

> library(dplyr)

> library(purrr)

> library(ggplot2)

> library(lmtest)

> library(spdep)

> library(classInt)   # Required for knearneigh

> library(broom)      # For tidy() and glance() functions

> library(grid)       # For grid.newpage()

> if (!dir.exists(graph_save_dir)) {
+   dir.create(graph_save_dir, recursive = TRUE)
+ }

> # ----------------------------#
> # 2. Read Spatial Data
> # ----------------------------#
> 
> # Read the streams dataset
> ET_streams <- st_read(s .... [TRUNCATED] 
Reading layer `streams_100k' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\streams_100k.gpkg' using driver `GPKG'
Simple feature collection with 643 features and 2 fields
Geometry type: LINESTRING
Dimension:     XY
Bounding box:  xmin: 404042.6 ymin: 4447904 xmax: 414579.6 ymax: 4466669
Projected CRS: NAD83 / UTM zone 13N

> # Read the observation points dataset
> ET_obs <- st_read(obs_points_path)
Reading layer `ET Full ssn points' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\Combined Watersheds\ET Full ssn points.gpkg' using driver `GPKG'
Simple feature collection with 645 features and 60 fields
Geometry type: POINT
Dimension:     XY
Bounding box:  xmin: 407401.1 ymin: 4449827 xmax: 413032.9 ymax: 4464548
Projected CRS: NAD83 / UTM zone 13N

> # Uncomment the following line if you encounter an error about Multilinestrings
> # ET_streams <- st_cast(ET_streams, "LINESTRING")
> 
> # --------- .... [TRUNCATED] 
[1] "Edge Attributes:"
[1] "rid"            "STRM_VAL"       "flow_accum_max" "Length"         "upDist"         "geometry"      
[1] "Site List Components:"
[1] "obs"
[1] "Updated Edge Attributes:"
[1] "rid"            "STRM_VAL"       "flow_accum_max" "Length"         "upDist"         "flow_accum_PI"  "afv_flow_accum" "geometry"      


SSN object is valid: TRUE

> # Create a distance matrix for spatial relationships
> # Purpose: Define spatial dependencies based on distances between sites
> ssn_create_distmat( .... [TRUNCATED] 

> # ----------------------------#
> # 4. Model Fitting and Output
> # ----------------------------#
> 
> # Redirect output to the specified file and a .... [TRUNCATED] 

> model_name
[1] "glm ch_sfm.erosion.norm VIF 3 100 ct thresh ws_re"

> model_formula
ch_sfm.erosion.norm ~ ch_elevation.mean + ch_slope.median + ch_flow.accumulation.max + 
    ch_curvature.median + ch_valley_width + ch_change.in.slope.over.width + 
    ch_channel.width.over.valley.width + ch_slope.over.width.central.diff + 
    ch_stream.power.central.diff + hs_hillslope.length + hs_slope.median + 
    hs_northness.median + hs_eastness.median + hs_curvature.median + 
    hs_bare.earth.mean + hs_ndvi.range + hs_dnbr.median + hs_drainage_density + 
    flow.accumulation.max + (1 | ch_watershed)

> ssn_mod <- ssn_glm(
+   formula = model_formula,
+   ssn.object = ET_ssn,
+   family = "Gamma",
+   tailup_type = "exponential",
+   taildown_type = .... [TRUNCATED] 

> # --------------------------------------------------
> # Spatial Statistical Modeling with SSN2
> # ------------------------------------------------ .... [TRUNCATED] 

> # Define the formula for the ssn_lm function
> # You can modify this formula as needed for different analyses
> model_formula <- as.formula(
+   "ch ..." ... [TRUNCATED] 

> # Specify the input and output directories
> input_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/Inputs"

> output_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/SSN ET/ET Full ws_re"

> model_name <- "glm ch_sfm.erosion.norm VIF 3 100 ct thresh ws_re"

> obs_points_path <- file.path(input_dir, "Combined Watersheds", "ET Full ssn points.gpkg")

> read_ssn <- TRUE # whether to create a new ssn (FALSE) or read the pre-existing ssn (TRUE)

> # Use file.path to create platform-independent file paths
> streams_path <- file.path(input_dir, "streams_100k.gpkg")

> ssn_path <- file.path(output_dir, "1_ET_Full_logtrans_independent_vars.ssn")

> output_file <- file.path(output_dir, model_name, "Results.txt")

> lsn_out <- file.path(output_dir, "0_lsn")

> # Define whether to save graphs and the directory to save them
> save_graphs <- TRUE  # Set to TRUE to save graphs as PNG

> graph_save_dir <- file.path(output_dir, model_name)  # Directory to save graphs

> # ----------------------------#
> # 1. Load Necessary Libraries
> # ----------------------------#
> 
> # Load required libraries
> library(SSN2)

> library(SSNbler)

> library(sf)

> library(dplyr)

> library(purrr)

> library(ggplot2)

> library(lmtest)

> library(spdep)

> library(classInt)   # Required for knearneigh

> library(broom)      # For tidy() and glance() functions

> library(grid)       # For grid.newpage()

> if (!dir.exists(graph_save_dir)) {
+   dir.create(graph_save_dir, recursive = TRUE)
+ }

> # ----------------------------#
> # 2. Read Spatial Data
> # ----------------------------#
> 
> # Read the streams dataset
> ET_streams <- st_read(s .... [TRUNCATED] 
Reading layer `streams_100k' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\streams_100k.gpkg' using driver `GPKG'
Simple feature collection with 643 features and 2 fields
Geometry type: LINESTRING
Dimension:     XY
Bounding box:  xmin: 404042.6 ymin: 4447904 xmax: 414579.6 ymax: 4466669
Projected CRS: NAD83 / UTM zone 13N

> # Read the observation points dataset
> ET_obs <- st_read(obs_points_path)
Reading layer `ET Full ssn points' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\Combined Watersheds\ET Full ssn points.gpkg' using driver `GPKG'
Simple feature collection with 645 features and 60 fields
Geometry type: POINT
Dimension:     XY
Bounding box:  xmin: 407401.1 ymin: 4449827 xmax: 413032.9 ymax: 4464548
Projected CRS: NAD83 / UTM zone 13N

> # Uncomment the following line if you encounter an error about Multilinestrings
> # ET_streams <- st_cast(ET_streams, "LINESTRING")
> 
> # --------- .... [TRUNCATED] 

> # Create a distance matrix for spatial relationships
> # Purpose: Define spatial dependencies based on distances between sites
> ssn_create_distmat( .... [TRUNCATED] 

> # ----------------------------#
> # 4. Model Fitting and Output
> # ----------------------------#
> 
> # Redirect output to the specified file and a .... [TRUNCATED] 

> model_name
[1] "glm ch_sfm.erosion.norm VIF 3 100 ct thresh ws_re"

> model_formula
ch_sfm.erosion.norm ~ ch_elevation.mean + ch_slope.median + ch_flow.accumulation.max + 
    ch_curvature.median + ch_valley_width + ch_change.in.slope.over.width + 
    ch_channel.width.over.valley.width + ch_slope.over.width.central.diff + 
    ch_stream.power.central.diff + hs_hillslope.length + hs_slope.median + 
    hs_northness.median + hs_eastness.median + hs_curvature.median + 
    hs_bare.earth.mean + hs_ndvi.range + hs_dnbr.median + hs_drainage_density + 
    flow.accumulation.max

> ssn_mod <- ssn_glm(
+   formula = model_formula,
+   ssn.object = ET_ssn,
+   family = "Gamma",
+   tailup_type = "exponential",
+   taildown_type = .... [TRUNCATED] 

> # Print the summary of the model to the file and console
> print(summary(ssn_mod))

Call:
ssn_glm(formula = model_formula, ssn.object = ET_ssn, family = "Gamma", 
    tailup_type = "exponential", taildown_type = "none", euclid_type = "gaussian", 
    additive = "afv_flow_accum", random = ~as.factor(ch_watershed))

Deviance Residuals:
    Min      1Q  Median      3Q     Max 
-1.9005 -0.2386 -0.0035  0.1847  1.0111 

Coefficients (fixed):
                                    Estimate Std. Error z value Pr(>|z|)  
(Intercept)                        -2.291130   1.000278  -2.290   0.0220 *
ch_elevation.mean                  -0.797335   0.943026  -0.846   0.3978  
ch_slope.median                     0.154667   0.071046   2.177   0.0295 *
ch_flow.accumulation.max            0.837915   0.754298   1.111   0.2666  
ch_curvature.median                 0.009497   0.066685   0.142   0.8868  
ch_valley_width                    -0.053729   0.075168  -0.715   0.4747  
ch_change.in.slope.over.width      -0.027491   0.017760  -1.548   0.1217  
ch_channel.width.over.valley.width  0.078486   0.075758   1.036   0.3002  
ch_slope.over.width.central.diff    0.045914   0.026656   1.722   0.0850 .
ch_stream.power.central.diff        0.004492   0.017657   0.254   0.7992  
hs_hillslope.length                -0.059319   0.046656  -1.271   0.2036  
hs_slope.median                     0.099233   0.089975   1.103   0.2701  
hs_northness.median                -0.097960   0.066669  -1.469   0.1417  
hs_eastness.median                 -0.015859   0.045612  -0.348   0.7281  
hs_curvature.median                 0.010601   0.030254   0.350   0.7260  
hs_bare.earth.mean                  0.074061   0.067308   1.100   0.2712  
hs_ndvi.range                      -0.056827   0.072440  -0.784   0.4328  
hs_dnbr.median                      0.006861   0.077904   0.088   0.9298  
hs_drainage_density                 3.230809  13.763039   0.235   0.8144  
flow.accumulation.max              -0.123641   0.093758  -1.319   0.1873  
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Pseudo R-squared: 0.02136

Coefficients (covariance):
              Effect                    Parameter   Estimate
  tailup exponential                 de (parsill)  1.540e+00
  tailup exponential                        range  9.958e+01
     euclid gaussian                 de (parsill)  2.340e+00
     euclid gaussian                        range  2.002e+03
              nugget                       nugget  8.270e-03
          dispersion                   dispersion  3.393e+00
              random  1 | as.factor(ch_watershed)  1.793e+00


> # Print variance components of the model
> varcomp(ssn_mod)
# A tibble: 6 × 2
  varcomp                     proportion
  <chr>                            <dbl>
1 Covariates (PR-sq)             0.0214 
2 tailup_de                      0.265  
3 taildown_de                    0      
4 euclid_de                      0.403  
5 nugget                         0.00142
6 1 | as.factor(ch_watershed)    0.309  

> # Tidy the model output with confidence intervals and print
> print(tidy(ssn_mod, conf.int = TRUE))  
# A tibble: 20 × 7
   term                               estimate std.error statistic p.value  conf.low conf.high
   <chr>                                 <dbl>     <dbl>     <dbl>   <dbl>     <dbl>     <dbl>
 1 (Intercept)                        -2.29       1.00     -2.29    0.0220  -4.25     -0.331  
 2 ch_change.in.slope.over.width      -0.0275     0.0178   -1.55    0.122   -0.0623    0.00732
 3 ch_channel.width.over.valley.width  0.0785     0.0758    1.04    0.300   -0.0700    0.227  
 4 ch_curvature.median                 0.00950    0.0667    0.142   0.887   -0.121     0.140  
 5 ch_elevation.mean                  -0.797      0.943    -0.846   0.398   -2.65      1.05   
 6 ch_flow.accumulation.max            0.838      0.754     1.11    0.267   -0.640     2.32   
 7 ch_slope.median                     0.155      0.0710    2.18    0.0295   0.0154    0.294  
 8 ch_slope.over.width.central.diff    0.0459     0.0267    1.72    0.0850  -0.00633   0.0982 
 9 ch_stream.power.central.diff        0.00449    0.0177    0.254   0.799   -0.0301    0.0391 
10 ch_valley_width                    -0.0537     0.0752   -0.715   0.475   -0.201     0.0936 
11 flow.accumulation.max              -0.124      0.0938   -1.32    0.187   -0.307     0.0601 
12 hs_bare.earth.mean                  0.0741     0.0673    1.10    0.271   -0.0579    0.206  
13 hs_curvature.median                 0.0106     0.0303    0.350   0.726   -0.0487    0.0699 
14 hs_dnbr.median                      0.00686    0.0779    0.0881  0.930   -0.146     0.160  
15 hs_drainage_density                 3.23      13.8       0.235   0.814  -23.7      30.2    
16 hs_eastness.median                 -0.0159     0.0456   -0.348   0.728   -0.105     0.0735 
17 hs_hillslope.length                -0.0593     0.0467   -1.27    0.204   -0.151     0.0321 
18 hs_ndvi.range                      -0.0568     0.0724   -0.784   0.433   -0.199     0.0852 
19 hs_northness.median                -0.0980     0.0667   -1.47    0.142   -0.229     0.0327 
20 hs_slope.median                     0.0992     0.0900    1.10    0.270   -0.0771    0.276  

> # Provide a glance summary of the model and print
> print(glance(ssn_mod))
# A tibble: 1 × 9
      n     p  npar value   AIC  AICc logLik deviance pseudo.r.squared
  <int> <dbl> <int> <dbl> <dbl> <dbl>  <dbl>    <dbl>            <dbl>
1   645    20     7 1013. 1027. 1028.  -507.     102.           0.0214

> # Perform Leave-One-Out Cross Validation and print
> print("Leave One Out Cross Validation")
[1] "Leave One Out Cross Validation"

> loocv_results <- loocv(ssn_mod)

> print(loocv_results)
# A tibble: 1 × 4
     bias  MSPE RMSPE   RAV
    <dbl> <dbl> <dbl> <dbl>
1 -0.0702 0.162 0.402 0.546

> # Stop redirecting output
> sink()

> # ----------------------------#
> # 5. Model Evaluation
> # ----------------------------#
> 
> # Extract residuals and fitted values from the model
 .... [TRUNCATED] 

> fitted_values <- fitted(ssn_mod)   

> # ----------------------------#
> # 6. Plotting and Saving Graphs
> # ----------------------------#
> 
> 
> # Create the graph save directory if sav .... [TRUNCATED] 

> # ----------------------------#
> # 7. Residuals vs Fitted Values Plot
> # ----------------------------#
> 
> # Purpose:
> #   - Linearity: Ensure t .... [TRUNCATED] 

> # Create the Residuals vs Fitted Values plot
> resid_fitted_plot <- ggplot(data.frame(Fitted = fitted_values, Residuals = residuals), aes(x = Fitted .... [TRUNCATED] 

> # Display the plot
> print(resid_fitted_plot)

> # Save the plot if saving is enabled
> if (save_graphs) {
+   ggsave(filename = file.path(graph_save_dir, "Residuals_vs_Fitted.png"), plot = resid_f .... [TRUNCATED] 
[1] "Saved Residuals vs Fitted Values plot."

> # ----------------------------#
> # 8. Q-Q Plot for Residuals
> # ----------------------------#
> 
> # Purpose:
> #   - Normality: Verify that resid .... [TRUNCATED] 

> # Enhanced Q-Q Plot using ggplot2
> qq_plot <- ggplot(data.frame(Residuals = residuals), aes(sample = Residuals)) +
+   stat_qq(color = "blue") +
+  .... [TRUNCATED] 

> # Display the ggplot2 Q-Q plot
> print(qq_plot)

> # Save the ggplot2 Q-Q plot if saving is enabled
> if (save_graphs) {
+   ggsave(filename = file.path(graph_save_dir, "QQ_Plot_Residuals_GGPlot2.png ..." ... [TRUNCATED] 
[1] "Saved ggplot2 Q-Q Plot of Residuals."

> # ----------------------------#
> # 9. Histogram of Residuals
> # ----------------------------#
> 
> # Purpose:
> #   - Normality
> #
> # What to Lo .... [TRUNCATED] 

> # Enhanced Histogram using ggplot2
> hist_plot <- ggplot(data.frame(Residuals = residuals), aes(x = Residuals)) +
+   geom_histogram(aes(y = ..densi .... [TRUNCATED] 

> # Display the ggplot2 histogram
> print(hist_plot)

> # Save the ggplot2 histogram if saving is enabled
> if (save_graphs) {
+   ggsave(filename = file.path(graph_save_dir, "Histogram_Residuals_GGPlot2. ..." ... [TRUNCATED] 
[1] "Saved ggplot2 Histogram of Residuals with Normal Curve."

> # Redirect output to the specified file and also print to console
> sink(output_file, append = TRUE, split = TRUE)

> print("")
[1] ""

> # ----------------------------#
> # 10. Statistical Tests
> # ----------------------------#
> 
> 
> # --------- Shapiro-Wilk Test for Normality ---- .... [TRUNCATED] 
[1] "-------- Shapiro-Wilk Test for Normality ---------"

> print("  - Normality: To check if the residuals are normally distributed.")
[1] "  - Normality: To check if the residuals are normally distributed."

> print("  - p-value > 0.05: Fail to reject null hypothesis (residuals are normally distributed).")
[1] "  - p-value > 0.05: Fail to reject null hypothesis (residuals are normally distributed)."

> print("  - p-value <= 0.05: Reject null hypothesis (residuals are not normally distributed).\n")
[1] "  - p-value <= 0.05: Reject null hypothesis (residuals are not normally distributed).\n"

> shapiro_test <- shapiro.test(residuals)

> print("Shapiro-Wilk Test Results:")
[1] "Shapiro-Wilk Test Results:"

> print(shapiro_test)

	Shapiro-Wilk normality test

data:  residuals
W = 0.96785, p-value = 1.094e-10


> # --------- Breusch-Pagan Test for Homoscedasticity ---------
> print("-------- Breusch-Pagan Test for Homoscedasticity ---------")
[1] "-------- Breusch-Pagan Test for Homoscedasticity ---------"

> print("  - Homoscedasticity: To check if residuals have constant variance across all levels of fitted values.")
[1] "  - Homoscedasticity: To check if residuals have constant variance across all levels of fitted values."

> print("  - p-value > 0.05: Fail to reject null hypothesis (homoscedasticity holds).")
[1] "  - p-value > 0.05: Fail to reject null hypothesis (homoscedasticity holds)."

> print("  - p-value <= 0.05: Reject null hypothesis (heteroscedasticity present).\n")
[1] "  - p-value <= 0.05: Reject null hypothesis (heteroscedasticity present).\n"

> # Extract the model frame from the ssn_lm model
> data_ssn <- model.frame(ssn_mod)

> # Perform Breusch-Pagan Test
> bp_test <- bptest(ssn_mod)

> print("Breusch-Pagan Test Results:")
[1] "Breusch-Pagan Test Results:"

> print(bp_test)

	studentized Breusch-Pagan test

data:  ssn_mod
BP = 75.814, df = 19, p-value = 9.683e-09


> # --------- Moran's I Test for Spatial Autocorrelation ---------
> print("\n-------- Moran's I Test for Spatial Autocorrelation ---------")
[1] "\n-------- Moran's I Test for Spatial Autocorrelation ---------"

> print("  - Spatial Autocorrelation: To determine if there is spatial autocorrelation in the residuals.")
[1] "  - Spatial Autocorrelation: To determine if there is spatial autocorrelation in the residuals."

> print("  - p-value > 0.05: Fail to reject null hypothesis (lack of spatial autocorrelation in residuals holds).")
[1] "  - p-value > 0.05: Fail to reject null hypothesis (lack of spatial autocorrelation in residuals holds)."

> print("  - p-value <= 0.05: Reject null hypothesis (spatial autocorrelation present).\n")
[1] "  - p-value <= 0.05: Reject null hypothesis (spatial autocorrelation present).\n"

> sink()

> # Extract spatial coordinates from the SSN object
> # Ensure that your SSN object has geometry information
> coords <- st_coordinates(ssn_get_data(s .... [TRUNCATED] 

> # Create a spatial weights matrix using k-nearest neighbors (k = 4 as an example)
> knn <- knearneigh(coords, k = 4)

> nb <- knn2nb(knn)

> lw <- nb2listw(nb, style = "W", zero.policy = TRUE)

> # Compute Moran's I
> moran_test <- moran.test(residuals, lw, zero.policy = TRUE)

> sink(output_file, append = TRUE, split = TRUE)

> print("Moran's I Test Results:")
[1] "Moran's I Test Results:"

> print(moran_test)

	Moran I test under randomisation

data:  residuals  
weights: lw    

Moran I statistic standard deviate = -7.2671, p-value = 1
alternative hypothesis: greater
sample estimates:
Moran I statistic       Expectation          Variance 
     -0.198457287      -0.001552795       0.000734155 


> # Stop redirecting output
> sink()

> # --------------------------------------------------
> # End of Script
> # --------------------------------------------------
> 
> 
> library(car)

> vif_result <- vif(lm(ch_sfm.erosion.norm ~ 
+                        ch_slope.median +
+                        ch_curvature.median +
+              .... [TRUNCATED] 

> # --------------------------------------------------
> # Spatial Statistical Modeling with SSN2
> # ------------------------------------------------ .... [TRUNCATED] 

> # Define the formula for the ssn_lm function
> # You can modify this formula as needed for different analyses
> model_formula <- as.formula(
+   "ch ..." ... [TRUNCATED] 

> # Specify the input and output directories
> input_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/Inputs"

> output_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/SSN ET/ET Full ws_re"

> model_name <- "glm ch_sfm.erosion.norm VIF 3 100 ct thresh ws_re"

> obs_points_path <- file.path(input_dir, "Combined Watersheds", "ET Full ssn points.gpkg")

> read_ssn <- TRUE # whether to create a new ssn (FALSE) or read the pre-existing ssn (TRUE)

> # Use file.path to create platform-independent file paths
> streams_path <- file.path(input_dir, "streams_100k.gpkg")

> ssn_path <- file.path(output_dir, "1_ET_Full_logtrans_independent_vars.ssn")

> output_file <- file.path(output_dir, model_name, "Results.txt")

> lsn_out <- file.path(output_dir, "0_lsn")

> # Define whether to save graphs and the directory to save them
> save_graphs <- TRUE  # Set to TRUE to save graphs as PNG

> graph_save_dir <- file.path(output_dir, model_name)  # Directory to save graphs

> # ----------------------------#
> # 1. Load Necessary Libraries
> # ----------------------------#
> 
> # Load required libraries
> library(SSN2)

> library(SSNbler)

> library(sf)

> library(dplyr)

> library(purrr)

> library(ggplot2)

> library(lmtest)

> library(spdep)

> library(classInt)   # Required for knearneigh

> library(broom)      # For tidy() and glance() functions

> library(grid)       # For grid.newpage()

> if (!dir.exists(graph_save_dir)) {
+   dir.create(graph_save_dir, recursive = TRUE)
+ }

> # ----------------------------#
> # 2. Read Spatial Data
> # ----------------------------#
> 
> # Read the streams dataset
> ET_streams <- st_read(s .... [TRUNCATED] 
Reading layer `streams_100k' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\streams_100k.gpkg' using driver `GPKG'
Simple feature collection with 643 features and 2 fields
Geometry type: LINESTRING
Dimension:     XY
Bounding box:  xmin: 404042.6 ymin: 4447904 xmax: 414579.6 ymax: 4466669
Projected CRS: NAD83 / UTM zone 13N

> # Read the observation points dataset
> ET_obs <- st_read(obs_points_path)
Reading layer `ET Full ssn points' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\Combined Watersheds\ET Full ssn points.gpkg' using driver `GPKG'
Simple feature collection with 645 features and 60 fields
Geometry type: POINT
Dimension:     XY
Bounding box:  xmin: 407401.1 ymin: 4449827 xmax: 413032.9 ymax: 4464548
Projected CRS: NAD83 / UTM zone 13N

> # Uncomment the following line if you encounter an error about Multilinestrings
> # ET_streams <- st_cast(ET_streams, "LINESTRING")
> 
> # --------- .... [TRUNCATED] 

> # Create a distance matrix for spatial relationships
> # Purpose: Define spatial dependencies based on distances between sites
> ssn_create_distmat( .... [TRUNCATED] 

> # ----------------------------#
> # 4. Model Fitting and Output
> # ----------------------------#
> 
> # Redirect output to the specified file and a .... [TRUNCATED] 

> model_name
[1] "glm ch_sfm.erosion.norm VIF 3 100 ct thresh ws_re"

> model_formula
ch_sfm.erosion.norm ~ ws_flow.accum.max + ws_slope.mean + ws_bare.earth.mean + 
    ws_drainage_density + ws_RV.Sand + ch_slope.median + ch_curvature.median + 
    ch_valley_width + ch_change.in.slope.over.width + ch_channel.width.over.valley.width + 
    ch_slope.over.width.central.diff + ch_stream.power.central.diff + 
    hs_hillslope.length + hs_slope.median + hs_northness.median + 
    hs_eastness.median + hs_curvature.median + hs_bare.earth.mean + 
    hs_ndvi.range + hs_dnbr.median + hs_drainage_density + flow.accumulation.max

> ssn_mod <- ssn_glm(
+   formula = model_formula,
+   ssn.object = ET_ssn,
+   family = "Gamma",
+   tailup_type = "exponential",
+   taildown_type = .... [TRUNCATED] 

> # Print the summary of the model to the file and console
> print(summary(ssn_mod))

Call:
ssn_glm(formula = model_formula, ssn.object = ET_ssn, family = "Gamma", 
    tailup_type = "exponential", taildown_type = "none", euclid_type = "gaussian", 
    additive = "afv_flow_accum", random = ~as.factor(ch_watershed))

Deviance Residuals:
      Min        1Q    Median        3Q       Max 
-1.899096 -0.244484  0.005467  0.190863  1.013314 

Coefficients (fixed):
                                     Estimate Std. Error z value Pr(>|z|)    
(Intercept)                        -1.9686360  0.8984917  -2.191   0.0284 *  
ws_flow.accum.max                  -0.4236557  0.2325182  -1.822   0.0685 .  
ws_slope.mean                       1.1187663  0.2768520   4.041 5.32e-05 ***
ws_bare.earth.mean                 -0.2392941  0.1509909  -1.585   0.1130    
ws_drainage_density                 0.0383747  0.0194197   1.976   0.0481 *  
ws_RV.Sand                         -0.4079859  0.4034231  -1.011   0.3119    
ch_slope.median                     0.1481487  0.0706427   2.097   0.0360 *  
ch_curvature.median                 0.0008038  0.0666369   0.012   0.9904    
ch_valley_width                    -0.0488746  0.0746302  -0.655   0.5125    
ch_change.in.slope.over.width      -0.0271306  0.0178150  -1.523   0.1278    
ch_channel.width.over.valley.width  0.0736065  0.0756281   0.973   0.3304    
ch_slope.over.width.central.diff    0.0457687  0.0266721   1.716   0.0862 .  
ch_stream.power.central.diff        0.0053541  0.0176862   0.303   0.7621    
hs_hillslope.length                -0.0551840  0.0466631  -1.183   0.2370    
hs_slope.median                     0.0838467  0.0900029   0.932   0.3515    
hs_northness.median                -0.1063774  0.0667991  -1.592   0.1113    
hs_eastness.median                 -0.0179435  0.0455613  -0.394   0.6937    
hs_curvature.median                 0.0109864  0.0303161   0.362   0.7171    
hs_bare.earth.mean                  0.0871841  0.0677662   1.287   0.1983    
hs_ndvi.range                      -0.0358530  0.0722844  -0.496   0.6199    
hs_dnbr.median                      0.0227799  0.0780155   0.292   0.7703    
hs_drainage_density                 0.4510822 13.7896864   0.033   0.9739    
flow.accumulation.max              -0.1191132  0.0745331  -1.598   0.1100    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Pseudo R-squared: 0.03917

Coefficients (covariance):
              Effect                    Parameter   Estimate
  tailup exponential                 de (parsill)  1.417e+00
  tailup exponential                        range  8.651e+01
     euclid gaussian                 de (parsill)  1.813e+00
     euclid gaussian                        range  5.405e+03
              nugget                       nugget  1.308e-03
          dispersion                   dispersion  3.411e+00
              random  1 | as.factor(ch_watershed)  3.019e-01


> # Print variance components of the model
> varcomp(ssn_mod)
# A tibble: 6 × 2
  varcomp                     proportion
  <chr>                            <dbl>
1 Covariates (PR-sq)            0.0392  
2 tailup_de                     0.385   
3 taildown_de                   0       
4 euclid_de                     0.493   
5 nugget                        0.000356
6 1 | as.factor(ch_watershed)   0.0821  

> # Tidy the model output with confidence intervals and print
> print(tidy(ssn_mod, conf.int = TRUE))  
# A tibble: 23 × 7
   term                                estimate std.error statistic p.value conf.low conf.high
   <chr>                                  <dbl>     <dbl>     <dbl>   <dbl>    <dbl>     <dbl>
 1 (Intercept)                        -1.97        0.898    -2.19    0.0284 -3.73     -0.208  
 2 ch_change.in.slope.over.width      -0.0271      0.0178   -1.52    0.128  -0.0620    0.00779
 3 ch_channel.width.over.valley.width  0.0736      0.0756    0.973   0.330  -0.0746    0.222  
 4 ch_curvature.median                 0.000804    0.0666    0.0121  0.990  -0.130     0.131  
 5 ch_slope.median                     0.148       0.0706    2.10    0.0360  0.00969   0.287  
 6 ch_slope.over.width.central.diff    0.0458      0.0267    1.72    0.0862 -0.00651   0.0980 
 7 ch_stream.power.central.diff        0.00535     0.0177    0.303   0.762  -0.0293    0.0400 
 8 ch_valley_width                    -0.0489      0.0746   -0.655   0.513  -0.195     0.0974 
 9 flow.accumulation.max              -0.119       0.0745   -1.60    0.110  -0.265     0.0270 
10 hs_bare.earth.mean                  0.0872      0.0678    1.29    0.198  -0.0456    0.220  
# ℹ 13 more rows
# ℹ Use `print(n = ...)` to see more rows

> # Provide a glance summary of the model and print
> print(glance(ssn_mod))
# A tibble: 1 × 9
      n     p  npar value   AIC  AICc logLik deviance pseudo.r.squared
  <int> <dbl> <int> <dbl> <dbl> <dbl>  <dbl>    <dbl>            <dbl>
1   645    23     7 1013. 1027. 1027.  -506.     99.1           0.0392

> # Perform Leave-One-Out Cross Validation and print
> print("Leave One Out Cross Validation")
[1] "Leave One Out Cross Validation"

> loocv_results <- loocv(ssn_mod)

> print(loocv_results)
# A tibble: 1 × 4
     bias  MSPE RMSPE   RAV
    <dbl> <dbl> <dbl> <dbl>
1 -0.0753 0.163 0.403 0.768

> # Stop redirecting output
> sink()

> # ----------------------------#
> # 5. Model Evaluation
> # ----------------------------#
> 
> # Extract residuals and fitted values from the model
 .... [TRUNCATED] 

> fitted_values <- fitted(ssn_mod)   

> # ----------------------------#
> # 6. Plotting and Saving Graphs
> # ----------------------------#
> 
> 
> # Create the graph save directory if sav .... [TRUNCATED] 

> # ----------------------------#
> # 7. Residuals vs Fitted Values Plot
> # ----------------------------#
> 
> # Purpose:
> #   - Linearity: Ensure t .... [TRUNCATED] 

> # Create the Residuals vs Fitted Values plot
> resid_fitted_plot <- ggplot(data.frame(Fitted = fitted_values, Residuals = residuals), aes(x = Fitted .... [TRUNCATED] 

> # Display the plot
> print(resid_fitted_plot)

> # Save the plot if saving is enabled
> if (save_graphs) {
+   ggsave(filename = file.path(graph_save_dir, "Residuals_vs_Fitted.png"), plot = resid_f .... [TRUNCATED] 
[1] "Saved Residuals vs Fitted Values plot."

> # ----------------------------#
> # 8. Q-Q Plot for Residuals
> # ----------------------------#
> 
> # Purpose:
> #   - Normality: Verify that resid .... [TRUNCATED] 

> # Enhanced Q-Q Plot using ggplot2
> qq_plot <- ggplot(data.frame(Residuals = residuals), aes(sample = Residuals)) +
+   stat_qq(color = "blue") +
+  .... [TRUNCATED] 

> # Display the ggplot2 Q-Q plot
> print(qq_plot)

> # Save the ggplot2 Q-Q plot if saving is enabled
> if (save_graphs) {
+   ggsave(filename = file.path(graph_save_dir, "QQ_Plot_Residuals_GGPlot2.png ..." ... [TRUNCATED] 
[1] "Saved ggplot2 Q-Q Plot of Residuals."

> # ----------------------------#
> # 9. Histogram of Residuals
> # ----------------------------#
> 
> # Purpose:
> #   - Normality
> #
> # What to Lo .... [TRUNCATED] 

> # Enhanced Histogram using ggplot2
> hist_plot <- ggplot(data.frame(Residuals = residuals), aes(x = Residuals)) +
+   geom_histogram(aes(y = ..densi .... [TRUNCATED] 

> # Display the ggplot2 histogram
> print(hist_plot)

> # Save the ggplot2 histogram if saving is enabled
> if (save_graphs) {
+   ggsave(filename = file.path(graph_save_dir, "Histogram_Residuals_GGPlot2. ..." ... [TRUNCATED] 
[1] "Saved ggplot2 Histogram of Residuals with Normal Curve."

> # Redirect output to the specified file and also print to console
> sink(output_file, append = TRUE, split = TRUE)

> print("")
[1] ""

> # ----------------------------#
> # 10. Statistical Tests
> # ----------------------------#
> 
> 
> # --------- Shapiro-Wilk Test for Normality ---- .... [TRUNCATED] 
[1] "-------- Shapiro-Wilk Test for Normality ---------"

> print("  - Normality: To check if the residuals are normally distributed.")
[1] "  - Normality: To check if the residuals are normally distributed."

> print("  - p-value > 0.05: Fail to reject null hypothesis (residuals are normally distributed).")
[1] "  - p-value > 0.05: Fail to reject null hypothesis (residuals are normally distributed)."

> print("  - p-value <= 0.05: Reject null hypothesis (residuals are not normally distributed).\n")
[1] "  - p-value <= 0.05: Reject null hypothesis (residuals are not normally distributed).\n"

> shapiro_test <- shapiro.test(residuals)

> print("Shapiro-Wilk Test Results:")
[1] "Shapiro-Wilk Test Results:"

> print(shapiro_test)

	Shapiro-Wilk normality test

data:  residuals
W = 0.96702, p-value = 7.299e-11


> # --------- Breusch-Pagan Test for Homoscedasticity ---------
> print("-------- Breusch-Pagan Test for Homoscedasticity ---------")
[1] "-------- Breusch-Pagan Test for Homoscedasticity ---------"

> print("  - Homoscedasticity: To check if residuals have constant variance across all levels of fitted values.")
[1] "  - Homoscedasticity: To check if residuals have constant variance across all levels of fitted values."

> print("  - p-value > 0.05: Fail to reject null hypothesis (homoscedasticity holds).")
[1] "  - p-value > 0.05: Fail to reject null hypothesis (homoscedasticity holds)."

> print("  - p-value <= 0.05: Reject null hypothesis (heteroscedasticity present).\n")
[1] "  - p-value <= 0.05: Reject null hypothesis (heteroscedasticity present).\n"

> # Extract the model frame from the ssn_lm model
> data_ssn <- model.frame(ssn_mod)

> # Perform Breusch-Pagan Test
> bp_test <- bptest(ssn_mod)

> print("Breusch-Pagan Test Results:")
[1] "Breusch-Pagan Test Results:"

> print(bp_test)

	studentized Breusch-Pagan test

data:  ssn_mod
BP = 59.412, df = 22, p-value = 2.729e-05


> # --------- Moran's I Test for Spatial Autocorrelation ---------
> print("\n-------- Moran's I Test for Spatial Autocorrelation ---------")
[1] "\n-------- Moran's I Test for Spatial Autocorrelation ---------"

> print("  - Spatial Autocorrelation: To determine if there is spatial autocorrelation in the residuals.")
[1] "  - Spatial Autocorrelation: To determine if there is spatial autocorrelation in the residuals."

> print("  - p-value > 0.05: Fail to reject null hypothesis (lack of spatial autocorrelation in residuals holds).")
[1] "  - p-value > 0.05: Fail to reject null hypothesis (lack of spatial autocorrelation in residuals holds)."

> print("  - p-value <= 0.05: Reject null hypothesis (spatial autocorrelation present).\n")
[1] "  - p-value <= 0.05: Reject null hypothesis (spatial autocorrelation present).\n"

> sink()

> # Extract spatial coordinates from the SSN object
> # Ensure that your SSN object has geometry information
> coords <- st_coordinates(ssn_get_data(s .... [TRUNCATED] 

> # Create a spatial weights matrix using k-nearest neighbors (k = 4 as an example)
> knn <- knearneigh(coords, k = 4)

> nb <- knn2nb(knn)

> lw <- nb2listw(nb, style = "W", zero.policy = TRUE)

> # Compute Moran's I
> moran_test <- moran.test(residuals, lw, zero.policy = TRUE)

> sink(output_file, append = TRUE, split = TRUE)

> print("Moran's I Test Results:")
[1] "Moran's I Test Results:"

> print(moran_test)

	Moran I test under randomisation

data:  residuals  
weights: lw    

Moran I statistic standard deviate = -7.2445, p-value = 1
alternative hypothesis: greater
sample estimates:
Moran I statistic       Expectation          Variance 
    -0.1978360659     -0.0015527950      0.0007340926 


> # Stop redirecting output
> sink()

> # --------------------------------------------------
> # End of Script
> # --------------------------------------------------
> 
> 

> # --------------------------------------------------
> # Spatial Statistical Modeling with SSN2
> # ------------------------------------------------ .... [TRUNCATED] 

> # Define the formula for the ssn_lm function
> # You can modify this formula as needed for different analyses
> model_formula <- as.formula(
+   "ch ..." ... [TRUNCATED] 

> # Specify the input and output directories
> input_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/Inputs"

> output_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/SSN ET/ET Full ws_re"

> model_name <- "glm ch_sfm.erosion.norm VIF 2 100 ct thresh ws_re"

> obs_points_path <- file.path(input_dir, "Combined Watersheds", "ET Full ssn points.gpkg")

> read_ssn <- TRUE # whether to create a new ssn (FALSE) or read the pre-existing ssn (TRUE)

> # Use file.path to create platform-independent file paths
> streams_path <- file.path(input_dir, "streams_100k.gpkg")

> ssn_path <- file.path(output_dir, "1_ET_Full_logtrans_independent_vars.ssn")

> output_file <- file.path(output_dir, model_name, "Results.txt")

> lsn_out <- file.path(output_dir, "0_lsn")

> # Define whether to save graphs and the directory to save them
> save_graphs <- TRUE  # Set to TRUE to save graphs as PNG

> graph_save_dir <- file.path(output_dir, model_name)  # Directory to save graphs

> # ----------------------------#
> # 1. Load Necessary Libraries
> # ----------------------------#
> 
> # Load required libraries
> library(SSN2)

> library(SSNbler)

> library(sf)

> library(dplyr)

> library(purrr)

> library(ggplot2)

> library(lmtest)

> library(spdep)

> library(classInt)   # Required for knearneigh

> library(broom)      # For tidy() and glance() functions

> library(grid)       # For grid.newpage()

> if (!dir.exists(graph_save_dir)) {
+   dir.create(graph_save_dir, recursive = TRUE)
+ }

> # ----------------------------#
> # 2. Read Spatial Data
> # ----------------------------#
> 
> # Read the streams dataset
> ET_streams <- st_read(s .... [TRUNCATED] 
Reading layer `streams_100k' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\streams_100k.gpkg' using driver `GPKG'
Simple feature collection with 643 features and 2 fields
Geometry type: LINESTRING
Dimension:     XY
Bounding box:  xmin: 404042.6 ymin: 4447904 xmax: 414579.6 ymax: 4466669
Projected CRS: NAD83 / UTM zone 13N

> # Read the observation points dataset
> ET_obs <- st_read(obs_points_path)
Reading layer `ET Full ssn points' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\Combined Watersheds\ET Full ssn points.gpkg' using driver `GPKG'
Simple feature collection with 645 features and 60 fields
Geometry type: POINT
Dimension:     XY
Bounding box:  xmin: 407401.1 ymin: 4449827 xmax: 413032.9 ymax: 4464548
Projected CRS: NAD83 / UTM zone 13N

> # Uncomment the following line if you encounter an error about Multilinestrings
> # ET_streams <- st_cast(ET_streams, "LINESTRING")
> 
> # --------- .... [TRUNCATED] 

> # Create a distance matrix for spatial relationships
> # Purpose: Define spatial dependencies based on distances between sites
> ssn_create_distmat( .... [TRUNCATED] 

> # ----------------------------#
> # 4. Model Fitting and Output
> # ----------------------------#
> 
> # Redirect output to the specified file and a .... [TRUNCATED] 

> model_name
[1] "glm ch_sfm.erosion.norm VIF 2 100 ct thresh ws_re"

> model_formula
ch_sfm.erosion.norm ~ ws_flow.accum.max + ws_slope.mean + ws_bare.earth.mean + 
    ws_drainage_density + ws_RV.Sand + ch_curvature.median + 
    ch_valley_width + ch_change.in.slope.over.width + ch_channel.width.over.valley.width + 
    ch_stream.power.central.diff + hs_hillslope.length + hs_slope.median + 
    hs_northness.median + hs_eastness.median + hs_curvature.median + 
    hs_ndvi.range + hs_dnbr.median + hs_drainage_density + flow.accumulation.max

> ssn_mod <- ssn_glm(
+   formula = model_formula,
+   ssn.object = ET_ssn,
+   family = "Gamma",
+   tailup_type = "exponential",
+   taildown_type = .... [TRUNCATED] 

> # Print the summary of the model to the file and console
> print(summary(ssn_mod))

Call:
ssn_glm(formula = model_formula, ssn.object = ET_ssn, family = "Gamma", 
    tailup_type = "exponential", taildown_type = "none", euclid_type = "gaussian", 
    additive = "afv_flow_accum", random = ~as.factor(ch_watershed))

Deviance Residuals:
       Min         1Q     Median         3Q        Max 
-1.8782655 -0.2339728 -0.0003834  0.1816483  0.9904105 

Coefficients (fixed):
                                    Estimate Std. Error z value Pr(>|z|)    
(Intercept)                        -1.949913   0.714828  -2.728  0.00638 ** 
ws_flow.accum.max                  -0.404024   0.228735  -1.766  0.07734 .  
ws_slope.mean                       1.139317   0.257134   4.431 9.39e-06 ***
ws_bare.earth.mean                 -0.227948   0.149620  -1.524  0.12763    
ws_drainage_density                 0.038633   0.018219   2.120  0.03396 *  
ws_RV.Sand                         -0.297464   0.379620  -0.784  0.43329    
ch_curvature.median                -0.008997   0.065960  -0.136  0.89150    
ch_valley_width                    -0.049524   0.074984  -0.660  0.50896    
ch_change.in.slope.over.width      -0.018392   0.017042  -1.079  0.28049    
ch_channel.width.over.valley.width  0.050237   0.075984   0.661  0.50851    
ch_stream.power.central.diff        0.024825   0.013866   1.790  0.07340 .  
hs_hillslope.length                -0.045256   0.045787  -0.988  0.32296    
hs_slope.median                     0.073010   0.089769   0.813  0.41604    
hs_northness.median                -0.128885   0.066777  -1.930  0.05360 .  
hs_eastness.median                 -0.020493   0.045418  -0.451  0.65184    
hs_curvature.median                 0.011279   0.030421   0.371  0.71080    
hs_ndvi.range                      -0.082624   0.065184  -1.268  0.20496    
hs_dnbr.median                      0.026938   0.078471   0.343  0.73138    
hs_drainage_density                 1.009103  13.868616   0.073  0.94200    
flow.accumulation.max              -0.141148   0.077038  -1.832  0.06692 .  
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Pseudo R-squared: 0.03101

Coefficients (covariance):
              Effect                    Parameter   Estimate
  tailup exponential                 de (parsill)  1.494e+00
  tailup exponential                        range  8.519e+01
     euclid gaussian                 de (parsill)  1.352e+00
     euclid gaussian                        range  3.729e+03
              nugget                       nugget  6.909e-04
          dispersion                   dispersion  3.482e+00
              random  1 | as.factor(ch_watershed)  1.759e-01


> # Print variance components of the model
> varcomp(ssn_mod)
# A tibble: 6 × 2
  varcomp                     proportion
  <chr>                            <dbl>
1 Covariates (PR-sq)            0.0310  
2 tailup_de                     0.479   
3 taildown_de                   0       
4 euclid_de                     0.433   
5 nugget                        0.000221
6 1 | as.factor(ch_watershed)   0.0564  

> # Tidy the model output with confidence intervals and print
> print(tidy(ssn_mod, conf.int = TRUE))  
# A tibble: 20 × 7
   term                               estimate std.error statistic    p.value  conf.low conf.high
   <chr>                                 <dbl>     <dbl>     <dbl>      <dbl>     <dbl>     <dbl>
 1 (Intercept)                        -1.95       0.715    -2.73   0.00638     -3.35     -0.549  
 2 ch_change.in.slope.over.width      -0.0184     0.0170   -1.08   0.280       -0.0518    0.0150 
 3 ch_channel.width.over.valley.width  0.0502     0.0760    0.661  0.509       -0.0987    0.199  
 4 ch_curvature.median                -0.00900    0.0660   -0.136  0.891       -0.138     0.120  
 5 ch_stream.power.central.diff        0.0248     0.0139    1.79   0.0734      -0.00235   0.0520 
 6 ch_valley_width                    -0.0495     0.0750   -0.660  0.509       -0.196     0.0974 
 7 flow.accumulation.max              -0.141      0.0770   -1.83   0.0669      -0.292     0.00984
 8 hs_curvature.median                 0.0113     0.0304    0.371  0.711       -0.0483    0.0709 
 9 hs_dnbr.median                      0.0269     0.0785    0.343  0.731       -0.127     0.181  
10 hs_drainage_density                 1.01      13.9       0.0728 0.942      -26.2      28.2    
11 hs_eastness.median                 -0.0205     0.0454   -0.451  0.652       -0.110     0.0685 
12 hs_hillslope.length                -0.0453     0.0458   -0.988  0.323       -0.135     0.0445 
13 hs_ndvi.range                      -0.0826     0.0652   -1.27   0.205       -0.210     0.0451 
14 hs_northness.median                -0.129      0.0668   -1.93   0.0536      -0.260     0.00200
15 hs_slope.median                     0.0730     0.0898    0.813  0.416       -0.103     0.249  
16 ws_bare.earth.mean                 -0.228      0.150    -1.52   0.128       -0.521     0.0653 
17 ws_drainage_density                 0.0386     0.0182    2.12   0.0340       0.00292   0.0743 
18 ws_flow.accum.max                  -0.404      0.229    -1.77   0.0773      -0.852     0.0443 
19 ws_RV.Sand                         -0.297      0.380    -0.784  0.433       -1.04      0.447  
20 ws_slope.mean                       1.14       0.257     4.43   0.00000939   0.635     1.64   

> # Provide a glance summary of the model and print
> print(glance(ssn_mod))
# A tibble: 1 × 9
      n     p  npar value   AIC  AICc logLik deviance pseudo.r.squared
  <int> <dbl> <int> <dbl> <dbl> <dbl>  <dbl>    <dbl>            <dbl>
1   645    20     7 1009. 1023. 1023.  -504.     94.0           0.0310

> # Perform Leave-One-Out Cross Validation and print
> print("Leave One Out Cross Validation")
[1] "Leave One Out Cross Validation"

> loocv_results <- loocv(ssn_mod)

> print(loocv_results)
# A tibble: 1 × 4
     bias  MSPE RMSPE   RAV
    <dbl> <dbl> <dbl> <dbl>
1 -0.0768 0.163 0.404 0.727

> # Stop redirecting output
> sink()

> # ----------------------------#
> # 5. Model Evaluation
> # ----------------------------#
> 
> # Extract residuals and fitted values from the model
 .... [TRUNCATED] 

> fitted_values <- fitted(ssn_mod)   

> # ----------------------------#
> # 6. Plotting and Saving Graphs
> # ----------------------------#
> 
> 
> # Create the graph save directory if sav .... [TRUNCATED] 

> # ----------------------------#
> # 7. Residuals vs Fitted Values Plot
> # ----------------------------#
> 
> # Purpose:
> #   - Linearity: Ensure t .... [TRUNCATED] 

> # Create the Residuals vs Fitted Values plot
> resid_fitted_plot <- ggplot(data.frame(Fitted = fitted_values, Residuals = residuals), aes(x = Fitted .... [TRUNCATED] 

> # Display the plot
> print(resid_fitted_plot)

> # Save the plot if saving is enabled
> if (save_graphs) {
+   ggsave(filename = file.path(graph_save_dir, "Residuals_vs_Fitted.png"), plot = resid_f .... [TRUNCATED] 
[1] "Saved Residuals vs Fitted Values plot."

> # ----------------------------#
> # 8. Q-Q Plot for Residuals
> # ----------------------------#
> 
> # Purpose:
> #   - Normality: Verify that resid .... [TRUNCATED] 

> # Enhanced Q-Q Plot using ggplot2
> qq_plot <- ggplot(data.frame(Residuals = residuals), aes(sample = Residuals)) +
+   stat_qq(color = "blue") +
+  .... [TRUNCATED] 

> # Display the ggplot2 Q-Q plot
> print(qq_plot)

> # Save the ggplot2 Q-Q plot if saving is enabled
> if (save_graphs) {
+   ggsave(filename = file.path(graph_save_dir, "QQ_Plot_Residuals_GGPlot2.png ..." ... [TRUNCATED] 
[1] "Saved ggplot2 Q-Q Plot of Residuals."

> # ----------------------------#
> # 9. Histogram of Residuals
> # ----------------------------#
> 
> # Purpose:
> #   - Normality
> #
> # What to Lo .... [TRUNCATED] 

> # Enhanced Histogram using ggplot2
> hist_plot <- ggplot(data.frame(Residuals = residuals), aes(x = Residuals)) +
+   geom_histogram(aes(y = ..densi .... [TRUNCATED] 

> # Display the ggplot2 histogram
> print(hist_plot)

> # Save the ggplot2 histogram if saving is enabled
> if (save_graphs) {
+   ggsave(filename = file.path(graph_save_dir, "Histogram_Residuals_GGPlot2. ..." ... [TRUNCATED] 
[1] "Saved ggplot2 Histogram of Residuals with Normal Curve."

> # Redirect output to the specified file and also print to console
> sink(output_file, append = TRUE, split = TRUE)

> print("")
[1] ""

> # ----------------------------#
> # 10. Statistical Tests
> # ----------------------------#
> 
> 
> # --------- Shapiro-Wilk Test for Normality ---- .... [TRUNCATED] 
[1] "-------- Shapiro-Wilk Test for Normality ---------"

> print("  - Normality: To check if the residuals are normally distributed.")
[1] "  - Normality: To check if the residuals are normally distributed."

> print("  - p-value > 0.05: Fail to reject null hypothesis (residuals are normally distributed).")
[1] "  - p-value > 0.05: Fail to reject null hypothesis (residuals are normally distributed)."

> print("  - p-value <= 0.05: Reject null hypothesis (residuals are not normally distributed).\n")
[1] "  - p-value <= 0.05: Reject null hypothesis (residuals are not normally distributed).\n"

> shapiro_test <- shapiro.test(residuals)

> print("Shapiro-Wilk Test Results:")
[1] "Shapiro-Wilk Test Results:"

> print(shapiro_test)

	Shapiro-Wilk normality test

data:  residuals
W = 0.96812, p-value = 1.252e-10


> # --------- Breusch-Pagan Test for Homoscedasticity ---------
> print("-------- Breusch-Pagan Test for Homoscedasticity ---------")
[1] "-------- Breusch-Pagan Test for Homoscedasticity ---------"

> print("  - Homoscedasticity: To check if residuals have constant variance across all levels of fitted values.")
[1] "  - Homoscedasticity: To check if residuals have constant variance across all levels of fitted values."

> print("  - p-value > 0.05: Fail to reject null hypothesis (homoscedasticity holds).")
[1] "  - p-value > 0.05: Fail to reject null hypothesis (homoscedasticity holds)."

> print("  - p-value <= 0.05: Reject null hypothesis (heteroscedasticity present).\n")
[1] "  - p-value <= 0.05: Reject null hypothesis (heteroscedasticity present).\n"

> # Extract the model frame from the ssn_lm model
> data_ssn <- model.frame(ssn_mod)

> # Perform Breusch-Pagan Test
> bp_test <- bptest(ssn_mod)

> print("Breusch-Pagan Test Results:")
[1] "Breusch-Pagan Test Results:"

> print(bp_test)

	studentized Breusch-Pagan test

data:  ssn_mod
BP = 59.158, df = 19, p-value = 5.254e-06


> # --------- Moran's I Test for Spatial Autocorrelation ---------
> print("\n-------- Moran's I Test for Spatial Autocorrelation ---------")
[1] "\n-------- Moran's I Test for Spatial Autocorrelation ---------"

> print("  - Spatial Autocorrelation: To determine if there is spatial autocorrelation in the residuals.")
[1] "  - Spatial Autocorrelation: To determine if there is spatial autocorrelation in the residuals."

> print("  - p-value > 0.05: Fail to reject null hypothesis (lack of spatial autocorrelation in residuals holds).")
[1] "  - p-value > 0.05: Fail to reject null hypothesis (lack of spatial autocorrelation in residuals holds)."

> print("  - p-value <= 0.05: Reject null hypothesis (spatial autocorrelation present).\n")
[1] "  - p-value <= 0.05: Reject null hypothesis (spatial autocorrelation present).\n"

> sink()

> # Extract spatial coordinates from the SSN object
> # Ensure that your SSN object has geometry information
> coords <- st_coordinates(ssn_get_data(s .... [TRUNCATED] 

> # Create a spatial weights matrix using k-nearest neighbors (k = 4 as an example)
> knn <- knearneigh(coords, k = 4)

> nb <- knn2nb(knn)

> lw <- nb2listw(nb, style = "W", zero.policy = TRUE)

> # Compute Moran's I
> moran_test <- moran.test(residuals, lw, zero.policy = TRUE)

> sink(output_file, append = TRUE, split = TRUE)

> print("Moran's I Test Results:")
[1] "Moran's I Test Results:"

> print(moran_test)

	Moran I test under randomisation

data:  residuals  
weights: lw    

Moran I statistic standard deviate = -7.382, p-value = 1
alternative hypothesis: greater
sample estimates:
Moran I statistic       Expectation          Variance 
    -0.2015572429     -0.0015527950      0.0007340585 


> # Stop redirecting output
> sink()

> # --------------------------------------------------
> # End of Script
> # --------------------------------------------------
> 
> 
-------------#
> 
> 
> # --------- Shapiro-Wilk Test for Normality ---- .... [TRUNCATED] 
[1] "-------- Shapiro-Wilk Test for Normality ---------"

> print("  - Normality: To check if the residuals are normally distributed.")
[1] "  - Normality: To check if the residuals are normally distributed."

> print("  - p-value > 0.05: Fail to reject null hypothesis (residuals are normally distributed).")
[1] "  - p-value > 0.05: Fail to reject null hypothesis (residuals are normally distributed)."

> print("  - p-value <= 0.05: Reject null hypothesis (residuals are not normally distributed).\n")
[1] "  - p-value <= 0.05: Reject null hypothesis (residuals are not normally distributed).\n"

> shapiro_test <- shapiro.test(residuals)

> print("Shapiro-Wilk Test Results:")
[1] "Shapiro-Wilk Test Results:"

> print(shapiro_test)

	Shapiro-Wilk normality test

data:  residuals
W = 0.96812, p-value = 1.252e-10


> # --------- Breusch-Pagan Test for Homoscedasticity ---------
> print("-------- Breusch-Pagan Test for Homoscedasticity ---------")
[1] "-------- Breusch-Pagan Test for Homoscedasticity ---------"

> print("  - Homoscedasticity: To check if residuals have constant variance across all levels of fitted values.")
[1] "  - Homoscedasticity: To check if residuals have constant variance across all levels of fitted values."

> print("  - p-value > 0.05: Fail to reject null hypothesis (homoscedasticity holds).")
[1] "  - p-value > 0.05: Fail to reject null hypothesis (homoscedasticity holds)."

> print("  - p-value <= 0.05: Reject null hypothesis (heteroscedasticity present).\n")
[1] "  - p-value <= 0.05: Reject null hypothesis (heteroscedasticity present).\n"

> # Extract the model frame from the ssn_lm model
> data_ssn <- model.frame(ssn_mod)

> # Perform Breusch-Pagan Test
> bp_test <- bptest(ssn_mod)

> print("Breusch-Pagan Test Results:")
[1] "Breusch-Pagan Test Results:"

> print(bp_test)

	studentized Breusch-Pagan test

data:  ssn_mod
BP = 59.158, df = 19, p-value = 5.254e-06


> # --------- Moran's I Test for Spatial Autocorrelation ---------
> print("\n-------- Moran's I Test for Spatial Autocorrelation ---------")
[1] "\n-------- Moran's I Test for Spatial Autocorrelation ---------"

> print("  - Spatial Autocorrelation: To determine if there is spatial autocorrelation in the residuals.")
[1] "  - Spatial Autocorrelation: To determine if there is spatial autocorrelation in the residuals."

> print("  - p-value > 0.05: Fail to reject null hypothesis (lack of spatial autocorrelation in residuals holds).")
[1] "  - p-value > 0.05: Fail to reject null hypothesis (lack of spatial autocorrelation in residuals holds)."

> print("  - p-value <= 0.05: Reject null hypothesis (spatial autocorrelation present).\n")
[1] "  - p-value <= 0.05: Reject null hypothesis (spatial autocorrelation present).\n"

> sink()

> # Extract spatial coordinates from the SSN object
> # Ensure that your SSN object has geometry information
> coords <- st_coordinates(ssn_get_data(s .... [TRUNCATED] 

> # Create a spatial weights matrix using k-nearest neighbors (k = 4 as an example)
> knn <- knearneigh(coords, k = 4)

> nb <- knn2nb(knn)

> lw <- nb2listw(nb, style = "W", zero.policy = TRUE)

> # Compute Moran's I
> moran_test <- moran.test(residuals, lw, zero.policy = TRUE)

> sink(output_file, append = TRUE, split = TRUE)

> print("Moran's I Test Results:")
[1] "Moran's I Test Results:"

> print(moran_test)

	Moran I test under randomisation

data:  residuals  
weights: lw    

Moran I statistic standard deviate = -7.382, p-value = 1
alternative hypothesis: greater
sample estimates:
Moran I statistic       Expectation          Variance 
    -0.2015572429     -0.0015527950      0.0007340585 


> # Stop redirecting output
> sink()

> # --------------------------------------------------
> # End of Script
> # --------------------------------------------------
> 
> 
