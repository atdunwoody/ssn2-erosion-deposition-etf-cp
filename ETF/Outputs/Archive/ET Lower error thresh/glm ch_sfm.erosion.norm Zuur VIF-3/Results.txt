
> model_name
[1] "glm ch_sfm.erosion.norm Zuur VIF-3"

> model_formula
ch_sfm.erosion.norm ~ ch_flow.accumulation.max + ch_curvature.median + 
    ch_slope.downstream + ch_change.in.slope.over.width + ch_stream.power + 
    ch_channel.width.over.valley.width + ch_slope.over.width.central.diff + 
    hs_hillslope.length + hs_slope.median + hs_eastness.median + 
    hs_curvature.median + hs_ndvi.range + hs_dnbr.median + hs_drainage_density

> ssn_mod <- ssn_glm(
+   formula = model_formula,
+   ssn.object = ET_ssn,
+   family = "Gamma",
+   tailup_type = "exponential",
+   taildown_type = .... [TRUNCATED] 

> # Print the summary of the model to the file and console
> print(summary(ssn_mod))

Call:
ssn_glm(formula = model_formula, ssn.object = ET_ssn, family = "Gamma", 
    tailup_type = "exponential", taildown_type = "none", euclid_type = "gaussian", 
    additive = "afv_flow_accum")

Deviance Residuals:
    Min      1Q  Median      3Q     Max 
-2.0811 -0.5776 -0.0768  0.2978  1.3314 

Coefficients (fixed):
                                   Estimate Std. Error z value Pr(>|z|)    
(Intercept)                        -1.59829    0.48117  -3.322 0.000895 ***
ch_flow.accumulation.max            1.85356    0.75399   2.458 0.013959 *  
ch_curvature.median                 0.16848    0.10868   1.550 0.121082    
ch_slope.downstream                 0.12197    0.22849   0.534 0.593471    
ch_change.in.slope.over.width      -0.08809    0.04524  -1.947 0.051519 .  
ch_stream.power                     0.53142    0.17982   2.955 0.003123 ** 
ch_channel.width.over.valley.width  0.38538    0.16780   2.297 0.021641 *  
ch_slope.over.width.central.diff    0.11806    0.05378   2.195 0.028159 *  
hs_hillslope.length                -0.12949    0.14934  -0.867 0.385872    
hs_slope.median                     0.03533    0.12870   0.274 0.783704    
hs_eastness.median                 -0.31197    0.15009  -2.079 0.037661 *  
hs_curvature.median                -0.02904    0.09177  -0.316 0.751688    
hs_ndvi.range                      -0.07783    0.16698  -0.466 0.641151    
hs_dnbr.median                     -0.46406    0.22077  -2.102 0.035549 *  
hs_drainage_density                20.81268   44.66568   0.466 0.641240    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Pseudo R-squared: 0.1246

Coefficients (covariance):
              Effect     Parameter   Estimate
  tailup exponential  de (parsill)  1.563e-01
  tailup exponential         range  1.212e+03
     euclid gaussian  de (parsill)  1.014e+00
     euclid gaussian         range  7.222e+01
              nugget        nugget  3.572e-02
          dispersion    dispersion  2.153e+00


> # Print variance components of the model
> varcomp(ssn_mod)
# A tibble: 5 × 2
  varcomp            proportion
  <chr>                   <dbl>
1 Covariates (PR-sq)     0.125 
2 tailup_de              0.113 
3 taildown_de            0     
4 euclid_de              0.736 
5 nugget                 0.0259

> # Tidy the model output with confidence intervals and print
> print(tidy(ssn_mod, conf.int = TRUE))  
# A tibble: 15 × 7
   term                               estimate std.error statistic  p.value conf.low  conf.high
   <chr>                                 <dbl>     <dbl>     <dbl>    <dbl>    <dbl>      <dbl>
 1 (Intercept)                         -1.60      0.481     -3.32  0.000895  -2.54    -0.655   
 2 ch_change.in.slope.over.width       -0.0881    0.0452    -1.95  0.0515    -0.177    0.000581
 3 ch_channel.width.over.valley.width   0.385     0.168      2.30  0.0216     0.0565   0.714   
 4 ch_curvature.median                  0.168     0.109      1.55  0.121     -0.0445   0.381   
 5 ch_flow.accumulation.max             1.85      0.754      2.46  0.0140     0.376    3.33    
 6 ch_slope.downstream                  0.122     0.228      0.534 0.593     -0.326    0.570   
 7 ch_slope.over.width.central.diff     0.118     0.0538     2.20  0.0282     0.0126   0.223   
 8 ch_stream.power                      0.531     0.180      2.96  0.00312    0.179    0.884   
 9 hs_curvature.median                 -0.0290    0.0918    -0.316 0.752     -0.209    0.151   
10 hs_dnbr.median                      -0.464     0.221     -2.10  0.0355    -0.897   -0.0314  
11 hs_drainage_density                 20.8      44.7        0.466 0.641    -66.7    108.      
12 hs_eastness.median                  -0.312     0.150     -2.08  0.0377    -0.606   -0.0178  
13 hs_hillslope.length                 -0.129     0.149     -0.867 0.386     -0.422    0.163   
14 hs_ndvi.range                       -0.0778    0.167     -0.466 0.641     -0.405    0.249   
15 hs_slope.median                      0.0353    0.129      0.274 0.784     -0.217    0.288   

> # Provide a glance summary of the model and print
> print(glance(ssn_mod))
# A tibble: 1 × 9
      n     p  npar value   AIC  AICc logLik deviance pseudo.r.squared
  <int> <dbl> <int> <dbl> <dbl> <dbl>  <dbl>    <dbl>            <dbl>
1   161    15     6  425.  437.  438.  -212.     59.3            0.125

> # Perform Leave-One-Out Cross Validation and print
> print("Leave One Out Cross Validation")
[1] "Leave One Out Cross Validation"

> loocv_results <- loocv(ssn_mod)

> print(loocv_results)
# A tibble: 1 × 4
     bias  MSPE RMSPE   RAV
    <dbl> <dbl> <dbl> <dbl>
1 -0.0429 0.263 0.512 0.315

> # Stop redirecting output
> sink()
central.diff    0.11806    0.05378   2.195 0.028159 *  
hs_hillslope.length                -0.12949    0.14934  -0.867 0.385872    
hs_slope.median                     0.03533    0.12870   0.274 0.783704    
hs_eastness.median                 -0.31197    0.15009  -2.079 0.037661 *  
hs_curvature.median                -0.02904    0.09177  -0.316 0.751688    
hs_ndvi.range                      -0.07783    0.16698  -0.466 0.641151    
hs_dnbr.median                     -0.46406    0.22077  -2.102 0.035549 *  
hs_drainage_density                20.81268   44.66568   0.466 0.641240    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Pseudo R-squared: 0.1246

Coefficients (covariance):
              Effect     Parameter   Estimate
  tailup exponential  de (parsill)  1.563e-01
  tailup exponential         range  1.212e+03
     euclid gaussian  de (parsill)  1.014e+00
     euclid gaussian         range  7.222e+01
              nugget        nugget  3.572e-02
          dispersion    dispersion  2.153e+00


> # Print variance components of the model
> varcomp(ssn_mod)
# A tibble: 5 × 2
  varcomp            proportion
  <chr>                   <dbl>
1 Covariates (PR-sq)     0.125 
2 tailup_de              0.113 
3 taildown_de            0     
4 euclid_de              0.736 
5 nugget                 0.0259

> # Tidy the model output with confidence intervals and print
> print(tidy(ssn_mod, conf.int = TRUE))  
# A tibble: 15 × 7
   term                               estimate std.error statistic  p.value conf.low  conf.high
   <chr>                                 <dbl>     <dbl>     <dbl>    <dbl>    <dbl>      <dbl>
 1 (Intercept)                         -1.60      0.481     -3.32  0.000895  -2.54    -0.655   
 2 ch_change.in.slope.over.width       -0.0881    0.0452    -1.95  0.0515    -0.177    0.000581
 3 ch_channel.width.over.valley.width   0.385     0.168      2.30  0.0216     0.0565   0.714   
 4 ch_curvature.median                  0.168     0.109      1.55  0.121     -0.0445   0.381   
 5 ch_flow.accumulation.max             1.85      0.754      2.46  0.0140     0.376    3.33    
 6 ch_slope.downstream                  0.122     0.228      0.534 0.593     -0.326    0.570   
 7 ch_slope.over.width.central.diff     0.118     0.0538     2.20  0.0282     0.0126   0.223   
 8 ch_stream.power                      0.531     0.180      2.96  0.00312    0.179    0.884   
 9 hs_curvature.median                 -0.0290    0.0918    -0.316 0.752     -0.209    0.151   
10 hs_dnbr.median                      -0.464     0.221     -2.10  0.0355    -0.897   -0.0314  
11 hs_drainage_density                 20.8      44.7        0.466 0.641    -66.7    108.      
12 hs_eastness.median                  -0.312     0.150     -2.08  0.0377    -0.606   -0.0178  
13 hs_hillslope.length                 -0.129     0.149     -0.867 0.386     -0.422    0.163   
14 hs_ndvi.range                       -0.0778    0.167     -0.466 0.641     -0.405    0.249   
15 hs_slope.median                      0.0353    0.129      0.274 0.784     -0.217    0.288   

> # Provide a glance summary of the model and print
> print(glance(ssn_mod))
# A tibble: 1 × 9
      n     p  npar value   AIC  AICc logLik deviance pseudo.r.squared
  <int> <dbl> <int> <dbl> <dbl> <dbl>  <dbl>    <dbl>            <dbl>
1   161    15     6  425.  437.  438.  -212.     59.3            0.125

> # Perform Leave-One-Out Cross Validation and print
> print("Leave One Out Cross Validation")
[1] "Leave One Out Cross Validation"

> loocv_results <- loocv(ssn_mod)

> print(loocv_results)
# A tibble: 1 × 4
     bias  MSPE RMSPE   RAV
    <dbl> <dbl> <dbl> <dbl>
1 -0.0429 0.263 0.512 0.315

> # Stop redirecting output
> sink()

> # ----------------------------#
> # 5. Model Evaluation
> # ----------------------------#
> 
> # Extract residuals and fitted values from the model
 .... [TRUNCATED] 

> fitted_values <- fitted(ssn_mod)   

> # ----------------------------#
> # 6. Plotting and Saving Graphs
> # ----------------------------#
> 
> 
> # Create the graph save directory if sav .... [TRUNCATED] 

> # ----------------------------#
> # 7. Residuals vs Fitted Values Plot
> # ----------------------------#
> 
> # Purpose:
> #   - Linearity: Ensure t .... [TRUNCATED] 

> # Create the Residuals vs Fitted Values plot
> resid_fitted_plot <- ggplot(data.frame(Fitted = fitted_values, Residuals = residuals), aes(x = Fitted .... [TRUNCATED] 

> # Display the plot
> print(resid_fitted_plot)

> # Save the plot if saving is enabled
> if (save_graphs) {
+   ggsave(filename = file.path(graph_save_dir, "Residuals_vs_Fitted.png"), plot = resid_f .... [TRUNCATED] 
[1] "Saved Residuals vs Fitted Values plot."

> # ----------------------------#
> # 8. Q-Q Plot for Residuals
> # ----------------------------#
> 
> # Purpose:
> #   - Normality: Verify that resid .... [TRUNCATED] 

> # Enhanced Q-Q Plot using ggplot2
> qq_plot <- ggplot(data.frame(Residuals = residuals), aes(sample = Residuals)) +
+   stat_qq(color = "blue") +
+  .... [TRUNCATED] 

> # Display the ggplot2 Q-Q plot
> print(qq_plot)

> # Save the ggplot2 Q-Q plot if saving is enabled
> if (save_graphs) {
+   ggsave(filename = file.path(graph_save_dir, "QQ_Plot_Residuals_GGPlot2.png ..." ... [TRUNCATED] 
[1] "Saved ggplot2 Q-Q Plot of Residuals."

> # ----------------------------#
> # 9. Histogram of Residuals
> # ----------------------------#
> 
> # Purpose:
> #   - Normality
> #
> # What to Lo .... [TRUNCATED] 

> # Enhanced Histogram using ggplot2
> hist_plot <- ggplot(data.frame(Residuals = residuals), aes(x = Residuals)) +
+   geom_histogram(aes(y = ..densi .... [TRUNCATED] 

> # Display the ggplot2 histogram
> print(hist_plot)

> # Save the ggplot2 histogram if saving is enabled
> if (save_graphs) {
+   ggsave(filename = file.path(graph_save_dir, "Histogram_Residuals_GGPlot2. ..." ... [TRUNCATED] 
[1] "Saved ggplot2 Histogram of Residuals with Normal Curve."

> # Redirect output to the specified file and also print to console
> sink(output_file, append = TRUE, split = TRUE)

> print("")
[1] ""

> # ----------------------------#
> # 10. Statistical Tests
> # ----------------------------#
> 
> 
> # --------- Shapiro-Wilk Test for Normality ---- .... [TRUNCATED] 
[1] "-------- Shapiro-Wilk Test for Normality ---------"

> print("  - Normality: To check if the residuals are normally distributed.")
[1] "  - Normality: To check if the residuals are normally distributed."

> print("  - p-value > 0.05: Fail to reject null hypothesis (residuals are normally distributed).")
[1] "  - p-value > 0.05: Fail to reject null hypothesis (residuals are normally distributed)."

> print("  - p-value <= 0.05: Reject null hypothesis (residuals are not normally distributed).\n")
[1] "  - p-value <= 0.05: Reject null hypothesis (residuals are not normally distributed).\n"

> shapiro_test <- shapiro.test(residuals)

> print("Shapiro-Wilk Test Results:")
[1] "Shapiro-Wilk Test Results:"

> print(shapiro_test)

	Shapiro-Wilk normality test

data:  residuals
W = 0.98967, p-value = 0.2887


> # --------- Breusch-Pagan Test for Homoscedasticity ---------
> print("-------- Breusch-Pagan Test for Homoscedasticity ---------")
[1] "-------- Breusch-Pagan Test for Homoscedasticity ---------"

> print("  - Homoscedasticity: To check if residuals have constant variance across all levels of fitted values.")
[1] "  - Homoscedasticity: To check if residuals have constant variance across all levels of fitted values."

> print("  - p-value > 0.05: Fail to reject null hypothesis (homoscedasticity holds).")
[1] "  - p-value > 0.05: Fail to reject null hypothesis (homoscedasticity holds)."

> print("  - p-value <= 0.05: Reject null hypothesis (heteroscedasticity present).\n")
[1] "  - p-value <= 0.05: Reject null hypothesis (heteroscedasticity present).\n"

> # Extract the model frame from the ssn_lm model
> data_ssn <- model.frame(ssn_mod)

> # Perform Breusch-Pagan Test
> bp_test <- bptest(ssn_mod)

> print("Breusch-Pagan Test Results:")
[1] "Breusch-Pagan Test Results:"

> print(bp_test)

	studentized Breusch-Pagan test

data:  ssn_mod
BP = 33.714, df = 14, p-value = 0.00227


> # --------- Moran's I Test for Spatial Autocorrelation ---------
> print("\n-------- Moran's I Test for Spatial Autocorrelation ---------")
[1] "\n-------- Moran's I Test for Spatial Autocorrelation ---------"

> print("  - Spatial Autocorrelation: To determine if there is spatial autocorrelation in the residuals.")
[1] "  - Spatial Autocorrelation: To determine if there is spatial autocorrelation in the residuals."

> print("  - p-value > 0.05: Fail to reject null hypothesis (lack of spatial autocorrelation in residuals holds).")
[1] "  - p-value > 0.05: Fail to reject null hypothesis (lack of spatial autocorrelation in residuals holds)."

> print("  - p-value <= 0.05: Reject null hypothesis (spatial autocorrelation present).\n")
[1] "  - p-value <= 0.05: Reject null hypothesis (spatial autocorrelation present).\n"

> sink()

> # Extract spatial coordinates from the SSN object
> # Ensure that your SSN object has geometry information
> coords <- st_coordinates(ssn_get_data(s .... [TRUNCATED] 

> # Create a spatial weights matrix using k-nearest neighbors (k = 4 as an example)
> knn <- knearneigh(coords, k = 4)

> nb <- knn2nb(knn)

> lw <- nb2listw(nb, style = "W", zero.policy = TRUE)

> # Compute Moran's I
> moran_test <- moran.test(residuals, lw, zero.policy = TRUE)

> sink(output_file, append = TRUE, split = TRUE)

> print("Moran's I Test Results:")
[1] "Moran's I Test Results:"

> print(moran_test)

	Moran I test under randomisation

data:  residuals  
weights: lw    

Moran I statistic standard deviate = -2.2623, p-value = 0.9882
alternative hypothesis: greater
sample estimates:
Moran I statistic       Expectation          Variance 
     -0.129614935      -0.006250000       0.002973482 


> # Stop redirecting output
> sink()

> # --------------------------------------------------
> # End of Script
> # --------------------------------------------------
> 

> # --------------------------------------------------
> # Spatial Statistical Modeling with SSN2
> # ------------------------------------------------ .... [TRUNCATED] 

> # Specify the input and output directories
> input_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/Inputs"

> output_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/SSN ET/ET Lower error thresh"

> model_name <- "glm ch_sfm.erosion.norm ~ ch_flow.accumulation.max corr07"

> obs_points_path <- file.path(input_dir, "Combined Watersheds", "ET Lower ssn points.gpkg")

> read_ssn <- TRUE # whether to create a new ssn (FALSE) or read the pre-existing ssn (TRUE)

> # Use file.path to create platform-independent file paths
> streams_path <- file.path(input_dir, "streams_100k.gpkg")

> ssn_path <- file.path(output_dir, "1_ET_Full_logtrans_independent_vars.ssn")

> output_file <- file.path(output_dir, model_name, "Results.txt")

> lsn_out <- file.path(output_dir, "0_lsn")

> # Define whether to save graphs and the directory to save them
> save_graphs <- TRUE  # Set to TRUE to save graphs as PNG

> graph_save_dir <- file.path(output_dir, model_name)  # Directory to save graphs

> # ----------------------------#
> # 1. Load Necessary Libraries
> # ----------------------------#
> 
> # Load required libraries
> library(SSN2)

> library(SSNbler)

> library(sf)

> library(dplyr)

> library(purrr)

> library(ggplot2)

> library(lmtest)

> library(spdep)

> library(classInt)   # Required for knearneigh

> library(broom)      # For tidy() and glance() functions

> library(grid)       # For grid.newpage()

> if (!dir.exists(graph_save_dir)) {
+   dir.create(graph_save_dir, recursive = TRUE)
+ }

> # ----------------------------#
> # 2. Read Spatial Data
> # ----------------------------#
> 
> # Read the streams dataset
> ET_streams <- st_read(s .... [TRUNCATED] 
Reading layer `streams_100k' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\streams_100k.gpkg' using driver `GPKG'
Simple feature collection with 643 features and 2 fields
Geometry type: LINESTRING
Dimension:     XY
Bounding box:  xmin: 404042.6 ymin: 4447904 xmax: 414579.6 ymax: 4466669
Projected CRS: NAD83 / UTM zone 13N

> # Read the observation points dataset
> ET_obs <- st_read(obs_points_path)
Reading layer `ET Lower ssn points' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\Combined Watersheds\ET Lower ssn points.gpkg' using driver `GPKG'
Simple feature collection with 161 features and 59 fields
Geometry type: POINT
Dimension:     XY
Bounding box:  xmin: 411939.2 ymin: 4449827 xmax: 413032.9 ymax: 4450878
Projected CRS: NAD83 / UTM zone 13N

> # Uncomment the following line if you encounter an error about Multilinestrings
> # ET_streams <- st_cast(ET_streams, "LINESTRING")
> 
> # --------- .... [TRUNCATED] 

> # Create a distance matrix for spatial relationships
> # Purpose: Define spatial dependencies based on distances between sites
> ssn_create_distmat( .... [TRUNCATED] 

> # ----------------------------#
> # 4. Model Fitting and Output
> # ----------------------------#
> 
> # Redirect output to the specified file and a .... [TRUNCATED] 

> model_name
[1] "glm ch_sfm.erosion.norm ~ ch_flow.accumulation.max corr07"

> model_formula
ch_sfm.erosion.norm ~ ch_flow.accumulation.max + ch_stream.power + 
    hs_hillslope.length + ch_channel.width.over.valley.width + 
    hs_curvature.median + ch_curvature.median + ch_valley_width + 
    ws_dnbr.mean + hs_slope.median + hs_northness.median + ws_bare.earth.mean + 
    ch_slope.median + hs_dnbr.median + hs_ndvi.mean + ch_slope.over.width.central.diff + 
    ch_elevation.mean + hs_eastness.median + ch_change.in.slope.over.width

> ssn_mod <- ssn_glm(
+   formula = model_formula,
+   ssn.object = ET_ssn,
+   family = "Gamma",
+   tailup_type = "exponential",
+   taildown_type = .... [TRUNCATED] 

> # Print the summary of the model to the file and console
> print(summary(ssn_mod))

Call:
ssn_glm(formula = model_formula, ssn.object = ET_ssn, family = "Gamma", 
    tailup_type = "exponential", taildown_type = "none", euclid_type = "gaussian", 
    additive = "afv_flow_accum")

Deviance Residuals:
     Min       1Q   Median       3Q      Max 
-1.65695 -0.45107 -0.05094  0.28315  1.10339 

Coefficients (fixed):
                                    Estimate Std. Error z value Pr(>|z|)   
(Intercept)                        -1.814118   0.644045  -2.817  0.00485 **
ch_flow.accumulation.max            2.268671   1.456026   1.558  0.11920   
ch_stream.power                     0.689306   0.354106   1.947  0.05158 . 
hs_hillslope.length                -0.217915   0.157722  -1.382  0.16708   
ch_channel.width.over.valley.width  0.536461   0.270706   1.982  0.04751 * 
hs_curvature.median                 0.008951   0.098195   0.091  0.92737   
ch_curvature.median                 0.150670   0.116110   1.298  0.19441   
ch_valley_width                     0.293049   0.297683   0.984  0.32490   
ws_dnbr.mean                        0.041431   0.590942   0.070  0.94411   
hs_slope.median                    -0.016868   0.131219  -0.129  0.89772   
hs_northness.median                -0.248826   0.312721  -0.796  0.42622   
ws_bare.earth.mean                  0.081265   0.455378   0.178  0.85837   
ch_slope.median                    -0.049439   0.319838  -0.155  0.87716   
hs_dnbr.median                     -0.483923   0.259262  -1.867  0.06197 . 
hs_ndvi.mean                       -0.099750   0.198099  -0.504  0.61459   
ch_slope.over.width.central.diff    0.117029   0.054053   2.165  0.03038 * 
ch_elevation.mean                   1.028720   0.817877   1.258  0.20847   
hs_eastness.median                 -0.498167   0.205054  -2.429  0.01512 * 
ch_change.in.slope.over.width      -0.075748   0.038595  -1.963  0.04969 * 
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Pseudo R-squared: 0.1462

Coefficients (covariance):
              Effect     Parameter  Estimate
  tailup exponential  de (parsill)   0.32619
  tailup exponential         range  58.66642
     euclid gaussian  de (parsill)   1.13910
     euclid gaussian         range  81.05794
              nugget        nugget   0.01608
          dispersion    dispersion   2.35749


> # Print variance components of the model
> varcomp(ssn_mod)
# A tibble: 5 × 2
  varcomp            proportion
  <chr>                   <dbl>
1 Covariates (PR-sq)    0.146  
2 tailup_de             0.188  
3 taildown_de           0      
4 euclid_de             0.657  
5 nugget                0.00927

> # Tidy the model output with confidence intervals and print
> print(tidy(ssn_mod, conf.int = TRUE))  
# A tibble: 19 × 7
   term                               estimate std.error statistic p.value conf.low conf.high
   <chr>                                 <dbl>     <dbl>     <dbl>   <dbl>    <dbl>     <dbl>
 1 (Intercept)                        -1.81       0.644    -2.82   0.00485 -3.08    -0.552   
 2 ch_change.in.slope.over.width      -0.0757     0.0386   -1.96   0.0497  -0.151   -0.000102
 3 ch_channel.width.over.valley.width  0.536      0.271     1.98   0.0475   0.00589  1.07    
 4 ch_curvature.median                 0.151      0.116     1.30   0.194   -0.0769   0.378   
 5 ch_elevation.mean                   1.03       0.818     1.26   0.208   -0.574    2.63    
 6 ch_flow.accumulation.max            2.27       1.46      1.56   0.119   -0.585    5.12    
 7 ch_slope.median                    -0.0494     0.320    -0.155  0.877   -0.676    0.577   
 8 ch_slope.over.width.central.diff    0.117      0.0541    2.17   0.0304   0.0111   0.223   
 9 ch_stream.power                     0.689      0.354     1.95   0.0516  -0.00473  1.38    
10 ch_valley_width                     0.293      0.298     0.984  0.325   -0.290    0.876   
11 hs_curvature.median                 0.00895    0.0982    0.0912 0.927   -0.184    0.201   
12 hs_dnbr.median                     -0.484      0.259    -1.87   0.0620  -0.992    0.0242  
13 hs_eastness.median                 -0.498      0.205    -2.43   0.0151  -0.900   -0.0963  
14 hs_hillslope.length                -0.218      0.158    -1.38   0.167   -0.527    0.0912  
15 hs_ndvi.mean                       -0.0998     0.198    -0.504  0.615   -0.488    0.289   
16 hs_northness.median                -0.249      0.313    -0.796  0.426   -0.862    0.364   
17 hs_slope.median                    -0.0169     0.131    -0.129  0.898   -0.274    0.240   
18 ws_bare.earth.mean                  0.0813     0.455     0.178  0.858   -0.811    0.974   
19 ws_dnbr.mean                        0.0414     0.591     0.0701 0.944   -1.12     1.20    

> # Provide a glance summary of the model and print
> print(glance(ssn_mod))
# A tibble: 1 × 9
      n     p  npar value   AIC  AICc logLik deviance pseudo.r.squared
  <int> <dbl> <int> <dbl> <dbl> <dbl>  <dbl>    <dbl>            <dbl>
1   161    19     6  430.  442.  442.  -215.     46.4            0.146

> # Perform Leave-One-Out Cross Validation and print
> print("Leave One Out Cross Validation")
[1] "Leave One Out Cross Validation"

> loocv_results <- loocv(ssn_mod)

> print(loocv_results)
# A tibble: 1 × 4
     bias  MSPE RMSPE   RAV
    <dbl> <dbl> <dbl> <dbl>
1 -0.0576 0.233 0.483 0.413

> # Stop redirecting output
> sink()

> # ----------------------------#
> # 5. Model Evaluation
> # ----------------------------#
> 
> # Extract residuals and fitted values from the model
 .... [TRUNCATED] 

> fitted_values <- fitted(ssn_mod)   

> # ----------------------------#
> # 6. Plotting and Saving Graphs
> # ----------------------------#
> 
> 
> # Create the graph save directory if sav .... [TRUNCATED] 

> # ----------------------------#
> # 7. Residuals vs Fitted Values Plot
> # ----------------------------#
> 
> # Purpose:
> #   - Linearity: Ensure t .... [TRUNCATED] 

> # Create the Residuals vs Fitted Values plot
> resid_fitted_plot <- ggplot(data.frame(Fitted = fitted_values, Residuals = residuals), aes(x = Fitted .... [TRUNCATED] 

> # Display the plot
> print(resid_fitted_plot)

> # Save the plot if saving is enabled
> if (save_graphs) {
+   ggsave(filename = file.path(graph_save_dir, "Residuals_vs_Fitted.png"), plot = resid_f .... [TRUNCATED] 
[1] "Saved Residuals vs Fitted Values plot."

> # ----------------------------#
> # 8. Q-Q Plot for Residuals
> # ----------------------------#
> 
> # Purpose:
> #   - Normality: Verify that resid .... [TRUNCATED] 

> # Enhanced Q-Q Plot using ggplot2
> qq_plot <- ggplot(data.frame(Residuals = residuals), aes(sample = Residuals)) +
+   stat_qq(color = "blue") +
+  .... [TRUNCATED] 

> # Display the ggplot2 Q-Q plot
> print(qq_plot)

> # Save the ggplot2 Q-Q plot if saving is enabled
> if (save_graphs) {
+   ggsave(filename = file.path(graph_save_dir, "QQ_Plot_Residuals_GGPlot2.png ..." ... [TRUNCATED] 
[1] "Saved ggplot2 Q-Q Plot of Residuals."

> # ----------------------------#
> # 9. Histogram of Residuals
> # ----------------------------#
> 
> # Purpose:
> #   - Normality
> #
> # What to Lo .... [TRUNCATED] 

> # Enhanced Histogram using ggplot2
> hist_plot <- ggplot(data.frame(Residuals = residuals), aes(x = Residuals)) +
+   geom_histogram(aes(y = ..densi .... [TRUNCATED] 

> # Display the ggplot2 histogram
> print(hist_plot)

> # Save the ggplot2 histogram if saving is enabled
> if (save_graphs) {
+   ggsave(filename = file.path(graph_save_dir, "Histogram_Residuals_GGPlot2. ..." ... [TRUNCATED] 
[1] "Saved ggplot2 Histogram of Residuals with Normal Curve."

> # Redirect output to the specified file and also print to console
> sink(output_file, append = TRUE, split = TRUE)

> print("")
[1] ""

> # ----------------------------#
> # 10. Statistical Tests
> # ----------------------------#
> 
> 
> # --------- Shapiro-Wilk Test for Normality ---- .... [TRUNCATED] 
[1] "-------- Shapiro-Wilk Test for Normality ---------"

> print("  - Normality: To check if the residuals are normally distributed.")
[1] "  - Normality: To check if the residuals are normally distributed."

> print("  - p-value > 0.05: Fail to reject null hypothesis (residuals are normally distributed).")
[1] "  - p-value > 0.05: Fail to reject null hypothesis (residuals are normally distributed)."

> print("  - p-value <= 0.05: Reject null hypothesis (residuals are not normally distributed).\n")
[1] "  - p-value <= 0.05: Reject null hypothesis (residuals are not normally distributed).\n"

> shapiro_test <- shapiro.test(residuals)

> print("Shapiro-Wilk Test Results:")
[1] "Shapiro-Wilk Test Results:"

> print(shapiro_test)

	Shapiro-Wilk normality test

data:  residuals
W = 0.98701, p-value = 0.1405


> # --------- Breusch-Pagan Test for Homoscedasticity ---------
> print("-------- Breusch-Pagan Test for Homoscedasticity ---------")
[1] "-------- Breusch-Pagan Test for Homoscedasticity ---------"

> print("  - Homoscedasticity: To check if residuals have constant variance across all levels of fitted values.")
[1] "  - Homoscedasticity: To check if residuals have constant variance across all levels of fitted values."

> print("  - p-value > 0.05: Fail to reject null hypothesis (homoscedasticity holds).")
[1] "  - p-value > 0.05: Fail to reject null hypothesis (homoscedasticity holds)."

> print("  - p-value <= 0.05: Reject null hypothesis (heteroscedasticity present).\n")
[1] "  - p-value <= 0.05: Reject null hypothesis (heteroscedasticity present).\n"

> # Extract the model frame from the ssn_lm model
> data_ssn <- model.frame(ssn_mod)

> # Perform Breusch-Pagan Test
> bp_test <- bptest(ssn_mod)

> print("Breusch-Pagan Test Results:")
[1] "Breusch-Pagan Test Results:"

> print(bp_test)

	studentized Breusch-Pagan test

data:  ssn_mod
BP = 38.676, df = 18, p-value = 0.003149


> # --------- Moran's I Test for Spatial Autocorrelation ---------
> print("\n-------- Moran's I Test for Spatial Autocorrelation ---------")
[1] "\n-------- Moran's I Test for Spatial Autocorrelation ---------"

> print("  - Spatial Autocorrelation: To determine if there is spatial autocorrelation in the residuals.")
[1] "  - Spatial Autocorrelation: To determine if there is spatial autocorrelation in the residuals."

> print("  - p-value > 0.05: Fail to reject null hypothesis (lack of spatial autocorrelation in residuals holds).")
[1] "  - p-value > 0.05: Fail to reject null hypothesis (lack of spatial autocorrelation in residuals holds)."

> print("  - p-value <= 0.05: Reject null hypothesis (spatial autocorrelation present).\n")
[1] "  - p-value <= 0.05: Reject null hypothesis (spatial autocorrelation present).\n"

> sink()

> # Extract spatial coordinates from the SSN object
> # Ensure that your SSN object has geometry information
> coords <- st_coordinates(ssn_get_data(s .... [TRUNCATED] 

> # Create a spatial weights matrix using k-nearest neighbors (k = 4 as an example)
> knn <- knearneigh(coords, k = 4)

> nb <- knn2nb(knn)

> lw <- nb2listw(nb, style = "W", zero.policy = TRUE)

> # Compute Moran's I
> moran_test <- moran.test(residuals, lw, zero.policy = TRUE)

> sink(output_file, append = TRUE, split = TRUE)

> print("Moran's I Test Results:")
[1] "Moran's I Test Results:"

> print(moran_test)

	Moran I test under randomisation

data:  residuals  
weights: lw    

Moran I statistic standard deviate = -3.273, p-value = 0.9995
alternative hypothesis: greater
sample estimates:
Moran I statistic       Expectation          Variance 
     -0.184844335      -0.006250000       0.002977373 


> # Stop redirecting output
> sink()

> # --------------------------------------------------
> # End of Script
> # --------------------------------------------------
> 

> # --------------------------------------------------
> # Spatial Statistical Modeling with SSN2
> # ------------------------------------------------ .... [TRUNCATED] 

> # Specify the input and output directories
> input_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/Inputs"

> output_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/SSN ET/ET Lower error thresh"

> model_name <- "glm ch_sfm.erosion.norm VIF 3 100ct thresh"

> obs_points_path <- file.path(input_dir, "Combined Watersheds", "ET Lower ssn points.gpkg")

> read_ssn <- FALSE # whether to create a new ssn (FALSE) or read the pre-existing ssn (TRUE)

> # Use file.path to create platform-independent file paths
> streams_path <- file.path(input_dir, "streams_100k.gpkg")

> ssn_path <- file.path(output_dir, "1_ET_Full_logtrans_independent_vars.ssn")

> output_file <- file.path(output_dir, model_name, "Results.txt")

> lsn_out <- file.path(output_dir, "0_lsn")

> # Define whether to save graphs and the directory to save them
> save_graphs <- TRUE  # Set to TRUE to save graphs as PNG

> graph_save_dir <- file.path(output_dir, model_name)  # Directory to save graphs

> # ----------------------------#
> # 1. Load Necessary Libraries
> # ----------------------------#
> 
> # Load required libraries
> library(SSN2)

> library(SSNbler)

> library(sf)

> library(dplyr)

> library(purrr)

> library(ggplot2)

> library(lmtest)

> library(spdep)

> library(classInt)   # Required for knearneigh

> library(broom)      # For tidy() and glance() functions

> library(grid)       # For grid.newpage()

> if (!dir.exists(graph_save_dir)) {
+   dir.create(graph_save_dir, recursive = TRUE)
+ }

> # ----------------------------#
> # 2. Read Spatial Data
> # ----------------------------#
> 
> # Read the streams dataset
> ET_streams <- st_read(s .... [TRUNCATED] 
Reading layer `streams_100k' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\streams_100k.gpkg' using driver `GPKG'
Simple feature collection with 643 features and 2 fields
Geometry type: LINESTRING
Dimension:     XY
Bounding box:  xmin: 404042.6 ymin: 4447904 xmax: 414579.6 ymax: 4466669
Projected CRS: NAD83 / UTM zone 13N

> # Read the observation points dataset
> ET_obs <- st_read(obs_points_path)
Reading layer `ET Lower ssn points' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\Combined Watersheds\ET Lower ssn points.gpkg' using driver `GPKG'
Simple feature collection with 107 features and 59 fields
Geometry type: POINT
Dimension:     XY
Bounding box:  xmin: 411943.5 ymin: 4449827 xmax: 412955.4 ymax: 4450878
Projected CRS: NAD83 / UTM zone 13N

> # Uncomment the following line if you encounter an error about Multilinestrings
> # ET_streams <- st_cast(ET_streams, "LINESTRING")
> 
> # --------- .... [TRUNCATED] 
[1] "Edge Attributes:"
[1] "rid"            "STRM_VAL"       "flow_accum_max" "Length"         "upDist"         "geometry"      
[1] "Site List Components:"
[1] "obs"
[1] "Updated Edge Attributes:"
[1] "rid"            "STRM_VAL"       "flow_accum_max" "Length"         "upDist"         "flow_accum_PI"  "afv_flow_accum" "geometry"      


SSN object is valid: TRUE

> # Create a distance matrix for spatial relationships
> # Purpose: Define spatial dependencies based on distances between sites
> ssn_create_distmat( .... [TRUNCATED] 

> # ----------------------------#
> # 4. Model Fitting and Output
> # ----------------------------#
> 
> # Redirect output to the specified file and a .... [TRUNCATED] 

> model_name
[1] "glm ch_sfm.erosion.norm VIF 3 100ct thresh"

> model_formula
ch_sfm.erosion.norm ~ ch_slope.median + ch_flow.accumulation.max + 
    ch_curvature.median + ch_channel_width + ch_change.in.slope.over.width + 
    ch_channel.width.over.valley.width + ch_slope.over.width.central.diff + 
    hs_area + hs_slope.median + hs_eastness.median + hs_curvature.median + 
    hs_ndvi.range + hs_dnbr.median + hs_drainage_density

> ssn_mod <- ssn_glm(
+   formula = model_formula,
+   ssn.object = ET_ssn,
+   family = "Gamma",
+   tailup_type = "exponential",
+   taildown_type = .... [TRUNCATED] 

> # Print the summary of the model to the file and console
> print(summary(ssn_mod))

Call:
ssn_glm(formula = model_formula, ssn.object = ET_ssn, family = "Gamma", 
    tailup_type = "exponential", taildown_type = "none", euclid_type = "gaussian", 
    additive = "afv_flow_accum")

Deviance Residuals:
       Min         1Q     Median         3Q        Max 
-2.311e-03 -7.081e-04  3.821e-05  6.401e-04  2.403e-03 

Coefficients (fixed):
                                     Estimate Std. Error z value Pr(>|z|)    
(Intercept)                          0.079275   0.134372   0.590   0.5552    
ch_slope.median                      0.162290   0.136543   1.189   0.2346    
ch_flow.accumulation.max             1.372506   0.239731   5.725 1.03e-08 ***
ch_curvature.median                  0.174952   0.108718   1.609   0.1076    
ch_channel_width                    -0.603617   0.130405  -4.629 3.68e-06 ***
ch_change.in.slope.over.width        0.022200   0.082848   0.268   0.7887    
ch_channel.width.over.valley.width   0.211821   0.163054   1.299   0.1939    
ch_slope.over.width.central.diff     0.053927   0.076372   0.706   0.4801    
hs_area                             -0.001325   0.111872  -0.012   0.9905    
hs_slope.median                     -0.165978   0.106744  -1.555   0.1200    
hs_eastness.median                  -0.130313   0.137579  -0.947   0.3435    
hs_curvature.median                  0.031254   0.101434   0.308   0.7580    
hs_ndvi.range                        0.058051   0.145873   0.398   0.6907    
hs_dnbr.median                      -0.409874   0.185672  -2.208   0.0273 *  
hs_drainage_density                -18.497266  43.952175  -0.421   0.6739    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Pseudo R-squared: 0.2742

Coefficients (covariance):
              Effect     Parameter   Estimate
  tailup exponential  de (parsill)  5.416e-01
  tailup exponential         range  1.104e+01
     euclid gaussian  de (parsill)  1.199e-03
     euclid gaussian         range  1.580e+18
              nugget        nugget  6.702e-19
          dispersion    dispersion  1.473e+03


> # Print variance components of the model
> varcomp(ssn_mod)
# A tibble: 5 × 2
  varcomp            proportion
  <chr>                   <dbl>
1 Covariates (PR-sq)   2.74e- 1
2 tailup_de            7.24e- 1
3 taildown_de          0       
4 euclid_de            1.60e- 3
5 nugget               8.96e-19

> # Tidy the model output with confidence intervals and print
> print(tidy(ssn_mod, conf.int = TRUE))  
# A tibble: 15 × 7
   term                                estimate std.error statistic      p.value  conf.low conf.high
   <chr>                                  <dbl>     <dbl>     <dbl>        <dbl>     <dbl>     <dbl>
 1 (Intercept)                          0.0793     0.134     0.590  0.555          -0.184     0.343 
 2 ch_change.in.slope.over.width        0.0222     0.0828    0.268  0.789          -0.140     0.185 
 3 ch_channel.width.over.valley.width   0.212      0.163     1.30   0.194          -0.108     0.531 
 4 ch_channel_width                    -0.604      0.130    -4.63   0.00000368     -0.859    -0.348 
 5 ch_curvature.median                  0.175      0.109     1.61   0.108          -0.0381    0.388 
 6 ch_flow.accumulation.max             1.37       0.240     5.73   0.0000000103    0.903     1.84  
 7 ch_slope.median                      0.162      0.137     1.19   0.235          -0.105     0.430 
 8 ch_slope.over.width.central.diff     0.0539     0.0764    0.706  0.480          -0.0958    0.204 
 9 hs_area                             -0.00133    0.112    -0.0118 0.991          -0.221     0.218 
10 hs_curvature.median                  0.0313     0.101     0.308  0.758          -0.168     0.230 
11 hs_dnbr.median                      -0.410      0.186    -2.21   0.0273         -0.774    -0.0460
12 hs_drainage_density                -18.5       44.0      -0.421  0.674        -105.       67.6   
13 hs_eastness.median                  -0.130      0.138    -0.947  0.344          -0.400     0.139 
14 hs_ndvi.range                        0.0581     0.146     0.398  0.691          -0.228     0.344 
15 hs_slope.median                     -0.166      0.107    -1.55   0.120          -0.375     0.0432

> # Provide a glance summary of the model and print
> print(glance(ssn_mod))
# A tibble: 1 × 9
      n     p  npar value   AIC  AICc logLik  deviance pseudo.r.squared
  <int> <dbl> <int> <dbl> <dbl> <dbl>  <dbl>     <dbl>            <dbl>
1   107    15     6  359.  371.  372.  -180. 0.0000991            0.274

> # Perform Leave-One-Out Cross Validation and print
> print("Leave One Out Cross Validation")
[1] "Leave One Out Cross Validation"

> loocv_results <- loocv(ssn_mod)

> print(loocv_results)
# A tibble: 1 × 4
    bias  MSPE RMSPE   RAV
   <dbl> <dbl> <dbl> <dbl>
1 -0.101 0.997 0.998 0.706

> # Stop redirecting output
> sink()

> # ----------------------------#
> # 5. Model Evaluation
> # ----------------------------#
> 
> # Extract residuals and fitted values from the model
 .... [TRUNCATED] 

> fitted_values <- fitted(ssn_mod)   

> # ----------------------------#
> # 6. Plotting and Saving Graphs
> # ----------------------------#
> 
> 
> # Create the graph save directory if sav .... [TRUNCATED] 

> # ----------------------------#
> # 7. Residuals vs Fitted Values Plot
> # ----------------------------#
> 
> # Purpose:
> #   - Linearity: Ensure t .... [TRUNCATED] 

> # Create the Residuals vs Fitted Values plot
> resid_fitted_plot <- ggplot(data.frame(Fitted = fitted_values, Residuals = residuals), aes(x = Fitted .... [TRUNCATED] 

> # Display the plot
> print(resid_fitted_plot)

> # Save the plot if saving is enabled
> if (save_graphs) {
+   ggsave(filename = file.path(graph_save_dir, "Residuals_vs_Fitted.png"), plot = resid_f .... [TRUNCATED] 
[1] "Saved Residuals vs Fitted Values plot."

> # ----------------------------#
> # 8. Q-Q Plot for Residuals
> # ----------------------------#
> 
> # Purpose:
> #   - Normality: Verify that resid .... [TRUNCATED] 

> # Enhanced Q-Q Plot using ggplot2
> qq_plot <- ggplot(data.frame(Residuals = residuals), aes(sample = Residuals)) +
+   stat_qq(color = "blue") +
+  .... [TRUNCATED] 

> # Display the ggplot2 Q-Q plot
> print(qq_plot)

> # Save the ggplot2 Q-Q plot if saving is enabled
> if (save_graphs) {
+   ggsave(filename = file.path(graph_save_dir, "QQ_Plot_Residuals_GGPlot2.png ..." ... [TRUNCATED] 
[1] "Saved ggplot2 Q-Q Plot of Residuals."

> # ----------------------------#
> # 9. Histogram of Residuals
> # ----------------------------#
> 
> # Purpose:
> #   - Normality
> #
> # What to Lo .... [TRUNCATED] 

> # Enhanced Histogram using ggplot2
> hist_plot <- ggplot(data.frame(Residuals = residuals), aes(x = Residuals)) +
+   geom_histogram(aes(y = ..densi .... [TRUNCATED] 

> # Display the ggplot2 histogram
> print(hist_plot)

> # Save the ggplot2 histogram if saving is enabled
> if (save_graphs) {
+   ggsave(filename = file.path(graph_save_dir, "Histogram_Residuals_GGPlot2. ..." ... [TRUNCATED] 
[1] "Saved ggplot2 Histogram of Residuals with Normal Curve."

> # Redirect output to the specified file and also print to console
> sink(output_file, append = TRUE, split = TRUE)

> print("")
[1] ""

> # ----------------------------#
> # 10. Statistical Tests
> # ----------------------------#
> 
> 
> # --------- Shapiro-Wilk Test for Normality ---- .... [TRUNCATED] 
[1] "-------- Shapiro-Wilk Test for Normality ---------"

> print("  - Normality: To check if the residuals are normally distributed.")
[1] "  - Normality: To check if the residuals are normally distributed."

> print("  - p-value > 0.05: Fail to reject null hypothesis (residuals are normally distributed).")
[1] "  - p-value > 0.05: Fail to reject null hypothesis (residuals are normally distributed)."

> print("  - p-value <= 0.05: Reject null hypothesis (residuals are not normally distributed).\n")
[1] "  - p-value <= 0.05: Reject null hypothesis (residuals are not normally distributed).\n"

> shapiro_test <- shapiro.test(residuals)

> print("Shapiro-Wilk Test Results:")
[1] "Shapiro-Wilk Test Results:"

> print(shapiro_test)

	Shapiro-Wilk normality test

data:  residuals
W = 0.99402, p-value = 0.9259


> # --------- Breusch-Pagan Test for Homoscedasticity ---------
> print("-------- Breusch-Pagan Test for Homoscedasticity ---------")
[1] "-------- Breusch-Pagan Test for Homoscedasticity ---------"

> print("  - Homoscedasticity: To check if residuals have constant variance across all levels of fitted values.")
[1] "  - Homoscedasticity: To check if residuals have constant variance across all levels of fitted values."

> print("  - p-value > 0.05: Fail to reject null hypothesis (homoscedasticity holds).")
[1] "  - p-value > 0.05: Fail to reject null hypothesis (homoscedasticity holds)."

> print("  - p-value <= 0.05: Reject null hypothesis (heteroscedasticity present).\n")
[1] "  - p-value <= 0.05: Reject null hypothesis (heteroscedasticity present).\n"

> # Extract the model frame from the ssn_lm model
> data_ssn <- model.frame(ssn_mod)

> # Perform Breusch-Pagan Test
> bp_test <- bptest(ssn_mod)

> print("Breusch-Pagan Test Results:")
[1] "Breusch-Pagan Test Results:"

> print(bp_test)

	studentized Breusch-Pagan test

data:  ssn_mod
BP = 19.714, df = 14, p-value = 0.1394


> # --------- Moran's I Test for Spatial Autocorrelation ---------
> print("\n-------- Moran's I Test for Spatial Autocorrelation ---------")
[1] "\n-------- Moran's I Test for Spatial Autocorrelation ---------"

> print("  - Spatial Autocorrelation: To determine if there is spatial autocorrelation in the residuals.")
[1] "  - Spatial Autocorrelation: To determine if there is spatial autocorrelation in the residuals."

> print("  - p-value > 0.05: Fail to reject null hypothesis (lack of spatial autocorrelation in residuals holds).")
[1] "  - p-value > 0.05: Fail to reject null hypothesis (lack of spatial autocorrelation in residuals holds)."

> print("  - p-value <= 0.05: Reject null hypothesis (spatial autocorrelation present).\n")
[1] "  - p-value <= 0.05: Reject null hypothesis (spatial autocorrelation present).\n"

> sink()

> # Extract spatial coordinates from the SSN object
> # Ensure that your SSN object has geometry information
> coords <- st_coordinates(ssn_get_data(s .... [TRUNCATED] 

> # Create a spatial weights matrix using k-nearest neighbors (k = 4 as an example)
> knn <- knearneigh(coords, k = 4)

> nb <- knn2nb(knn)

> lw <- nb2listw(nb, style = "W", zero.policy = TRUE)

> # Compute Moran's I
> moran_test <- moran.test(residuals, lw, zero.policy = TRUE)

> sink(output_file, append = TRUE, split = TRUE)

> print("Moran's I Test Results:")
[1] "Moran's I Test Results:"

> print(moran_test)

	Moran I test under randomisation

data:  residuals  
weights: lw    

Moran I statistic standard deviate = -2.2457, p-value = 0.9876
alternative hypothesis: greater
sample estimates:
Moran I statistic       Expectation          Variance 
     -0.155371159      -0.009433962       0.004223150 


> # Stop redirecting output
> sink()

> # --------------------------------------------------
> # End of Script
> # --------------------------------------------------
> 

> # --------------------------------------------------
> # Spatial Statistical Modeling with SSN2
> # ------------------------------------------------ .... [TRUNCATED] 

> # Specify the input and output directories
> input_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/Inputs"

> output_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/SSN ET/ET Lower error thresh"

> model_name <- "glm ch_sfm.erosion.norm VIF 3 100ct thresh"

> obs_points_path <- file.path(input_dir, "Combined Watersheds", "ET Lower ssn points.gpkg")

> read_ssn <- FALSE # whether to create a new ssn (FALSE) or read the pre-existing ssn (TRUE)

> # Use file.path to create platform-independent file paths
> streams_path <- file.path(input_dir, "streams_100k.gpkg")

> ssn_path <- file.path(output_dir, "1_ET_Full_logtrans_independent_vars.ssn")

> output_file <- file.path(output_dir, model_name, "Results.txt")

> lsn_out <- file.path(output_dir, "0_lsn")

> # Define whether to save graphs and the directory to save them
> save_graphs <- TRUE  # Set to TRUE to save graphs as PNG

> graph_save_dir <- file.path(output_dir, model_name)  # Directory to save graphs

> # ----------------------------#
> # 1. Load Necessary Libraries
> # ----------------------------#
> 
> # Load required libraries
> library(SSN2)

> library(SSNbler)

> library(sf)

> library(dplyr)

> library(purrr)

> library(ggplot2)

> library(lmtest)

> library(spdep)

> library(classInt)   # Required for knearneigh

> library(broom)      # For tidy() and glance() functions

> library(grid)       # For grid.newpage()

> if (!dir.exists(graph_save_dir)) {
+   dir.create(graph_save_dir, recursive = TRUE)
+ }

> # ----------------------------#
> # 2. Read Spatial Data
> # ----------------------------#
> 
> # Read the streams dataset
> ET_streams <- st_read(s .... [TRUNCATED] 
Reading layer `streams_100k' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\streams_100k.gpkg' using driver `GPKG'
Simple feature collection with 643 features and 2 fields
Geometry type: LINESTRING
Dimension:     XY
Bounding box:  xmin: 404042.6 ymin: 4447904 xmax: 414579.6 ymax: 4466669
Projected CRS: NAD83 / UTM zone 13N

> # Read the observation points dataset
> ET_obs <- st_read(obs_points_path)
Reading layer `ET Lower ssn points' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\Combined Watersheds\ET Lower ssn points.gpkg' using driver `GPKG'
Simple feature collection with 107 features and 59 fields
Geometry type: POINT
Dimension:     XY
Bounding box:  xmin: 411943.5 ymin: 4449827 xmax: 412955.4 ymax: 4450878
Projected CRS: NAD83 / UTM zone 13N

> # Uncomment the following line if you encounter an error about Multilinestrings
> # ET_streams <- st_cast(ET_streams, "LINESTRING")
> 
> # --------- .... [TRUNCATED] 
[1] "Edge Attributes:"
[1] "rid"            "STRM_VAL"       "flow_accum_max" "Length"         "upDist"         "geometry"      
[1] "Site List Components:"
[1] "obs"
[1] "Updated Edge Attributes:"
[1] "rid"            "STRM_VAL"       "flow_accum_max" "Length"         "upDist"         "flow_accum_PI"  "afv_flow_accum" "geometry"      


SSN object is valid: TRUE

> # Create a distance matrix for spatial relationships
> # Purpose: Define spatial dependencies based on distances between sites
> ssn_create_distmat( .... [TRUNCATED] 

> # ----------------------------#
> # 4. Model Fitting and Output
> # ----------------------------#
> 
> # Redirect output to the specified file and a .... [TRUNCATED] 

> model_name
[1] "glm ch_sfm.erosion.norm VIF 3 100ct thresh"

> model_formula
ch_sfm.erosion.norm ~ ch_slope.median + ch_flow.accumulation.max + 
    ch_curvature.median + ch_valley_width + ch_central.slope.difference + 
    ch_channel.width.over.valley.width + ch_slope.over.width.central.diff + 
    hs_area + hs_slope.median + hs_eastness.median + hs_curvature.median + 
    hs_ndvi.range + hs_dnbr.median + hs_drainage_density

> ssn_mod <- ssn_glm(
+   formula = model_formula,
+   ssn.object = ET_ssn,
+   family = "Gamma",
+   tailup_type = "exponential",
+   taildown_type = .... [TRUNCATED] 

> # Print the summary of the model to the file and console
> print(summary(ssn_mod))

Call:
ssn_glm(formula = model_formula, ssn.object = ET_ssn, family = "Gamma", 
    tailup_type = "exponential", taildown_type = "none", euclid_type = "gaussian", 
    additive = "afv_flow_accum")

Deviance Residuals:
       Min         1Q     Median         3Q        Max 
-0.0070917 -0.0016667  0.0000772  0.0015103  0.0068540 

Coefficients (fixed):
                                    Estimate Std. Error z value Pr(>|z|)    
(Intercept)                          0.07162    0.16155   0.443  0.65751    
ch_slope.median                      0.21851    0.15029   1.454  0.14596    
ch_flow.accumulation.max             1.30897    0.28874   4.533 5.81e-06 ***
ch_curvature.median                  0.02483    0.10655   0.233  0.81576    
ch_valley_width                     -0.41059    0.15866  -2.588  0.00966 ** 
ch_central.slope.difference          0.07123    0.07860   0.906  0.36476    
ch_channel.width.over.valley.width  -0.28161    0.17129  -1.644  0.10017    
ch_slope.over.width.central.diff     0.02645    0.07671   0.345  0.73026    
hs_area                              0.01978    0.11720   0.169  0.86597    
hs_slope.median                     -0.12173    0.11210  -1.086  0.27753    
hs_eastness.median                  -0.10291    0.14229  -0.723  0.46951    
hs_curvature.median                  0.06978    0.10336   0.675  0.49962    
hs_ndvi.range                        0.06150    0.15706   0.392  0.69537    
hs_dnbr.median                      -0.39137    0.20229  -1.935  0.05303 .  
hs_drainage_density                -36.29232   45.59787  -0.796  0.42608    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Pseudo R-squared: 0.1683

Coefficients (covariance):
              Effect     Parameter   Estimate
  tailup exponential  de (parsill)  6.465e-01
  tailup exponential         range  1.565e+01
     euclid gaussian  de (parsill)  2.372e-08
     euclid gaussian         range  8.643e+04
              nugget        nugget  2.164e-02
          dispersion    dispersion  5.548e+02


> # Print variance components of the model
> varcomp(ssn_mod)
# A tibble: 5 × 2
  varcomp              proportion
  <chr>                     <dbl>
1 Covariates (PR-sq) 0.168       
2 tailup_de          0.805       
3 taildown_de        0           
4 euclid_de          0.0000000295
5 nugget             0.0269      

> # Tidy the model output with confidence intervals and print
> print(tidy(ssn_mod, conf.int = TRUE))  
# A tibble: 15 × 7
   term                               estimate std.error statistic    p.value  conf.low conf.high
   <chr>                                 <dbl>     <dbl>     <dbl>      <dbl>     <dbl>     <dbl>
 1 (Intercept)                          0.0716    0.162      0.443 0.658        -0.245    0.388  
 2 ch_central.slope.difference          0.0712    0.0786     0.906 0.365        -0.0828   0.225  
 3 ch_channel.width.over.valley.width  -0.282     0.171     -1.64  0.100        -0.617    0.0541 
 4 ch_curvature.median                  0.0248    0.107      0.233 0.816        -0.184    0.234  
 5 ch_flow.accumulation.max             1.31      0.289      4.53  0.00000581    0.743    1.87   
 6 ch_slope.median                      0.219     0.150      1.45  0.146        -0.0760   0.513  
 7 ch_slope.over.width.central.diff     0.0264    0.0767     0.345 0.730        -0.124    0.177  
 8 ch_valley_width                     -0.411     0.159     -2.59  0.00966      -0.722   -0.0996 
 9 hs_area                              0.0198    0.117      0.169 0.866        -0.210    0.249  
10 hs_curvature.median                  0.0698    0.103      0.675 0.500        -0.133    0.272  
11 hs_dnbr.median                      -0.391     0.202     -1.93  0.0530       -0.788    0.00511
12 hs_drainage_density                -36.3      45.6       -0.796 0.426      -126.      53.1    
13 hs_eastness.median                  -0.103     0.142     -0.723 0.470        -0.382    0.176  
14 hs_ndvi.range                        0.0615    0.157      0.392 0.695        -0.246    0.369  
15 hs_slope.median                     -0.122     0.112     -1.09  0.278        -0.341    0.0980 

> # Provide a glance summary of the model and print
> print(glance(ssn_mod))
# A tibble: 1 × 9
      n     p  npar value   AIC  AICc logLik deviance pseudo.r.squared
  <int> <dbl> <int> <dbl> <dbl> <dbl>  <dbl>    <dbl>            <dbl>
1   107    15     6  369.  381.  381.  -184. 0.000664            0.168

> # Perform Leave-One-Out Cross Validation and print
> print("Leave One Out Cross Validation")
[1] "Leave One Out Cross Validation"

> loocv_results <- loocv(ssn_mod)

> print(loocv_results)
# A tibble: 1 × 4
    bias  MSPE RMSPE   RAV
   <dbl> <dbl> <dbl> <dbl>
1 -0.120 0.723 0.850 0.728

> # Stop redirecting output
> sink()

> # ----------------------------#
> # 5. Model Evaluation
> # ----------------------------#
> 
> # Extract residuals and fitted values from the model
 .... [TRUNCATED] 

> fitted_values <- fitted(ssn_mod)   

> # ----------------------------#
> # 6. Plotting and Saving Graphs
> # ----------------------------#
> 
> 
> # Create the graph save directory if sav .... [TRUNCATED] 

> # ----------------------------#
> # 7. Residuals vs Fitted Values Plot
> # ----------------------------#
> 
> # Purpose:
> #   - Linearity: Ensure t .... [TRUNCATED] 

> # Create the Residuals vs Fitted Values plot
> resid_fitted_plot <- ggplot(data.frame(Fitted = fitted_values, Residuals = residuals), aes(x = Fitted .... [TRUNCATED] 

> # Display the plot
> print(resid_fitted_plot)

> # Save the plot if saving is enabled
> if (save_graphs) {
+   ggsave(filename = file.path(graph_save_dir, "Residuals_vs_Fitted.png"), plot = resid_f .... [TRUNCATED] 
[1] "Saved Residuals vs Fitted Values plot."

> # ----------------------------#
> # 8. Q-Q Plot for Residuals
> # ----------------------------#
> 
> # Purpose:
> #   - Normality: Verify that resid .... [TRUNCATED] 

> # Enhanced Q-Q Plot using ggplot2
> qq_plot <- ggplot(data.frame(Residuals = residuals), aes(sample = Residuals)) +
+   stat_qq(color = "blue") +
+  .... [TRUNCATED] 

> # Display the ggplot2 Q-Q plot
> print(qq_plot)

> # Save the ggplot2 Q-Q plot if saving is enabled
> if (save_graphs) {
+   ggsave(filename = file.path(graph_save_dir, "QQ_Plot_Residuals_GGPlot2.png ..." ... [TRUNCATED] 
[1] "Saved ggplot2 Q-Q Plot of Residuals."

> # ----------------------------#
> # 9. Histogram of Residuals
> # ----------------------------#
> 
> # Purpose:
> #   - Normality
> #
> # What to Lo .... [TRUNCATED] 

> # Enhanced Histogram using ggplot2
> hist_plot <- ggplot(data.frame(Residuals = residuals), aes(x = Residuals)) +
+   geom_histogram(aes(y = ..densi .... [TRUNCATED] 

> # Display the ggplot2 histogram
> print(hist_plot)

> # Save the ggplot2 histogram if saving is enabled
> if (save_graphs) {
+   ggsave(filename = file.path(graph_save_dir, "Histogram_Residuals_GGPlot2. ..." ... [TRUNCATED] 
[1] "Saved ggplot2 Histogram of Residuals with Normal Curve."

> # Redirect output to the specified file and also print to console
> sink(output_file, append = TRUE, split = TRUE)

> print("")
[1] ""

> # ----------------------------#
> # 10. Statistical Tests
> # ----------------------------#
> 
> 
> # --------- Shapiro-Wilk Test for Normality ---- .... [TRUNCATED] 
[1] "-------- Shapiro-Wilk Test for Normality ---------"

> print("  - Normality: To check if the residuals are normally distributed.")
[1] "  - Normality: To check if the residuals are normally distributed."

> print("  - p-value > 0.05: Fail to reject null hypothesis (residuals are normally distributed).")
[1] "  - p-value > 0.05: Fail to reject null hypothesis (residuals are normally distributed)."

> print("  - p-value <= 0.05: Reject null hypothesis (residuals are not normally distributed).\n")
[1] "  - p-value <= 0.05: Reject null hypothesis (residuals are not normally distributed).\n"

> shapiro_test <- shapiro.test(residuals)

> print("Shapiro-Wilk Test Results:")
[1] "Shapiro-Wilk Test Results:"

> print(shapiro_test)

	Shapiro-Wilk normality test

data:  residuals
W = 0.98881, p-value = 0.52


> # --------- Breusch-Pagan Test for Homoscedasticity ---------
> print("-------- Breusch-Pagan Test for Homoscedasticity ---------")
[1] "-------- Breusch-Pagan Test for Homoscedasticity ---------"

> print("  - Homoscedasticity: To check if residuals have constant variance across all levels of fitted values.")
[1] "  - Homoscedasticity: To check if residuals have constant variance across all levels of fitted values."

> print("  - p-value > 0.05: Fail to reject null hypothesis (homoscedasticity holds).")
[1] "  - p-value > 0.05: Fail to reject null hypothesis (homoscedasticity holds)."

> print("  - p-value <= 0.05: Reject null hypothesis (heteroscedasticity present).\n")
[1] "  - p-value <= 0.05: Reject null hypothesis (heteroscedasticity present).\n"

> # Extract the model frame from the ssn_lm model
> data_ssn <- model.frame(ssn_mod)

> # Perform Breusch-Pagan Test
> bp_test <- bptest(ssn_mod)

> print("Breusch-Pagan Test Results:")
[1] "Breusch-Pagan Test Results:"

> print(bp_test)

	studentized Breusch-Pagan test

data:  ssn_mod
BP = 20.444, df = 14, p-value = 0.1167


> # --------- Moran's I Test for Spatial Autocorrelation ---------
> print("\n-------- Moran's I Test for Spatial Autocorrelation ---------")
[1] "\n-------- Moran's I Test for Spatial Autocorrelation ---------"

> print("  - Spatial Autocorrelation: To determine if there is spatial autocorrelation in the residuals.")
[1] "  - Spatial Autocorrelation: To determine if there is spatial autocorrelation in the residuals."

> print("  - p-value > 0.05: Fail to reject null hypothesis (lack of spatial autocorrelation in residuals holds).")
[1] "  - p-value > 0.05: Fail to reject null hypothesis (lack of spatial autocorrelation in residuals holds)."

> print("  - p-value <= 0.05: Reject null hypothesis (spatial autocorrelation present).\n")
[1] "  - p-value <= 0.05: Reject null hypothesis (spatial autocorrelation present).\n"

> sink()

> # Extract spatial coordinates from the SSN object
> # Ensure that your SSN object has geometry information
> coords <- st_coordinates(ssn_get_data(s .... [TRUNCATED] 

> # Create a spatial weights matrix using k-nearest neighbors (k = 4 as an example)
> knn <- knearneigh(coords, k = 4)

> nb <- knn2nb(knn)

> lw <- nb2listw(nb, style = "W", zero.policy = TRUE)

> # Compute Moran's I
> moran_test <- moran.test(residuals, lw, zero.policy = TRUE)

> sink(output_file, append = TRUE, split = TRUE)

> print("Moran's I Test Results:")
[1] "Moran's I Test Results:"

> print(moran_test)

	Moran I test under randomisation

data:  residuals  
weights: lw    

Moran I statistic standard deviate = -2.5563, p-value = 0.9947
alternative hypothesis: greater
sample estimates:
Moran I statistic       Expectation          Variance 
     -0.175219908      -0.009433962       0.004205943 


> # Stop redirecting output
> sink()

> # --------------------------------------------------
> # End of Script
> # --------------------------------------------------
> 

> # --------------------------------------------------
> # Spatial Statistical Modeling with SSN2
> # ------------------------------------------------ .... [TRUNCATED] 

> # Specify the input and output directories
> input_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/Inputs"

> output_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/SSN ET/ET Lower error thresh"

> model_name <- "glm ch_sfm.erosion.norm VIF 3 100ct thresh ws_re"

> obs_points_path <- file.path(input_dir, "Combined Watersheds", "ET Lower ssn points.gpkg")

> read_ssn <- TRUE # whether to create a new ssn (FALSE) or read the pre-existing ssn (TRUE)

> # Use file.path to create platform-independent file paths
> streams_path <- file.path(input_dir, "streams_100k.gpkg")

> ssn_path <- file.path(output_dir, "1_ET_Full_logtrans_independent_vars.ssn")

> output_file <- file.path(output_dir, model_name, "Results.txt")

> lsn_out <- file.path(output_dir, "0_lsn")

> # Define whether to save graphs and the directory to save them
> save_graphs <- TRUE  # Set to TRUE to save graphs as PNG

> graph_save_dir <- file.path(output_dir, model_name)  # Directory to save graphs

> # ----------------------------#
> # 1. Load Necessary Libraries
> # ----------------------------#
> 
> # Load required libraries
> library(SSN2)

> library(SSNbler)

> library(sf)

> library(dplyr)

> library(purrr)

> library(ggplot2)

> library(lmtest)

> library(spdep)

> library(classInt)   # Required for knearneigh

> library(broom)      # For tidy() and glance() functions

> library(grid)       # For grid.newpage()

> if (!dir.exists(graph_save_dir)) {
+   dir.create(graph_save_dir, recursive = TRUE)
+ }

> # ----------------------------#
> # 2. Read Spatial Data
> # ----------------------------#
> 
> # Read the streams dataset
> ET_streams <- st_read(s .... [TRUNCATED] 
Reading layer `streams_100k' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\streams_100k.gpkg' using driver `GPKG'
Simple feature collection with 643 features and 2 fields
Geometry type: LINESTRING
Dimension:     XY
Bounding box:  xmin: 404042.6 ymin: 4447904 xmax: 414579.6 ymax: 4466669
Projected CRS: NAD83 / UTM zone 13N

> # Read the observation points dataset
> ET_obs <- st_read(obs_points_path)
Reading layer `ET Lower ssn points' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\Combined Watersheds\ET Lower ssn points.gpkg' using driver `GPKG'
Simple feature collection with 107 features and 59 fields
Geometry type: POINT
Dimension:     XY
Bounding box:  xmin: 411943.5 ymin: 4449827 xmax: 412955.4 ymax: 4450878
Projected CRS: NAD83 / UTM zone 13N

> # Uncomment the following line if you encounter an error about Multilinestrings
> # ET_streams <- st_cast(ET_streams, "LINESTRING")
> 
> # --------- .... [TRUNCATED] 

> # Create a distance matrix for spatial relationships
> # Purpose: Define spatial dependencies based on distances between sites
> ssn_create_distmat( .... [TRUNCATED] 

> # ----------------------------#
> # 4. Model Fitting and Output
> # ----------------------------#
> 
> # Redirect output to the specified file and a .... [TRUNCATED] 

> model_name
[1] "glm ch_sfm.erosion.norm VIF 3 100ct thresh ws_re"

> model_formula
ch_sfm.erosion.norm ~ ch_slope.median + ch_flow.accumulation.max + 
    ch_curvature.median + ch_valley_width + ch_central.slope.difference + 
    ch_channel.width.over.valley.width + ch_slope.over.width.central.diff + 
    hs_area + hs_slope.median + hs_eastness.median + hs_curvature.median + 
    hs_ndvi.range + hs_dnbr.median + hs_drainage_density + (1 | 
    ch_watershed)

> ssn_mod <- ssn_glm(
+   formula = model_formula,
+   ssn.object = ET_ssn,
+   family = "Gamma",
+   tailup_type = "exponential",
+   taildown_type = .... [TRUNCATED] 

> # --------------------------------------------------
> # Spatial Statistical Modeling with SSN2
> # ------------------------------------------------ .... [TRUNCATED] 

> # --------------------------------------------------
> # Spatial Statistical Modeling with SSN2
> # ------------------------------------------------ .... [TRUNCATED] 

> # Specify the input and output directories
> input_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/Inputs"

> output_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/SSN ET/ET Lower error thresh"

> model_name <- "glm ch_sfm.erosion.norm VIF 3 100ct thresh ws_re"

> obs_points_path <- file.path(input_dir, "Combined Watersheds", "ET Lower ssn points.gpkg")

> read_ssn <- TRUE # whether to create a new ssn (FALSE) or read the pre-existing ssn (TRUE)

> # Use file.path to create platform-independent file paths
> streams_path <- file.path(input_dir, "streams_100k.gpkg")

> ssn_path <- file.path(output_dir, "1_ET_Full_logtrans_independent_vars.ssn")

> output_file <- file.path(output_dir, model_name, "Results.txt")

> lsn_out <- file.path(output_dir, "0_lsn")

> # Define whether to save graphs and the directory to save them
> save_graphs <- TRUE  # Set to TRUE to save graphs as PNG

> graph_save_dir <- file.path(output_dir, model_name)  # Directory to save graphs

> # ----------------------------#
> # 1. Load Necessary Libraries
> # ----------------------------#
> 
> # Load required libraries
> library(SSN2)

> library(SSNbler)

> library(sf)

> library(dplyr)

> library(purrr)

> library(ggplot2)

> library(lmtest)

> library(spdep)

> library(classInt)   # Required for knearneigh

> library(broom)      # For tidy() and glance() functions

> library(grid)       # For grid.newpage()

> if (!dir.exists(graph_save_dir)) {
+   dir.create(graph_save_dir, recursive = TRUE)
+ }

> # ----------------------------#
> # 2. Read Spatial Data
> # ----------------------------#
> 
> # Read the streams dataset
> ET_streams <- st_read(s .... [TRUNCATED] 
Reading layer `streams_100k' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\streams_100k.gpkg' using driver `GPKG'
Simple feature collection with 643 features and 2 fields
Geometry type: LINESTRING
Dimension:     XY
Bounding box:  xmin: 404042.6 ymin: 4447904 xmax: 414579.6 ymax: 4466669
Projected CRS: NAD83 / UTM zone 13N

> # Read the observation points dataset
> ET_obs <- st_read(obs_points_path)
Reading layer `ET Lower ssn points' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\Combined Watersheds\ET Lower ssn points.gpkg' using driver `GPKG'
Simple feature collection with 107 features and 59 fields
Geometry type: POINT
Dimension:     XY
Bounding box:  xmin: 411943.5 ymin: 4449827 xmax: 412955.4 ymax: 4450878
Projected CRS: NAD83 / UTM zone 13N

> # Uncomment the following line if you encounter an error about Multilinestrings
> # ET_streams <- st_cast(ET_streams, "LINESTRING")
> 
> # --------- .... [TRUNCATED] 

> # Create a distance matrix for spatial relationships
> # Purpose: Define spatial dependencies based on distances between sites
> ssn_create_distmat( .... [TRUNCATED] 

> # ----------------------------#
> # 4. Model Fitting and Output
> # ----------------------------#
> 
> # Redirect output to the specified file and a .... [TRUNCATED] 

> model_name
[1] "glm ch_sfm.erosion.norm VIF 3 100ct thresh ws_re"

> model_formula
ch_sfm.erosion.norm ~ ch_slope.median + ch_flow.accumulation.max + 
    ch_curvature.median + ch_valley_width + ch_central.slope.difference + 
    ch_channel.width.over.valley.width + ch_slope.over.width.central.diff + 
    hs_area + hs_slope.median + hs_eastness.median + hs_curvature.median + 
    hs_ndvi.range + hs_dnbr.median + hs_drainage_density

> ssn_mod <- ssn_glm(
+   formula = model_formula,
+   ssn.object = ET_ssn,
+   family = "Gamma",
+   tailup_type = "exponential",
+   taildown_type = .... [TRUNCATED] 

> # Print the summary of the model to the file and console
> print(summary(ssn_mod))

Call:
ssn_glm(formula = model_formula, ssn.object = ET_ssn, family = "Gamma", 
    tailup_type = "exponential", taildown_type = "none", euclid_type = "gaussian", 
    additive = "afv_flow_accum")

Deviance Residuals:
       Min         1Q     Median         3Q        Max 
-0.0070917 -0.0016667  0.0000772  0.0015103  0.0068540 

Coefficients (fixed):
                                    Estimate Std. Error z value Pr(>|z|)    
(Intercept)                          0.07162    0.16155   0.443  0.65751    
ch_slope.median                      0.21851    0.15029   1.454  0.14596    
ch_flow.accumulation.max             1.30897    0.28874   4.533 5.81e-06 ***
ch_curvature.median                  0.02483    0.10655   0.233  0.81576    
ch_valley_width                     -0.41059    0.15866  -2.588  0.00966 ** 
ch_central.slope.difference          0.07123    0.07860   0.906  0.36476    
ch_channel.width.over.valley.width  -0.28161    0.17129  -1.644  0.10017    
ch_slope.over.width.central.diff     0.02645    0.07671   0.345  0.73026    
hs_area                              0.01978    0.11720   0.169  0.86597    
hs_slope.median                     -0.12173    0.11210  -1.086  0.27753    
hs_eastness.median                  -0.10291    0.14229  -0.723  0.46951    
hs_curvature.median                  0.06978    0.10336   0.675  0.49962    
hs_ndvi.range                        0.06150    0.15706   0.392  0.69537    
hs_dnbr.median                      -0.39137    0.20229  -1.935  0.05303 .  
hs_drainage_density                -36.29232   45.59787  -0.796  0.42608    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Pseudo R-squared: 0.1683

Coefficients (covariance):
              Effect     Parameter   Estimate
  tailup exponential  de (parsill)  6.465e-01
  tailup exponential         range  1.565e+01
     euclid gaussian  de (parsill)  2.372e-08
     euclid gaussian         range  8.643e+04
              nugget        nugget  2.164e-02
          dispersion    dispersion  5.548e+02


> # Print variance components of the model
> varcomp(ssn_mod)
# A tibble: 5 × 2
  varcomp              proportion
  <chr>                     <dbl>
1 Covariates (PR-sq) 0.168       
2 tailup_de          0.805       
3 taildown_de        0           
4 euclid_de          0.0000000295
5 nugget             0.0269      

> # Tidy the model output with confidence intervals and print
> print(tidy(ssn_mod, conf.int = TRUE))  
# A tibble: 15 × 7
   term                               estimate std.error statistic    p.value  conf.low conf.high
   <chr>                                 <dbl>     <dbl>     <dbl>      <dbl>     <dbl>     <dbl>
 1 (Intercept)                          0.0716    0.162      0.443 0.658        -0.245    0.388  
 2 ch_central.slope.difference          0.0712    0.0786     0.906 0.365        -0.0828   0.225  
 3 ch_channel.width.over.valley.width  -0.282     0.171     -1.64  0.100        -0.617    0.0541 
 4 ch_curvature.median                  0.0248    0.107      0.233 0.816        -0.184    0.234  
 5 ch_flow.accumulation.max             1.31      0.289      4.53  0.00000581    0.743    1.87   
 6 ch_slope.median                      0.219     0.150      1.45  0.146        -0.0760   0.513  
 7 ch_slope.over.width.central.diff     0.0264    0.0767     0.345 0.730        -0.124    0.177  
 8 ch_valley_width                     -0.411     0.159     -2.59  0.00966      -0.722   -0.0996 
 9 hs_area                              0.0198    0.117      0.169 0.866        -0.210    0.249  
10 hs_curvature.median                  0.0698    0.103      0.675 0.500        -0.133    0.272  
11 hs_dnbr.median                      -0.391     0.202     -1.93  0.0530       -0.788    0.00511
12 hs_drainage_density                -36.3      45.6       -0.796 0.426      -126.      53.1    
13 hs_eastness.median                  -0.103     0.142     -0.723 0.470        -0.382    0.176  
14 hs_ndvi.range                        0.0615    0.157      0.392 0.695        -0.246    0.369  
15 hs_slope.median                     -0.122     0.112     -1.09  0.278        -0.341    0.0980 

> # Provide a glance summary of the model and print
> print(glance(ssn_mod))
# A tibble: 1 × 9
      n     p  npar value   AIC  AICc logLik deviance pseudo.r.squared
  <int> <dbl> <int> <dbl> <dbl> <dbl>  <dbl>    <dbl>            <dbl>
1   107    15     6  369.  381.  381.  -184. 0.000664            0.168

> # Perform Leave-One-Out Cross Validation and print
> print("Leave One Out Cross Validation")
[1] "Leave One Out Cross Validation"

> loocv_results <- loocv(ssn_mod)

> print(loocv_results)
# A tibble: 1 × 4
    bias  MSPE RMSPE   RAV
   <dbl> <dbl> <dbl> <dbl>
1 -0.120 0.723 0.850 0.728

> # Stop redirecting output
> sink()

> # ----------------------------#
> # 5. Model Evaluation
> # ----------------------------#
> 
> # Extract residuals and fitted values from the model
 .... [TRUNCATED] 

> fitted_values <- fitted(ssn_mod)   

> # ----------------------------#
> # 6. Plotting and Saving Graphs
> # ----------------------------#
> 
> 
> # Create the graph save directory if sav .... [TRUNCATED] 

> # ----------------------------#
> # 7. Residuals vs Fitted Values Plot
> # ----------------------------#
> 
> # Purpose:
> #   - Linearity: Ensure t .... [TRUNCATED] 

> # Create the Residuals vs Fitted Values plot
> resid_fitted_plot <- ggplot(data.frame(Fitted = fitted_values, Residuals = residuals), aes(x = Fitted .... [TRUNCATED] 

> # Display the plot
> print(resid_fitted_plot)

> # Save the plot if saving is enabled
> if (save_graphs) {
+   ggsave(filename = file.path(graph_save_dir, "Residuals_vs_Fitted.png"), plot = resid_f .... [TRUNCATED] 
[1] "Saved Residuals vs Fitted Values plot."

> # ----------------------------#
> # 8. Q-Q Plot for Residuals
> # ----------------------------#
> 
> # Purpose:
> #   - Normality: Verify that resid .... [TRUNCATED] 

> # Enhanced Q-Q Plot using ggplot2
> qq_plot <- ggplot(data.frame(Residuals = residuals), aes(sample = Residuals)) +
+   stat_qq(color = "blue") +
+  .... [TRUNCATED] 

> # Display the ggplot2 Q-Q plot
> print(qq_plot)

> # Save the ggplot2 Q-Q plot if saving is enabled
> if (save_graphs) {
+   ggsave(filename = file.path(graph_save_dir, "QQ_Plot_Residuals_GGPlot2.png ..." ... [TRUNCATED] 
[1] "Saved ggplot2 Q-Q Plot of Residuals."

> # ----------------------------#
> # 9. Histogram of Residuals
> # ----------------------------#
> 
> # Purpose:
> #   - Normality
> #
> # What to Lo .... [TRUNCATED] 

> # Enhanced Histogram using ggplot2
> hist_plot <- ggplot(data.frame(Residuals = residuals), aes(x = Residuals)) +
+   geom_histogram(aes(y = ..densi .... [TRUNCATED] 

> # Display the ggplot2 histogram
> print(hist_plot)

> # Save the ggplot2 histogram if saving is enabled
> if (save_graphs) {
+   ggsave(filename = file.path(graph_save_dir, "Histogram_Residuals_GGPlot2. ..." ... [TRUNCATED] 
[1] "Saved ggplot2 Histogram of Residuals with Normal Curve."

> # Redirect output to the specified file and also print to console
> sink(output_file, append = TRUE, split = TRUE)

> print("")
[1] ""

> # ----------------------------#
> # 10. Statistical Tests
> # ----------------------------#
> 
> 
> # --------- Shapiro-Wilk Test for Normality ---- .... [TRUNCATED] 
[1] "-------- Shapiro-Wilk Test for Normality ---------"

> print("  - Normality: To check if the residuals are normally distributed.")
[1] "  - Normality: To check if the residuals are normally distributed."

> print("  - p-value > 0.05: Fail to reject null hypothesis (residuals are normally distributed).")
[1] "  - p-value > 0.05: Fail to reject null hypothesis (residuals are normally distributed)."

> print("  - p-value <= 0.05: Reject null hypothesis (residuals are not normally distributed).\n")
[1] "  - p-value <= 0.05: Reject null hypothesis (residuals are not normally distributed).\n"

> shapiro_test <- shapiro.test(residuals)

> print("Shapiro-Wilk Test Results:")
[1] "Shapiro-Wilk Test Results:"

> print(shapiro_test)

	Shapiro-Wilk normality test

data:  residuals
W = 0.98881, p-value = 0.52


> # --------- Breusch-Pagan Test for Homoscedasticity ---------
> print("-------- Breusch-Pagan Test for Homoscedasticity ---------")
[1] "-------- Breusch-Pagan Test for Homoscedasticity ---------"

> print("  - Homoscedasticity: To check if residuals have constant variance across all levels of fitted values.")
[1] "  - Homoscedasticity: To check if residuals have constant variance across all levels of fitted values."

> print("  - p-value > 0.05: Fail to reject null hypothesis (homoscedasticity holds).")
[1] "  - p-value > 0.05: Fail to reject null hypothesis (homoscedasticity holds)."

> print("  - p-value <= 0.05: Reject null hypothesis (heteroscedasticity present).\n")
[1] "  - p-value <= 0.05: Reject null hypothesis (heteroscedasticity present).\n"

> # Extract the model frame from the ssn_lm model
> data_ssn <- model.frame(ssn_mod)

> # Perform Breusch-Pagan Test
> bp_test <- bptest(ssn_mod)

> print("Breusch-Pagan Test Results:")
[1] "Breusch-Pagan Test Results:"

> print(bp_test)

	studentized Breusch-Pagan test

data:  ssn_mod
BP = 20.444, df = 14, p-value = 0.1167


> # --------- Moran's I Test for Spatial Autocorrelation ---------
> print("\n-------- Moran's I Test for Spatial Autocorrelation ---------")
[1] "\n-------- Moran's I Test for Spatial Autocorrelation ---------"

> print("  - Spatial Autocorrelation: To determine if there is spatial autocorrelation in the residuals.")
[1] "  - Spatial Autocorrelation: To determine if there is spatial autocorrelation in the residuals."

> print("  - p-value > 0.05: Fail to reject null hypothesis (lack of spatial autocorrelation in residuals holds).")
[1] "  - p-value > 0.05: Fail to reject null hypothesis (lack of spatial autocorrelation in residuals holds)."

> print("  - p-value <= 0.05: Reject null hypothesis (spatial autocorrelation present).\n")
[1] "  - p-value <= 0.05: Reject null hypothesis (spatial autocorrelation present).\n"

> sink()

> # Extract spatial coordinates from the SSN object
> # Ensure that your SSN object has geometry information
> coords <- st_coordinates(ssn_get_data(s .... [TRUNCATED] 

> # Create a spatial weights matrix using k-nearest neighbors (k = 4 as an example)
> knn <- knearneigh(coords, k = 4)

> nb <- knn2nb(knn)

> lw <- nb2listw(nb, style = "W", zero.policy = TRUE)

> # Compute Moran's I
> moran_test <- moran.test(residuals, lw, zero.policy = TRUE)

> sink(output_file, append = TRUE, split = TRUE)

> print("Moran's I Test Results:")
[1] "Moran's I Test Results:"

> print(moran_test)

	Moran I test under randomisation

data:  residuals  
weights: lw    

Moran I statistic standard deviate = -2.5563, p-value = 0.9947
alternative hypothesis: greater
sample estimates:
Moran I statistic       Expectation          Variance 
     -0.175219908      -0.009433962       0.004205943 


> # Stop redirecting output
> sink()

> # --------------------------------------------------
> # End of Script
> # --------------------------------------------------
> 

> # --------------------------------------------------
> # Spatial Statistical Modeling with SSN2
> # ------------------------------------------------ .... [TRUNCATED] 

> # Specify the input and output directories
> input_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/Inputs"

> output_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/SSN ET/ET Full ws_re"

> model_name <- "glm ch_sfm.erosion.norm VIF 3 ws_re"

> obs_points_path <- file.path(input_dir, "Combined Watersheds", "ET Full ssn points.gpkg")

> read_ssn <- FALSE # whether to create a new ssn (FALSE) or read the pre-existing ssn (TRUE)

> # Use file.path to create platform-independent file paths
> streams_path <- file.path(input_dir, "streams_100k.gpkg")

> ssn_path <- file.path(output_dir, "1_ET_Full_logtrans_independent_vars.ssn")

> output_file <- file.path(output_dir, model_name, "Results.txt")

> lsn_out <- file.path(output_dir, "0_lsn")

> # Define whether to save graphs and the directory to save them
> save_graphs <- TRUE  # Set to TRUE to save graphs as PNG

> graph_save_dir <- file.path(output_dir, model_name)  # Directory to save graphs

> # ----------------------------#
> # 1. Load Necessary Libraries
> # ----------------------------#
> 
> # Load required libraries
> library(SSN2)

> library(SSNbler)

> library(sf)

> library(dplyr)

> library(purrr)

> library(ggplot2)

> library(lmtest)

> library(spdep)

> library(classInt)   # Required for knearneigh

> library(broom)      # For tidy() and glance() functions

> library(grid)       # For grid.newpage()

> if (!dir.exists(graph_save_dir)) {
+   dir.create(graph_save_dir, recursive = TRUE)
+ }

> # ----------------------------#
> # 2. Read Spatial Data
> # ----------------------------#
> 
> # Read the streams dataset
> ET_streams <- st_read(s .... [TRUNCATED] 
Reading layer `streams_100k' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\streams_100k.gpkg' using driver `GPKG'
Simple feature collection with 643 features and 2 fields
Geometry type: LINESTRING
Dimension:     XY
Bounding box:  xmin: 404042.6 ymin: 4447904 xmax: 414579.6 ymax: 4466669
Projected CRS: NAD83 / UTM zone 13N

> # Read the observation points dataset
> ET_obs <- st_read(obs_points_path)
Reading layer `ET Full ssn points' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\Combined Watersheds\ET Full ssn points.gpkg' using driver `GPKG'
Simple feature collection with 645 features and 60 fields
Geometry type: POINT
Dimension:     XY
Bounding box:  xmin: 407401.1 ymin: 4449827 xmax: 413032.9 ymax: 4464548
Projected CRS: NAD83 / UTM zone 13N

> # Uncomment the following line if you encounter an error about Multilinestrings
> # ET_streams <- st_cast(ET_streams, "LINESTRING")
> 
> # --------- .... [TRUNCATED] 
[1] "Edge Attributes:"
[1] "rid"            "STRM_VAL"       "flow_accum_max" "Length"         "upDist"         "geometry"      
[1] "Site List Components:"
[1] "obs"
[1] "Updated Edge Attributes:"
[1] "rid"            "STRM_VAL"       "flow_accum_max" "Length"         "upDist"         "flow_accum_PI"  "afv_flow_accum" "geometry"      


SSN object is valid: TRUE

> # Create a distance matrix for spatial relationships
> # Purpose: Define spatial dependencies based on distances between sites
> ssn_create_distmat( .... [TRUNCATED] 

> # ----------------------------#
> # 4. Model Fitting and Output
> # ----------------------------#
> 
> # Redirect output to the specified file and a .... [TRUNCATED] 

> model_name
[1] "glm ch_sfm.erosion.norm VIF 3 ws_re"

> model_formula
ch_sfm.erosion.norm ~ ch_slope.median + ch_flow.accumulation.max + 
    ch_curvature.median + ch_valley_width + ch_central.slope.difference + 
    ch_channel.width.over.valley.width + ch_slope.over.width.central.diff + 
    hs_area + hs_slope.median + hs_eastness.median + hs_curvature.median + 
    hs_ndvi.range + hs_dnbr.median + hs_drainage_density + (1 | 
    ch_watershed)

> ssn_mod <- ssn_glm(
+   formula = model_formula,
+   ssn.object = ET_ssn,
+   family = "Gamma",
+   tailup_type = "exponential",
+   taildown_type = .... [TRUNCATED] 

> # --------------------------------------------------
> # Spatial Statistical Modeling with SSN2
> # ------------------------------------------------ .... [TRUNCATED] 

> # Specify the input and output directories
> input_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/Inputs"

> output_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/SSN ET/ET Full ws_re"

> model_name <- "glm ch_sfm.erosion.norm VIF 3 ws_re"

> obs_points_path <- file.path(input_dir, "Combined Watersheds", "ET Full ssn points.gpkg")

> read_ssn <- TRUE # whether to create a new ssn (FALSE) or read the pre-existing ssn (TRUE)

> # Use file.path to create platform-independent file paths
> streams_path <- file.path(input_dir, "streams_100k.gpkg")

> ssn_path <- file.path(output_dir, "1_ET_Full_logtrans_independent_vars.ssn")

> output_file <- file.path(output_dir, model_name, "Results.txt")

> lsn_out <- file.path(output_dir, "0_lsn")

> # Define whether to save graphs and the directory to save them
> save_graphs <- TRUE  # Set to TRUE to save graphs as PNG

> graph_save_dir <- file.path(output_dir, model_name)  # Directory to save graphs

> # ----------------------------#
> # 1. Load Necessary Libraries
> # ----------------------------#
> 
> # Load required libraries
> library(SSN2)

> library(SSNbler)

> library(sf)

> library(dplyr)

> library(purrr)

> library(ggplot2)

> library(lmtest)

> library(spdep)

> library(classInt)   # Required for knearneigh

> library(broom)      # For tidy() and glance() functions

> library(grid)       # For grid.newpage()

> if (!dir.exists(graph_save_dir)) {
+   dir.create(graph_save_dir, recursive = TRUE)
+ }

> # ----------------------------#
> # 2. Read Spatial Data
> # ----------------------------#
> 
> # Read the streams dataset
> ET_streams <- st_read(s .... [TRUNCATED] 
Reading layer `streams_100k' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\streams_100k.gpkg' using driver `GPKG'
Simple feature collection with 643 features and 2 fields
Geometry type: LINESTRING
Dimension:     XY
Bounding box:  xmin: 404042.6 ymin: 4447904 xmax: 414579.6 ymax: 4466669
Projected CRS: NAD83 / UTM zone 13N

> # Read the observation points dataset
> ET_obs <- st_read(obs_points_path)
Reading layer `ET Full ssn points' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\Combined Watersheds\ET Full ssn points.gpkg' using driver `GPKG'
Simple feature collection with 645 features and 60 fields
Geometry type: POINT
Dimension:     XY
Bounding box:  xmin: 407401.1 ymin: 4449827 xmax: 413032.9 ymax: 4464548
Projected CRS: NAD83 / UTM zone 13N

> # Uncomment the following line if you encounter an error about Multilinestrings
> # ET_streams <- st_cast(ET_streams, "LINESTRING")
> 
> # --------- .... [TRUNCATED] 

> # Create a distance matrix for spatial relationships
> # Purpose: Define spatial dependencies based on distances between sites
> ssn_create_distmat( .... [TRUNCATED] 

> # ----------------------------#
> # 4. Model Fitting and Output
> # ----------------------------#
> 
> # Redirect output to the specified file and a .... [TRUNCATED] 

> model_name
[1] "glm ch_sfm.erosion.norm VIF 3 ws_re"

> model_formula
ch_sfm.erosion.norm ~ ch_slope.median + ch_curvature.median + 
    ch_valley_width + ch_central.slope.difference + ch_channel.width.over.valley.width + 
    ch_slope.over.width.central.diff + hs_area + hs_slope.median + 
    hs_eastness.median + hs_curvature.median + hs_ndvi.range + 
    hs_dnbr.median + hs_drainage_density + (1 | ch_watershed)

> ssn_mod <- ssn_glm(
+   formula = model_formula,
+   ssn.object = ET_ssn,
+   family = "Gamma",
+   tailup_type = "exponential",
+   taildown_type = .... [TRUNCATED] 

> # --------------------------------------------------
> # Spatial Statistical Modeling with SSN2
> # ------------------------------------------------ .... [TRUNCATED] 

> # Specify the input and output directories
> input_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/Inputs"

> output_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/SSN ET/ET Full ws_re"

> model_name <- "glm ch_sfm.erosion.norm VIF 3 ws_re"

> obs_points_path <- file.path(input_dir, "Combined Watersheds", "ET Full ssn points.gpkg")

> read_ssn <- TRUE # whether to create a new ssn (FALSE) or read the pre-existing ssn (TRUE)

> # Use file.path to create platform-independent file paths
> streams_path <- file.path(input_dir, "streams_100k.gpkg")

> ssn_path <- file.path(output_dir, "1_ET_Full_logtrans_independent_vars.ssn")

> output_file <- file.path(output_dir, model_name, "Results.txt")

> lsn_out <- file.path(output_dir, "0_lsn")

> # Define whether to save graphs and the directory to save them
> save_graphs <- TRUE  # Set to TRUE to save graphs as PNG

> graph_save_dir <- file.path(output_dir, model_name)  # Directory to save graphs

> # ----------------------------#
> # 1. Load Necessary Libraries
> # ----------------------------#
> 
> # Load required libraries
> library(SSN2)

> library(SSNbler)

> library(sf)

> library(dplyr)

> library(purrr)

> library(ggplot2)

> library(lmtest)

> library(spdep)

> library(classInt)   # Required for knearneigh

> library(broom)      # For tidy() and glance() functions

> library(grid)       # For grid.newpage()

> if (!dir.exists(graph_save_dir)) {
+   dir.create(graph_save_dir, recursive = TRUE)
+ }

> # ----------------------------#
> # 2. Read Spatial Data
> # ----------------------------#
> 
> # Read the streams dataset
> ET_streams <- st_read(s .... [TRUNCATED] 
Reading layer `streams_100k' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\streams_100k.gpkg' using driver `GPKG'
Simple feature collection with 643 features and 2 fields
Geometry type: LINESTRING
Dimension:     XY
Bounding box:  xmin: 404042.6 ymin: 4447904 xmax: 414579.6 ymax: 4466669
Projected CRS: NAD83 / UTM zone 13N

> # Read the observation points dataset
> ET_obs <- st_read(obs_points_path)
Reading layer `ET Full ssn points' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\Combined Watersheds\ET Full ssn points.gpkg' using driver `GPKG'
Simple feature collection with 645 features and 60 fields
Geometry type: POINT
Dimension:     XY
Bounding box:  xmin: 407401.1 ymin: 4449827 xmax: 413032.9 ymax: 4464548
Projected CRS: NAD83 / UTM zone 13N

> # Uncomment the following line if you encounter an error about Multilinestrings
> # ET_streams <- st_cast(ET_streams, "LINESTRING")
> 
> # --------- .... [TRUNCATED] 

> # Create a distance matrix for spatial relationships
> # Purpose: Define spatial dependencies based on distances between sites
> ssn_create_distmat( .... [TRUNCATED] 

> # ----------------------------#
> # 4. Model Fitting and Output
> # ----------------------------#
> 
> # Redirect output to the specified file and a .... [TRUNCATED] 

> model_name
[1] "glm ch_sfm.erosion.norm VIF 3 ws_re"

> model_formula
ch_sfm.erosion.norm ~ ch_slope.median + ch_curvature.median + 
    ch_valley_width + ch_central.slope.difference + ch_channel.width.over.valley.width + 
    ch_slope.over.width.central.diff + hs_area + hs_slope.median + 
    hs_eastness.median + hs_curvature.median + hs_ndvi.range + 
    hs_dnbr.median + hs_drainage_density

> ssn_mod <- ssn_glm(
+   formula = model_formula,
+   ssn.object = ET_ssn,
+   family = "Gamma",
+   tailup_type = "exponential",
+   taildown_type = .... [TRUNCATED] 

> # --------------------------------------------------
> # Spatial Statistical Modeling with SSN2
> # ------------------------------------------------ .... [TRUNCATED] 

> # Specify the input and output directories
> input_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/Inputs"

> output_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/SSN ET/ET Full ws_re"

> model_name <- "glm ch_sfm.erosion.norm VIF 3 ws_re"

> obs_points_path <- file.path(input_dir, "Combined Watersheds", "ET Full ssn points.gpkg")

> read_ssn <- TRUE # whether to create a new ssn (FALSE) or read the pre-existing ssn (TRUE)

> # Use file.path to create platform-independent file paths
> streams_path <- file.path(input_dir, "streams_100k.gpkg")

> ssn_path <- file.path(output_dir, "1_ET_Full_logtrans_independent_vars.ssn")

> output_file <- file.path(output_dir, model_name, "Results.txt")

> lsn_out <- file.path(output_dir, "0_lsn")

> # Define whether to save graphs and the directory to save them
> save_graphs <- TRUE  # Set to TRUE to save graphs as PNG

> graph_save_dir <- file.path(output_dir, model_name)  # Directory to save graphs

> # ----------------------------#
> # 1. Load Necessary Libraries
> # ----------------------------#
> 
> # Load required libraries
> library(SSN2)

> library(SSNbler)

> library(sf)

> library(dplyr)

> library(purrr)

> library(ggplot2)

> library(lmtest)

> library(spdep)

> library(classInt)   # Required for knearneigh

> library(broom)      # For tidy() and glance() functions

> library(grid)       # For grid.newpage()

> if (!dir.exists(graph_save_dir)) {
+   dir.create(graph_save_dir, recursive = TRUE)
+ }

> # ----------------------------#
> # 2. Read Spatial Data
> # ----------------------------#
> 
> # Read the streams dataset
> ET_streams <- st_read(s .... [TRUNCATED] 
Reading layer `streams_100k' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\streams_100k.gpkg' using driver `GPKG'
Simple feature collection with 643 features and 2 fields
Geometry type: LINESTRING
Dimension:     XY
Bounding box:  xmin: 404042.6 ymin: 4447904 xmax: 414579.6 ymax: 4466669
Projected CRS: NAD83 / UTM zone 13N

> # Read the observation points dataset
> ET_obs <- st_read(obs_points_path)
Reading layer `ET Full ssn points' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\Combined Watersheds\ET Full ssn points.gpkg' using driver `GPKG'
Simple feature collection with 645 features and 60 fields
Geometry type: POINT
Dimension:     XY
Bounding box:  xmin: 407401.1 ymin: 4449827 xmax: 413032.9 ymax: 4464548
Projected CRS: NAD83 / UTM zone 13N

> # Uncomment the following line if you encounter an error about Multilinestrings
> # ET_streams <- st_cast(ET_streams, "LINESTRING")
> 
> # --------- .... [TRUNCATED] 

> # Create a distance matrix for spatial relationships
> # Purpose: Define spatial dependencies based on distances between sites
> ssn_create_distmat( .... [TRUNCATED] 

> # ----------------------------#
> # 4. Model Fitting and Output
> # ----------------------------#
> 
> # Redirect output to the specified file and a .... [TRUNCATED] 

> model_name
[1] "glm ch_sfm.erosion.norm VIF 3 ws_re"

> model_formula
ch_sfm.erosion.norm ~ ch_slope.median + ch_flow.accumulation.max + 
    ch_valley_width + ch_central.slope.difference + hs_ndvi.range + 
    (1 | ch_watershed)

> ssn_mod <- ssn_glm(
+   formula = model_formula,
+   ssn.object = ET_ssn,
+   family = "Gamma",
+   tailup_type = "exponential",
+   taildown_type = .... [TRUNCATED] 

> # --------------------------------------------------
> # Spatial Statistical Modeling with SSN2
> # ------------------------------------------------ .... [TRUNCATED] 

> # Specify the input and output directories
> input_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/Inputs"

> output_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/SSN ET/ET Full ws_re"

> model_name <- "glm ch_sfm.erosion.norm VIF 3 ws_re"

> obs_points_path <- file.path(input_dir, "Combined Watersheds", "ET Full ssn points.gpkg")

> read_ssn <- TRUE # whether to create a new ssn (FALSE) or read the pre-existing ssn (TRUE)

> # Use file.path to create platform-independent file paths
> streams_path <- file.path(input_dir, "streams_100k.gpkg")

> ssn_path <- file.path(output_dir, "1_ET_Full_logtrans_independent_vars.ssn")

> output_file <- file.path(output_dir, model_name, "Results.txt")

> lsn_out <- file.path(output_dir, "0_lsn")

> # Define whether to save graphs and the directory to save them
> save_graphs <- TRUE  # Set to TRUE to save graphs as PNG

> graph_save_dir <- file.path(output_dir, model_name)  # Directory to save graphs

> # ----------------------------#
> # 1. Load Necessary Libraries
> # ----------------------------#
> 
> # Load required libraries
> library(SSN2)

> library(SSNbler)

> library(sf)

> library(dplyr)

> library(purrr)

> library(ggplot2)

> library(lmtest)

> library(spdep)

> library(classInt)   # Required for knearneigh

> library(broom)      # For tidy() and glance() functions

> library(grid)       # For grid.newpage()

> if (!dir.exists(graph_save_dir)) {
+   dir.create(graph_save_dir, recursive = TRUE)
+ }

> # ----------------------------#
> # 2. Read Spatial Data
> # ----------------------------#
> 
> # Read the streams dataset
> ET_streams <- st_read(s .... [TRUNCATED] 
Reading layer `streams_100k' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\streams_100k.gpkg' using driver `GPKG'
Simple feature collection with 643 features and 2 fields
Geometry type: LINESTRING
Dimension:     XY
Bounding box:  xmin: 404042.6 ymin: 4447904 xmax: 414579.6 ymax: 4466669
Projected CRS: NAD83 / UTM zone 13N

> # Read the observation points dataset
> ET_obs <- st_read(obs_points_path)
Reading layer `ET Full ssn points' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\Combined Watersheds\ET Full ssn points.gpkg' using driver `GPKG'
Simple feature collection with 645 features and 60 fields
Geometry type: POINT
Dimension:     XY
Bounding box:  xmin: 407401.1 ymin: 4449827 xmax: 413032.9 ymax: 4464548
Projected CRS: NAD83 / UTM zone 13N

> # Uncomment the following line if you encounter an error about Multilinestrings
> # ET_streams <- st_cast(ET_streams, "LINESTRING")
> 
> # --------- .... [TRUNCATED] 

> # Create a distance matrix for spatial relationships
> # Purpose: Define spatial dependencies based on distances between sites
> ssn_create_distmat( .... [TRUNCATED] 

> # ----------------------------#
> # 4. Model Fitting and Output
> # ----------------------------#
> 
> # Redirect output to the specified file and a .... [TRUNCATED] 

> # --------------------------------------------------
> # Spatial Statistical Modeling with SSN2
> # ------------------------------------------------ .... [TRUNCATED] 

> # Specify the input and output directories
> input_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/Inputs"

> output_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/SSN ET/ET Full ws_re"

> model_name <- "glm ch_sfm.erosion.norm VIF 3 ws_re"

> obs_points_path <- file.path(input_dir, "Combined Watersheds", "ET Full ssn points.gpkg")

> read_ssn <- TRUE # whether to create a new ssn (FALSE) or read the pre-existing ssn (TRUE)

> # Use file.path to create platform-independent file paths
> streams_path <- file.path(input_dir, "streams_100k.gpkg")

> ssn_path <- file.path(output_dir, "1_ET_Full_logtrans_independent_vars.ssn")

> output_file <- file.path(output_dir, model_name, "Results.txt")

> lsn_out <- file.path(output_dir, "0_lsn")

> # Define whether to save graphs and the directory to save them
> save_graphs <- TRUE  # Set to TRUE to save graphs as PNG

> graph_save_dir <- file.path(output_dir, model_name)  # Directory to save graphs

> # ----------------------------#
> # 1. Load Necessary Libraries
> # ----------------------------#
> 
> # Load required libraries
> library(SSN2)

> library(SSNbler)

> library(sf)

> library(dplyr)

> library(purrr)

> library(ggplot2)

> library(lmtest)

> library(spdep)

> library(classInt)   # Required for knearneigh

> library(broom)      # For tidy() and glance() functions

> library(grid)       # For grid.newpage()

> if (!dir.exists(graph_save_dir)) {
+   dir.create(graph_save_dir, recursive = TRUE)
+ }

> # ----------------------------#
> # 2. Read Spatial Data
> # ----------------------------#
> 
> # Read the streams dataset
> ET_streams <- st_read(s .... [TRUNCATED] 
Reading layer `streams_100k' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\streams_100k.gpkg' using driver `GPKG'
Simple feature collection with 643 features and 2 fields
Geometry type: LINESTRING
Dimension:     XY
Bounding box:  xmin: 404042.6 ymin: 4447904 xmax: 414579.6 ymax: 4466669
Projected CRS: NAD83 / UTM zone 13N

> # Read the observation points dataset
> ET_obs <- st_read(obs_points_path)
Reading layer `ET Full ssn points' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\Combined Watersheds\ET Full ssn points.gpkg' using driver `GPKG'
Simple feature collection with 645 features and 60 fields
Geometry type: POINT
Dimension:     XY
Bounding box:  xmin: 407401.1 ymin: 4449827 xmax: 413032.9 ymax: 4464548
Projected CRS: NAD83 / UTM zone 13N

> # Uncomment the following line if you encounter an error about Multilinestrings
> # ET_streams <- st_cast(ET_streams, "LINESTRING")
> 
> # --------- .... [TRUNCATED] 

> # Create a distance matrix for spatial relationships
> # Purpose: Define spatial dependencies based on distances between sites
> ssn_create_distmat( .... [TRUNCATED] 

> # ----------------------------#
> # 4. Model Fitting and Output
> # ----------------------------#
> 
> # Redirect output to the specified file and a .... [TRUNCATED] 

> # --------------------------------------------------
> # Spatial Statistical Modeling with SSN2
> # ------------------------------------------------ .... [TRUNCATED] 

> # Define the formula for the ssn_lm function
> # You can modify this formula as needed for different analyses
> model_formula <- as.formula(
+   "ch ..." ... [TRUNCATED] 

> # Specify the input and output directories
> input_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/Inputs"

> output_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/SSN ET/ET Full ws_re"

> model_name <- "glm ch_sfm.erosion.norm VIF 3 ws_re"

> obs_points_path <- file.path(input_dir, "Combined Watersheds", "ET Full ssn points.gpkg")

> read_ssn <- TRUE # whether to create a new ssn (FALSE) or read the pre-existing ssn (TRUE)

> # Use file.path to create platform-independent file paths
> streams_path <- file.path(input_dir, "streams_100k.gpkg")

> ssn_path <- file.path(output_dir, "1_ET_Full_logtrans_independent_vars.ssn")

> output_file <- file.path(output_dir, model_name, "Results.txt")

> lsn_out <- file.path(output_dir, "0_lsn")

> # Define whether to save graphs and the directory to save them
> save_graphs <- TRUE  # Set to TRUE to save graphs as PNG

> graph_save_dir <- file.path(output_dir, model_name)  # Directory to save graphs

> # ----------------------------#
> # 1. Load Necessary Libraries
> # ----------------------------#
> 
> # Load required libraries
> library(SSN2)

> library(SSNbler)

> library(sf)

> library(dplyr)

> library(purrr)

> library(ggplot2)

> library(lmtest)

> library(spdep)

> library(classInt)   # Required for knearneigh

> library(broom)      # For tidy() and glance() functions

> library(grid)       # For grid.newpage()

> if (!dir.exists(graph_save_dir)) {
+   dir.create(graph_save_dir, recursive = TRUE)
+ }

> # ----------------------------#
> # 2. Read Spatial Data
> # ----------------------------#
> 
> # Read the streams dataset
> ET_streams <- st_read(s .... [TRUNCATED] 
Reading layer `streams_100k' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\streams_100k.gpkg' using driver `GPKG'
Simple feature collection with 643 features and 2 fields
Geometry type: LINESTRING
Dimension:     XY
Bounding box:  xmin: 404042.6 ymin: 4447904 xmax: 414579.6 ymax: 4466669
Projected CRS: NAD83 / UTM zone 13N

> # Read the observation points dataset
> ET_obs <- st_read(obs_points_path)
Reading layer `ET Full ssn points' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\Combined Watersheds\ET Full ssn points.gpkg' using driver `GPKG'
Simple feature collection with 645 features and 60 fields
Geometry type: POINT
Dimension:     XY
Bounding box:  xmin: 407401.1 ymin: 4449827 xmax: 413032.9 ymax: 4464548
Projected CRS: NAD83 / UTM zone 13N

> # Uncomment the following line if you encounter an error about Multilinestrings
> # ET_streams <- st_cast(ET_streams, "LINESTRING")
> 
> # --------- .... [TRUNCATED] 

> # Create a distance matrix for spatial relationships
> # Purpose: Define spatial dependencies based on distances between sites
> ssn_create_distmat( .... [TRUNCATED] 

> # ----------------------------#
> # 4. Model Fitting and Output
> # ----------------------------#
> 
> # Redirect output to the specified file and a .... [TRUNCATED] 

> model_name
[1] "glm ch_sfm.erosion.norm VIF 3 ws_re"

> model_formula
ch_sfm.erosion.norm ~ ch_slope.median + (1 | ch_watershed)

> ssn_mod <- ssn_glm(
+   formula = model_formula,
+   ssn.object = ET_ssn,
+   family = "Gamma",
+   tailup_type = "exponential",
+   taildown_type = .... [TRUNCATED] 

> # --------------------------------------------------
> # Spatial Statistical Modeling with SSN2
> # ------------------------------------------------ .... [TRUNCATED] 

> # Define the formula for the ssn_lm function
> # You can modify this formula as needed for different analyses
> model_formula <- as.formula(
+   "ch ..." ... [TRUNCATED] 

> # Specify the input and output directories
> input_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/Inputs"

> output_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/SSN ET/ET Full ws_re"

> model_name <- "glm ch_sfm.erosion.norm VIF 3 ws_re"

> obs_points_path <- file.path(input_dir, "Combined Watersheds", "ET Full ssn points.gpkg")

> read_ssn <- TRUE # whether to create a new ssn (FALSE) or read the pre-existing ssn (TRUE)

> # Use file.path to create platform-independent file paths
> streams_path <- file.path(input_dir, "streams_100k.gpkg")

> ssn_path <- file.path(output_dir, "1_ET_Full_logtrans_independent_vars.ssn")

> output_file <- file.path(output_dir, model_name, "Results.txt")

> lsn_out <- file.path(output_dir, "0_lsn")

> # Define whether to save graphs and the directory to save them
> save_graphs <- TRUE  # Set to TRUE to save graphs as PNG

> graph_save_dir <- file.path(output_dir, model_name)  # Directory to save graphs

> # ----------------------------#
> # 1. Load Necessary Libraries
> # ----------------------------#
> 
> # Load required libraries
> library(SSN2)

> library(SSNbler)

> library(sf)

> library(dplyr)

> library(purrr)

> library(ggplot2)

> library(lmtest)

> library(spdep)

> library(classInt)   # Required for knearneigh

> library(broom)      # For tidy() and glance() functions

> library(grid)       # For grid.newpage()

> if (!dir.exists(graph_save_dir)) {
+   dir.create(graph_save_dir, recursive = TRUE)
+ }

> # ----------------------------#
> # 2. Read Spatial Data
> # ----------------------------#
> 
> # Read the streams dataset
> ET_streams <- st_read(s .... [TRUNCATED] 
Reading layer `streams_100k' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\streams_100k.gpkg' using driver `GPKG'
Simple feature collection with 643 features and 2 fields
Geometry type: LINESTRING
Dimension:     XY
Bounding box:  xmin: 404042.6 ymin: 4447904 xmax: 414579.6 ymax: 4466669
Projected CRS: NAD83 / UTM zone 13N

> # Read the observation points dataset
> ET_obs <- st_read(obs_points_path)
Reading layer `ET Full ssn points' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\Combined Watersheds\ET Full ssn points.gpkg' using driver `GPKG'
Simple feature collection with 645 features and 60 fields
Geometry type: POINT
Dimension:     XY
Bounding box:  xmin: 407401.1 ymin: 4449827 xmax: 413032.9 ymax: 4464548
Projected CRS: NAD83 / UTM zone 13N

> # Uncomment the following line if you encounter an error about Multilinestrings
> # ET_streams <- st_cast(ET_streams, "LINESTRING")
> 
> # --------- .... [TRUNCATED] 

> # Create a distance matrix for spatial relationships
> # Purpose: Define spatial dependencies based on distances between sites
> ssn_create_distmat( .... [TRUNCATED] 

> # ----------------------------#
> # 4. Model Fitting and Output
> # ----------------------------#
> 
> # Redirect output to the specified file and a .... [TRUNCATED] 

> model_name
[1] "glm ch_sfm.erosion.norm VIF 3 ws_re"

> model_formula
ch_sfm.erosion.norm ~ (1 | ch_watershed)

> ssn_mod <- ssn_glm(
+   formula = model_formula,
+   ssn.object = ET_ssn,
+   family = "Gamma",
+   tailup_type = "exponential",
+   taildown_type = .... [TRUNCATED] 
NULL
< table of extent 0 >

> # --------------------------------------------------
> # Spatial Statistical Modeling with SSN2
> # ------------------------------------------------ .... [TRUNCATED] 

> # Specify the input and output directories
> input_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/Inputs"

> output_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/SSN ET/ET Full ws_re"

> model_name <- "glm ch_sfm.erosion.norm VIF 3 ws_re"

> obs_points_path <- file.path(input_dir, "Combined Watersheds", "ET Full ssn points.gpkg")

> read_ssn <- TRUE # whether to create a new ssn (FALSE) or read the pre-existing ssn (TRUE)

> # Use file.path to create platform-independent file paths
> streams_path <- file.path(input_dir, "streams_100k.gpkg")

> ssn_path <- file.path(output_dir, "1_ET_Full_logtrans_independent_vars.ssn")

> output_file <- file.path(output_dir, model_name, "Results.txt")

> lsn_out <- file.path(output_dir, "0_lsn")

> # Define whether to save graphs and the directory to save them
> save_graphs <- TRUE  # Set to TRUE to save graphs as PNG

> graph_save_dir <- file.path(output_dir, model_name)  # Directory to save graphs

> # ----------------------------#
> # 1. Load Necessary Libraries
> # ----------------------------#
> 
> # Load required libraries
> library(SSN2)

> library(SSNbler)

> library(sf)

> library(dplyr)

> library(purrr)

> library(ggplot2)

> library(lmtest)

> library(spdep)

> library(classInt)   # Required for knearneigh

> library(broom)      # For tidy() and glance() functions

> library(grid)       # For grid.newpage()

> if (!dir.exists(graph_save_dir)) {
+   dir.create(graph_save_dir, recursive = TRUE)
+ }

> # ----------------------------#
> # 2. Read Spatial Data
> # ----------------------------#
> 
> # Read the streams dataset
> ET_streams <- st_read(s .... [TRUNCATED] 
Reading layer `streams_100k' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\streams_100k.gpkg' using driver `GPKG'
Simple feature collection with 643 features and 2 fields
Geometry type: LINESTRING
Dimension:     XY
Bounding box:  xmin: 404042.6 ymin: 4447904 xmax: 414579.6 ymax: 4466669
Projected CRS: NAD83 / UTM zone 13N

> # Read the observation points dataset
> ET_obs <- st_read(obs_points_path)
Reading layer `ET Full ssn points' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\Combined Watersheds\ET Full ssn points.gpkg' using driver `GPKG'
Simple feature collection with 645 features and 60 fields
Geometry type: POINT
Dimension:     XY
Bounding box:  xmin: 407401.1 ymin: 4449827 xmax: 413032.9 ymax: 4464548
Projected CRS: NAD83 / UTM zone 13N

> # Uncomment the following line if you encounter an error about Multilinestrings
> # ET_streams <- st_cast(ET_streams, "LINESTRING")
> 
> # --------- .... [TRUNCATED] 

> # Create a distance matrix for spatial relationships
> # Purpose: Define spatial dependencies based on distances between sites
> ssn_create_distmat( .... [TRUNCATED] 

> # ----------------------------#
> # 4. Model Fitting and Output
> # ----------------------------#
> 
> # Redirect output to the specified file and a .... [TRUNCATED] 

> # --------------------------------------------------
> # Spatial Statistical Modeling with SSN2
> # ------------------------------------------------ .... [TRUNCATED] 

> # Define the formula for the ssn_lm function
> # You can modify this formula as needed for different analyses
> model_formula <- as.formula(
+   "ch ..." ... [TRUNCATED] 

> # Specify the input and output directories
> input_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/Inputs"

> output_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/SSN ET/ET Full ws_re"

> model_name <- "glm ch_sfm.erosion.norm VIF 3 ws_re"

> obs_points_path <- file.path(input_dir, "Combined Watersheds", "ET Full ssn points.gpkg")

> read_ssn <- TRUE # whether to create a new ssn (FALSE) or read the pre-existing ssn (TRUE)

> # Use file.path to create platform-independent file paths
> streams_path <- file.path(input_dir, "streams_100k.gpkg")

> ssn_path <- file.path(output_dir, "1_ET_Full_logtrans_independent_vars.ssn")

> output_file <- file.path(output_dir, model_name, "Results.txt")

> lsn_out <- file.path(output_dir, "0_lsn")

> # Define whether to save graphs and the directory to save them
> save_graphs <- TRUE  # Set to TRUE to save graphs as PNG

> graph_save_dir <- file.path(output_dir, model_name)  # Directory to save graphs

> # ----------------------------#
> # 1. Load Necessary Libraries
> # ----------------------------#
> 
> # Load required libraries
> library(SSN2)

> library(SSNbler)

> library(sf)

> library(dplyr)

> library(purrr)

> library(ggplot2)

> library(lmtest)

> library(spdep)

> library(classInt)   # Required for knearneigh

> library(broom)      # For tidy() and glance() functions

> library(grid)       # For grid.newpage()

> if (!dir.exists(graph_save_dir)) {
+   dir.create(graph_save_dir, recursive = TRUE)
+ }

> # ----------------------------#
> # 2. Read Spatial Data
> # ----------------------------#
> 
> # Read the streams dataset
> ET_streams <- st_read(s .... [TRUNCATED] 
Reading layer `streams_100k' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\streams_100k.gpkg' using driver `GPKG'
Simple feature collection with 643 features and 2 fields
Geometry type: LINESTRING
Dimension:     XY
Bounding box:  xmin: 404042.6 ymin: 4447904 xmax: 414579.6 ymax: 4466669
Projected CRS: NAD83 / UTM zone 13N

> # Read the observation points dataset
> ET_obs <- st_read(obs_points_path)
Reading layer `ET Full ssn points' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\Combined Watersheds\ET Full ssn points.gpkg' using driver `GPKG'
Simple feature collection with 645 features and 60 fields
Geometry type: POINT
Dimension:     XY
Bounding box:  xmin: 407401.1 ymin: 4449827 xmax: 413032.9 ymax: 4464548
Projected CRS: NAD83 / UTM zone 13N

> # Uncomment the following line if you encounter an error about Multilinestrings
> # ET_streams <- st_cast(ET_streams, "LINESTRING")
> 
> # --------- .... [TRUNCATED] 

> # Create a distance matrix for spatial relationships
> # Purpose: Define spatial dependencies based on distances between sites
> ssn_create_distmat( .... [TRUNCATED] 

> # ----------------------------#
> # 4. Model Fitting and Output
> # ----------------------------#
> 
> # Redirect output to the specified file and a .... [TRUNCATED] 

> model_name
[1] "glm ch_sfm.erosion.norm VIF 3 ws_re"

> model_formula
ch_sfm.erosion.norm ~ ch_slope.median + ch_curvature.median + 
    ch_valley_width + ch_central.slope.difference + ch_channel.width.over.valley.width + 
    ch_slope.over.width.central.diff + hs_area + hs_slope.median + 
    hs_eastness.median + hs_curvature.median + hs_ndvi.range + 
    hs_dnbr.median + hs_drainage_density + ch_watershed

> ssn_mod <- ssn_glm(
+   formula = model_formula,
+   ssn.object = ET_ssn,
+   family = "Gamma",
+   tailup_type = "exponential",
+   taildown_type = .... [TRUNCATED] 

> # Print the summary of the model to the file and console
> print(summary(ssn_mod))

Call:
ssn_glm(formula = model_formula, ssn.object = ET_ssn, family = "Gamma", 
    tailup_type = "exponential", taildown_type = "none", euclid_type = "gaussian", 
    additive = "afv_flow_accum")

Deviance Residuals:
     Min       1Q   Median       3Q      Max 
-1.97575 -0.29152 -0.01429  0.22337  1.14741 

Coefficients (fixed):
                                    Estimate Std. Error z value Pr(>|z|)   
(Intercept)                         0.081420   1.391434   0.059  0.95334   
ch_slope.median                     0.151747   0.070068   2.166  0.03033 * 
ch_curvature.median                 0.009959   0.066831   0.149  0.88154   
ch_valley_width                    -0.054263   0.075628  -0.717  0.47307   
ch_central.slope.difference        -0.051828   0.030209  -1.716  0.08622 . 
ch_channel.width.over.valley.width  0.082748   0.075513   1.096  0.27316   
ch_slope.over.width.central.diff    0.056676   0.021293   2.662  0.00777 **
hs_area                            -0.021892   0.041007  -0.534  0.59344   
hs_slope.median                     0.078084   0.089237   0.875  0.38156   
hs_eastness.median                 -0.002436   0.043498  -0.056  0.95535   
hs_curvature.median                 0.008276   0.029486   0.281  0.77896   
hs_ndvi.range                      -0.060944   0.063676  -0.957  0.33852   
hs_dnbr.median                     -0.030411   0.074332  -0.409  0.68244   
hs_drainage_density                 2.149034  13.965222   0.154  0.87770   
ch_watershed                       -0.612585   0.222942  -2.748  0.00600 **
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Pseudo R-squared: 0.01247

Coefficients (covariance):
              Effect     Parameter   Estimate
  tailup exponential  de (parsill)  2.514e+00
  tailup exponential         range  2.041e+02
     euclid gaussian  de (parsill)  1.219e+00
     euclid gaussian         range  3.394e+04
              nugget        nugget  3.303e-04
          dispersion    dispersion  2.975e+00


> # Print variance components of the model
> varcomp(ssn_mod)
# A tibble: 5 × 2
  varcomp            proportion
  <chr>                   <dbl>
1 Covariates (PR-sq)  0.0125   
2 tailup_de           0.665    
3 taildown_de         0        
4 euclid_de           0.322    
5 nugget              0.0000874

> # Tidy the model output with confidence intervals and print
> print(tidy(ssn_mod, conf.int = TRUE))  
# A tibble: 15 × 7
   term                               estimate std.error statistic p.value conf.low conf.high
   <chr>                                 <dbl>     <dbl>     <dbl>   <dbl>    <dbl>     <dbl>
 1 (Intercept)                         0.0814     1.39      0.0585 0.953    -2.65     2.81   
 2 ch_central.slope.difference        -0.0518     0.0302   -1.72   0.0862   -0.111    0.00738
 3 ch_channel.width.over.valley.width  0.0827     0.0755    1.10   0.273    -0.0653   0.231  
 4 ch_curvature.median                 0.00996    0.0668    0.149  0.882    -0.121    0.141  
 5 ch_slope.median                     0.152      0.0701    2.17   0.0303    0.0144   0.289  
 6 ch_slope.over.width.central.diff    0.0567     0.0213    2.66   0.00777   0.0149   0.0984 
 7 ch_valley_width                    -0.0543     0.0756   -0.717  0.473    -0.202    0.0940 
 8 ch_watershed                       -0.613      0.223    -2.75   0.00600  -1.05    -0.176  
 9 hs_area                            -0.0219     0.0410   -0.534  0.593    -0.102    0.0585 
10 hs_curvature.median                 0.00828    0.0295    0.281  0.779    -0.0495   0.0661 
11 hs_dnbr.median                     -0.0304     0.0743   -0.409  0.682    -0.176    0.115  
12 hs_drainage_density                 2.15      14.0       0.154  0.878   -25.2     29.5    
13 hs_eastness.median                 -0.00244    0.0435   -0.0560 0.955    -0.0877   0.0828 
14 hs_ndvi.range                      -0.0609     0.0637   -0.957  0.339    -0.186    0.0639 
15 hs_slope.median                     0.0781     0.0892    0.875  0.382    -0.0968   0.253  

> # Provide a glance summary of the model and print
> print(glance(ssn_mod))
# A tibble: 1 × 9
      n     p  npar value   AIC  AICc logLik deviance pseudo.r.squared
  <int> <dbl> <int> <dbl> <dbl> <dbl>  <dbl>    <dbl>            <dbl>
1   645    15     6 1017. 1029. 1029.  -508.     131.           0.0125

> # Perform Leave-One-Out Cross Validation and print
> print("Leave One Out Cross Validation")
[1] "Leave One Out Cross Validation"

> loocv_results <- loocv(ssn_mod)

> print(loocv_results)
# A tibble: 1 × 4
     bias  MSPE RMSPE   RAV
    <dbl> <dbl> <dbl> <dbl>
1 -0.0674 0.154 0.392 0.493

> # Stop redirecting output
> sink()

> # ----------------------------#
> # 5. Model Evaluation
> # ----------------------------#
> 
> # Extract residuals and fitted values from the model
 .... [TRUNCATED] 

> fitted_values <- fitted(ssn_mod)   

> # ----------------------------#
> # 6. Plotting and Saving Graphs
> # ----------------------------#
> 
> 
> # Create the graph save directory if sav .... [TRUNCATED] 

> # ----------------------------#
> # 7. Residuals vs Fitted Values Plot
> # ----------------------------#
> 
> # Purpose:
> #   - Linearity: Ensure t .... [TRUNCATED] 

> # Create the Residuals vs Fitted Values plot
> resid_fitted_plot <- ggplot(data.frame(Fitted = fitted_values, Residuals = residuals), aes(x = Fitted .... [TRUNCATED] 

> # Display the plot
> print(resid_fitted_plot)

> # Save the plot if saving is enabled
> if (save_graphs) {
+   ggsave(filename = file.path(graph_save_dir, "Residuals_vs_Fitted.png"), plot = resid_f .... [TRUNCATED] 
[1] "Saved Residuals vs Fitted Values plot."

> # ----------------------------#
> # 8. Q-Q Plot for Residuals
> # ----------------------------#
> 
> # Purpose:
> #   - Normality: Verify that resid .... [TRUNCATED] 

> # Enhanced Q-Q Plot using ggplot2
> qq_plot <- ggplot(data.frame(Residuals = residuals), aes(sample = Residuals)) +
+   stat_qq(color = "blue") +
+  .... [TRUNCATED] 

> # Display the ggplot2 Q-Q plot
> print(qq_plot)

> # Save the ggplot2 Q-Q plot if saving is enabled
> if (save_graphs) {
+   ggsave(filename = file.path(graph_save_dir, "QQ_Plot_Residuals_GGPlot2.png ..." ... [TRUNCATED] 
[1] "Saved ggplot2 Q-Q Plot of Residuals."

> # ----------------------------#
> # 9. Histogram of Residuals
> # ----------------------------#
> 
> # Purpose:
> #   - Normality
> #
> # What to Lo .... [TRUNCATED] 

> # Enhanced Histogram using ggplot2
> hist_plot <- ggplot(data.frame(Residuals = residuals), aes(x = Residuals)) +
+   geom_histogram(aes(y = ..densi .... [TRUNCATED] 

> # Display the ggplot2 histogram
> print(hist_plot)

> # Save the ggplot2 histogram if saving is enabled
> if (save_graphs) {
+   ggsave(filename = file.path(graph_save_dir, "Histogram_Residuals_GGPlot2. ..." ... [TRUNCATED] 
[1] "Saved ggplot2 Histogram of Residuals with Normal Curve."

> # Redirect output to the specified file and also print to console
> sink(output_file, append = TRUE, split = TRUE)

> print("")
[1] ""

> # ----------------------------#
> # 10. Statistical Tests
> # ----------------------------#
> 
> 
> # --------- Shapiro-Wilk Test for Normality ---- .... [TRUNCATED] 
[1] "-------- Shapiro-Wilk Test for Normality ---------"

> print("  - Normality: To check if the residuals are normally distributed.")
[1] "  - Normality: To check if the residuals are normally distributed."

> print("  - p-value > 0.05: Fail to reject null hypothesis (residuals are normally distributed).")
[1] "  - p-value > 0.05: Fail to reject null hypothesis (residuals are normally distributed)."

> print("  - p-value <= 0.05: Reject null hypothesis (residuals are not normally distributed).\n")
[1] "  - p-value <= 0.05: Reject null hypothesis (residuals are not normally distributed).\n"

> shapiro_test <- shapiro.test(residuals)

> print("Shapiro-Wilk Test Results:")
[1] "Shapiro-Wilk Test Results:"

> print(shapiro_test)

	Shapiro-Wilk normality test

data:  residuals
W = 0.97505, p-value = 5e-09


> # --------- Breusch-Pagan Test for Homoscedasticity ---------
> print("-------- Breusch-Pagan Test for Homoscedasticity ---------")
[1] "-------- Breusch-Pagan Test for Homoscedasticity ---------"

> print("  - Homoscedasticity: To check if residuals have constant variance across all levels of fitted values.")
[1] "  - Homoscedasticity: To check if residuals have constant variance across all levels of fitted values."

> print("  - p-value > 0.05: Fail to reject null hypothesis (homoscedasticity holds).")
[1] "  - p-value > 0.05: Fail to reject null hypothesis (homoscedasticity holds)."

> print("  - p-value <= 0.05: Reject null hypothesis (heteroscedasticity present).\n")
[1] "  - p-value <= 0.05: Reject null hypothesis (heteroscedasticity present).\n"

> # Extract the model frame from the ssn_lm model
> data_ssn <- model.frame(ssn_mod)

> # Perform Breusch-Pagan Test
> bp_test <- bptest(ssn_mod)

> print("Breusch-Pagan Test Results:")
[1] "Breusch-Pagan Test Results:"

> print(bp_test)

	studentized Breusch-Pagan test

data:  ssn_mod
BP = 53.915, df = 14, p-value = 1.328e-06


> # --------- Moran's I Test for Spatial Autocorrelation ---------
> print("\n-------- Moran's I Test for Spatial Autocorrelation ---------")
[1] "\n-------- Moran's I Test for Spatial Autocorrelation ---------"

> print("  - Spatial Autocorrelation: To determine if there is spatial autocorrelation in the residuals.")
[1] "  - Spatial Autocorrelation: To determine if there is spatial autocorrelation in the residuals."

> print("  - p-value > 0.05: Fail to reject null hypothesis (lack of spatial autocorrelation in residuals holds).")
[1] "  - p-value > 0.05: Fail to reject null hypothesis (lack of spatial autocorrelation in residuals holds)."

> print("  - p-value <= 0.05: Reject null hypothesis (spatial autocorrelation present).\n")
[1] "  - p-value <= 0.05: Reject null hypothesis (spatial autocorrelation present).\n"

> sink()

> # Extract spatial coordinates from the SSN object
> # Ensure that your SSN object has geometry information
> coords <- st_coordinates(ssn_get_data(s .... [TRUNCATED] 

> # Create a spatial weights matrix using k-nearest neighbors (k = 4 as an example)
> knn <- knearneigh(coords, k = 4)

> nb <- knn2nb(knn)

> lw <- nb2listw(nb, style = "W", zero.policy = TRUE)

> # Compute Moran's I
> moran_test <- moran.test(residuals, lw, zero.policy = TRUE)

> sink(output_file, append = TRUE, split = TRUE)

> print("Moran's I Test Results:")
[1] "Moran's I Test Results:"

> print(moran_test)

	Moran I test under randomisation

data:  residuals  
weights: lw    

Moran I statistic standard deviate = -6.569, p-value = 1
alternative hypothesis: greater
sample estimates:
Moran I statistic       Expectation          Variance 
    -0.1795996935     -0.0015527950      0.0007346234 


> # Stop redirecting output
> sink()

> # --------------------------------------------------
> # End of Script
> # --------------------------------------------------
> 
> 
> library(car)

> vif_result <- vif(lm(ch_sfm.erosion.norm ~ 
+                        ch_slope.median +
+                        ch_curvature.median +
+              .... [TRUNCATED] 

> # --------------------------------------------------
> # Spatial Statistical Modeling with SSN2
> # ------------------------------------------------ .... [TRUNCATED] 

> # Define the formula for the ssn_lm function
> # You can modify this formula as needed for different analyses
> model_formula <- as.formula(
+   "ch ..." ... [TRUNCATED] 

> # Specify the input and output directories
> input_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/Inputs"

> output_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/SSN ET/ET Full ws_re"

> model_name <- "glm ch_sfm.erosion.norm VIF 3 100 ct thresh ws_re"

> obs_points_path <- file.path(input_dir, "Combined Watersheds", "ET Full ssn points.gpkg")

> read_ssn <- FALSE # whether to create a new ssn (FALSE) or read the pre-existing ssn (TRUE)

> # Use file.path to create platform-independent file paths
> streams_path <- file.path(input_dir, "streams_100k.gpkg")

> ssn_path <- file.path(output_dir, "1_ET_Full_logtrans_independent_vars.ssn")

> output_file <- file.path(output_dir, model_name, "Results.txt")

> lsn_out <- file.path(output_dir, "0_lsn")

> # Define whether to save graphs and the directory to save them
> save_graphs <- TRUE  # Set to TRUE to save graphs as PNG

> graph_save_dir <- file.path(output_dir, model_name)  # Directory to save graphs

> # ----------------------------#
> # 1. Load Necessary Libraries
> # ----------------------------#
> 
> # Load required libraries
> library(SSN2)

> library(SSNbler)

> library(sf)

> library(dplyr)

> library(purrr)

> library(ggplot2)

> library(lmtest)

> library(spdep)

> library(classInt)   # Required for knearneigh

> library(broom)      # For tidy() and glance() functions

> library(grid)       # For grid.newpage()

> if (!dir.exists(graph_save_dir)) {
+   dir.create(graph_save_dir, recursive = TRUE)
+ }

> # ----------------------------#
> # 2. Read Spatial Data
> # ----------------------------#
> 
> # Read the streams dataset
> ET_streams <- st_read(s .... [TRUNCATED] 
Reading layer `streams_100k' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\streams_100k.gpkg' using driver `GPKG'
Simple feature collection with 643 features and 2 fields
Geometry type: LINESTRING
Dimension:     XY
Bounding box:  xmin: 404042.6 ymin: 4447904 xmax: 414579.6 ymax: 4466669
Projected CRS: NAD83 / UTM zone 13N

> # Read the observation points dataset
> ET_obs <- st_read(obs_points_path)
Reading layer `ET Full ssn points' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\Combined Watersheds\ET Full ssn points.gpkg' using driver `GPKG'
Simple feature collection with 645 features and 60 fields
Geometry type: POINT
Dimension:     XY
Bounding box:  xmin: 407401.1 ymin: 4449827 xmax: 413032.9 ymax: 4464548
Projected CRS: NAD83 / UTM zone 13N

> # Uncomment the following line if you encounter an error about Multilinestrings
> # ET_streams <- st_cast(ET_streams, "LINESTRING")
> 
> # --------- .... [TRUNCATED] 
[1] "Edge Attributes:"
[1] "rid"            "STRM_VAL"       "flow_accum_max" "Length"         "upDist"         "geometry"      
[1] "Site List Components:"
[1] "obs"
[1] "Updated Edge Attributes:"
[1] "rid"            "STRM_VAL"       "flow_accum_max" "Length"         "upDist"         "flow_accum_PI"  "afv_flow_accum" "geometry"      


SSN object is valid: TRUE

> # Create a distance matrix for spatial relationships
> # Purpose: Define spatial dependencies based on distances between sites
> ssn_create_distmat( .... [TRUNCATED] 

> # ----------------------------#
> # 4. Model Fitting and Output
> # ----------------------------#
> 
> # Redirect output to the specified file and a .... [TRUNCATED] 

> model_name
[1] "glm ch_sfm.erosion.norm VIF 3 100 ct thresh ws_re"

> model_formula
ch_sfm.erosion.norm ~ ch_elevation.mean + ch_slope.median + ch_flow.accumulation.max + 
    ch_curvature.median + ch_valley_width + ch_change.in.slope.over.width + 
    ch_channel.width.over.valley.width + ch_slope.over.width.central.diff + 
    ch_stream.power.central.diff + hs_hillslope.length + hs_slope.median + 
    hs_northness.median + hs_eastness.median + hs_curvature.median + 
    hs_bare.earth.mean + hs_ndvi.range + hs_dnbr.median + hs_drainage_density + 
    flow.accumulation.max + (1 | ch_watershed)

> ssn_mod <- ssn_glm(
+   formula = model_formula,
+   ssn.object = ET_ssn,
+   family = "Gamma",
+   tailup_type = "exponential",
+   taildown_type = .... [TRUNCATED] 

> # --------------------------------------------------
> # Spatial Statistical Modeling with SSN2
> # ------------------------------------------------ .... [TRUNCATED] 

> # Define the formula for the ssn_lm function
> # You can modify this formula as needed for different analyses
> model_formula <- as.formula(
+   "ch ..." ... [TRUNCATED] 

> # Specify the input and output directories
> input_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/Inputs"

> output_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/SSN ET/ET Full ws_re"

> model_name <- "glm ch_sfm.erosion.norm VIF 3 100 ct thresh ws_re"

> obs_points_path <- file.path(input_dir, "Combined Watersheds", "ET Full ssn points.gpkg")

> read_ssn <- TRUE # whether to create a new ssn (FALSE) or read the pre-existing ssn (TRUE)

> # Use file.path to create platform-independent file paths
> streams_path <- file.path(input_dir, "streams_100k.gpkg")

> ssn_path <- file.path(output_dir, "1_ET_Full_logtrans_independent_vars.ssn")

> output_file <- file.path(output_dir, model_name, "Results.txt")

> lsn_out <- file.path(output_dir, "0_lsn")

> # Define whether to save graphs and the directory to save them
> save_graphs <- TRUE  # Set to TRUE to save graphs as PNG

> graph_save_dir <- file.path(output_dir, model_name)  # Directory to save graphs

> # ----------------------------#
> # 1. Load Necessary Libraries
> # ----------------------------#
> 
> # Load required libraries
> library(SSN2)

> library(SSNbler)

> library(sf)

> library(dplyr)

> library(purrr)

> library(ggplot2)

> library(lmtest)

> library(spdep)

> library(classInt)   # Required for knearneigh

> library(broom)      # For tidy() and glance() functions

> library(grid)       # For grid.newpage()

> if (!dir.exists(graph_save_dir)) {
+   dir.create(graph_save_dir, recursive = TRUE)
+ }

> # ----------------------------#
> # 2. Read Spatial Data
> # ----------------------------#
> 
> # Read the streams dataset
> ET_streams <- st_read(s .... [TRUNCATED] 
Reading layer `streams_100k' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\streams_100k.gpkg' using driver `GPKG'
Simple feature collection with 643 features and 2 fields
Geometry type: LINESTRING
Dimension:     XY
Bounding box:  xmin: 404042.6 ymin: 4447904 xmax: 414579.6 ymax: 4466669
Projected CRS: NAD83 / UTM zone 13N

> # Read the observation points dataset
> ET_obs <- st_read(obs_points_path)
Reading layer `ET Full ssn points' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\Combined Watersheds\ET Full ssn points.gpkg' using driver `GPKG'
Simple feature collection with 645 features and 60 fields
Geometry type: POINT
Dimension:     XY
Bounding box:  xmin: 407401.1 ymin: 4449827 xmax: 413032.9 ymax: 4464548
Projected CRS: NAD83 / UTM zone 13N

> # Uncomment the following line if you encounter an error about Multilinestrings
> # ET_streams <- st_cast(ET_streams, "LINESTRING")
> 
> # --------- .... [TRUNCATED] 

> # Create a distance matrix for spatial relationships
> # Purpose: Define spatial dependencies based on distances between sites
> ssn_create_distmat( .... [TRUNCATED] 

> # ----------------------------#
> # 4. Model Fitting and Output
> # ----------------------------#
> 
> # Redirect output to the specified file and a .... [TRUNCATED] 

> model_name
[1] "glm ch_sfm.erosion.norm VIF 3 100 ct thresh ws_re"

> model_formula
ch_sfm.erosion.norm ~ ch_elevation.mean + ch_slope.median + ch_flow.accumulation.max + 
    ch_curvature.median + ch_valley_width + ch_change.in.slope.over.width + 
    ch_channel.width.over.valley.width + ch_slope.over.width.central.diff + 
    ch_stream.power.central.diff + hs_hillslope.length + hs_slope.median + 
    hs_northness.median + hs_eastness.median + hs_curvature.median + 
    hs_bare.earth.mean + hs_ndvi.range + hs_dnbr.median + hs_drainage_density + 
    flow.accumulation.max

> ssn_mod <- ssn_glm(
+   formula = model_formula,
+   ssn.object = ET_ssn,
+   family = "Gamma",
+   tailup_type = "exponential",
+   taildown_type = .... [TRUNCATED] 

> # Print the summary of the model to the file and console
> print(summary(ssn_mod))

Call:
ssn_glm(formula = model_formula, ssn.object = ET_ssn, family = "Gamma", 
    tailup_type = "exponential", taildown_type = "none", euclid_type = "gaussian", 
    additive = "afv_flow_accum", random = ~as.factor(ch_watershed))

Deviance Residuals:
    Min      1Q  Median      3Q     Max 
-1.9005 -0.2386 -0.0035  0.1847  1.0111 

Coefficients (fixed):
                                    Estimate Std. Error z value Pr(>|z|)  
(Intercept)                        -2.291130   1.000278  -2.290   0.0220 *
ch_elevation.mean                  -0.797335   0.943026  -0.846   0.3978  
ch_slope.median                     0.154667   0.071046   2.177   0.0295 *
ch_flow.accumulation.max            0.837915   0.754298   1.111   0.2666  
ch_curvature.median                 0.009497   0.066685   0.142   0.8868  
ch_valley_width                    -0.053729   0.075168  -0.715   0.4747  
ch_change.in.slope.over.width      -0.027491   0.017760  -1.548   0.1217  
ch_channel.width.over.valley.width  0.078486   0.075758   1.036   0.3002  
ch_slope.over.width.central.diff    0.045914   0.026656   1.722   0.0850 .
ch_stream.power.central.diff        0.004492   0.017657   0.254   0.7992  
hs_hillslope.length                -0.059319   0.046656  -1.271   0.2036  
hs_slope.median                     0.099233   0.089975   1.103   0.2701  
hs_northness.median                -0.097960   0.066669  -1.469   0.1417  
hs_eastness.median                 -0.015859   0.045612  -0.348   0.7281  
hs_curvature.median                 0.010601   0.030254   0.350   0.7260  
hs_bare.earth.mean                  0.074061   0.067308   1.100   0.2712  
hs_ndvi.range                      -0.056827   0.072440  -0.784   0.4328  
hs_dnbr.median                      0.006861   0.077904   0.088   0.9298  
hs_drainage_density                 3.230809  13.763039   0.235   0.8144  
flow.accumulation.max              -0.123641   0.093758  -1.319   0.1873  
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Pseudo R-squared: 0.02136

Coefficients (covariance):
              Effect                    Parameter   Estimate
  tailup exponential                 de (parsill)  1.540e+00
  tailup exponential                        range  9.958e+01
     euclid gaussian                 de (parsill)  2.340e+00
     euclid gaussian                        range  2.002e+03
              nugget                       nugget  8.270e-03
          dispersion                   dispersion  3.393e+00
              random  1 | as.factor(ch_watershed)  1.793e+00


> # Print variance components of the model
> varcomp(ssn_mod)
# A tibble: 6 × 2
  varcomp                     proportion
  <chr>                            <dbl>
1 Covariates (PR-sq)             0.0214 
2 tailup_de                      0.265  
3 taildown_de                    0      
4 euclid_de                      0.403  
5 nugget                         0.00142
6 1 | as.factor(ch_watershed)    0.309  

> # Tidy the model output with confidence intervals and print
> print(tidy(ssn_mod, conf.int = TRUE))  
# A tibble: 20 × 7
   term                               estimate std.error statistic p.value  conf.low conf.high
   <chr>                                 <dbl>     <dbl>     <dbl>   <dbl>     <dbl>     <dbl>
 1 (Intercept)                        -2.29       1.00     -2.29    0.0220  -4.25     -0.331  
 2 ch_change.in.slope.over.width      -0.0275     0.0178   -1.55    0.122   -0.0623    0.00732
 3 ch_channel.width.over.valley.width  0.0785     0.0758    1.04    0.300   -0.0700    0.227  
 4 ch_curvature.median                 0.00950    0.0667    0.142   0.887   -0.121     0.140  
 5 ch_elevation.mean                  -0.797      0.943    -0.846   0.398   -2.65      1.05   
 6 ch_flow.accumulation.max            0.838      0.754     1.11    0.267   -0.640     2.32   
 7 ch_slope.median                     0.155      0.0710    2.18    0.0295   0.0154    0.294  
 8 ch_slope.over.width.central.diff    0.0459     0.0267    1.72    0.0850  -0.00633   0.0982 
 9 ch_stream.power.central.diff        0.00449    0.0177    0.254   0.799   -0.0301    0.0391 
10 ch_valley_width                    -0.0537     0.0752   -0.715   0.475   -0.201     0.0936 
11 flow.accumulation.max              -0.124      0.0938   -1.32    0.187   -0.307     0.0601 
12 hs_bare.earth.mean                  0.0741     0.0673    1.10    0.271   -0.0579    0.206  
13 hs_curvature.median                 0.0106     0.0303    0.350   0.726   -0.0487    0.0699 
14 hs_dnbr.median                      0.00686    0.0779    0.0881  0.930   -0.146     0.160  
15 hs_drainage_density                 3.23      13.8       0.235   0.814  -23.7      30.2    
16 hs_eastness.median                 -0.0159     0.0456   -0.348   0.728   -0.105     0.0735 
17 hs_hillslope.length                -0.0593     0.0467   -1.27    0.204   -0.151     0.0321 
18 hs_ndvi.range                      -0.0568     0.0724   -0.784   0.433   -0.199     0.0852 
19 hs_northness.median                -0.0980     0.0667   -1.47    0.142   -0.229     0.0327 
20 hs_slope.median                     0.0992     0.0900    1.10    0.270   -0.0771    0.276  

> # Provide a glance summary of the model and print
> print(glance(ssn_mod))
# A tibble: 1 × 9
      n     p  npar value   AIC  AICc logLik deviance pseudo.r.squared
  <int> <dbl> <int> <dbl> <dbl> <dbl>  <dbl>    <dbl>            <dbl>
1   645    20     7 1013. 1027. 1028.  -507.     102.           0.0214

> # Perform Leave-One-Out Cross Validation and print
> print("Leave One Out Cross Validation")
[1] "Leave One Out Cross Validation"

> loocv_results <- loocv(ssn_mod)

> print(loocv_results)
# A tibble: 1 × 4
     bias  MSPE RMSPE   RAV
    <dbl> <dbl> <dbl> <dbl>
1 -0.0702 0.162 0.402 0.546

> # Stop redirecting output
> sink()

> # ----------------------------#
> # 5. Model Evaluation
> # ----------------------------#
> 
> # Extract residuals and fitted values from the model
 .... [TRUNCATED] 

> fitted_values <- fitted(ssn_mod)   

> # ----------------------------#
> # 6. Plotting and Saving Graphs
> # ----------------------------#
> 
> 
> # Create the graph save directory if sav .... [TRUNCATED] 

> # ----------------------------#
> # 7. Residuals vs Fitted Values Plot
> # ----------------------------#
> 
> # Purpose:
> #   - Linearity: Ensure t .... [TRUNCATED] 

> # Create the Residuals vs Fitted Values plot
> resid_fitted_plot <- ggplot(data.frame(Fitted = fitted_values, Residuals = residuals), aes(x = Fitted .... [TRUNCATED] 

> # Display the plot
> print(resid_fitted_plot)

> # Save the plot if saving is enabled
> if (save_graphs) {
+   ggsave(filename = file.path(graph_save_dir, "Residuals_vs_Fitted.png"), plot = resid_f .... [TRUNCATED] 
[1] "Saved Residuals vs Fitted Values plot."

> # ----------------------------#
> # 8. Q-Q Plot for Residuals
> # ----------------------------#
> 
> # Purpose:
> #   - Normality: Verify that resid .... [TRUNCATED] 

> # Enhanced Q-Q Plot using ggplot2
> qq_plot <- ggplot(data.frame(Residuals = residuals), aes(sample = Residuals)) +
+   stat_qq(color = "blue") +
+  .... [TRUNCATED] 

> # Display the ggplot2 Q-Q plot
> print(qq_plot)

> # Save the ggplot2 Q-Q plot if saving is enabled
> if (save_graphs) {
+   ggsave(filename = file.path(graph_save_dir, "QQ_Plot_Residuals_GGPlot2.png ..." ... [TRUNCATED] 
[1] "Saved ggplot2 Q-Q Plot of Residuals."

> # ----------------------------#
> # 9. Histogram of Residuals
> # ----------------------------#
> 
> # Purpose:
> #   - Normality
> #
> # What to Lo .... [TRUNCATED] 

> # Enhanced Histogram using ggplot2
> hist_plot <- ggplot(data.frame(Residuals = residuals), aes(x = Residuals)) +
+   geom_histogram(aes(y = ..densi .... [TRUNCATED] 

> # Display the ggplot2 histogram
> print(hist_plot)

> # Save the ggplot2 histogram if saving is enabled
> if (save_graphs) {
+   ggsave(filename = file.path(graph_save_dir, "Histogram_Residuals_GGPlot2. ..." ... [TRUNCATED] 
[1] "Saved ggplot2 Histogram of Residuals with Normal Curve."

> # Redirect output to the specified file and also print to console
> sink(output_file, append = TRUE, split = TRUE)

> print("")
[1] ""

> # ----------------------------#
> # 10. Statistical Tests
> # ----------------------------#
> 
> 
> # --------- Shapiro-Wilk Test for Normality ---- .... [TRUNCATED] 
[1] "-------- Shapiro-Wilk Test for Normality ---------"

> print("  - Normality: To check if the residuals are normally distributed.")
[1] "  - Normality: To check if the residuals are normally distributed."

> print("  - p-value > 0.05: Fail to reject null hypothesis (residuals are normally distributed).")
[1] "  - p-value > 0.05: Fail to reject null hypothesis (residuals are normally distributed)."

> print("  - p-value <= 0.05: Reject null hypothesis (residuals are not normally distributed).\n")
[1] "  - p-value <= 0.05: Reject null hypothesis (residuals are not normally distributed).\n"

> shapiro_test <- shapiro.test(residuals)

> print("Shapiro-Wilk Test Results:")
[1] "Shapiro-Wilk Test Results:"

> print(shapiro_test)

	Shapiro-Wilk normality test

data:  residuals
W = 0.96785, p-value = 1.094e-10


> # --------- Breusch-Pagan Test for Homoscedasticity ---------
> print("-------- Breusch-Pagan Test for Homoscedasticity ---------")
[1] "-------- Breusch-Pagan Test for Homoscedasticity ---------"

> print("  - Homoscedasticity: To check if residuals have constant variance across all levels of fitted values.")
[1] "  - Homoscedasticity: To check if residuals have constant variance across all levels of fitted values."

> print("  - p-value > 0.05: Fail to reject null hypothesis (homoscedasticity holds).")
[1] "  - p-value > 0.05: Fail to reject null hypothesis (homoscedasticity holds)."

> print("  - p-value <= 0.05: Reject null hypothesis (heteroscedasticity present).\n")
[1] "  - p-value <= 0.05: Reject null hypothesis (heteroscedasticity present).\n"

> # Extract the model frame from the ssn_lm model
> data_ssn <- model.frame(ssn_mod)

> # Perform Breusch-Pagan Test
> bp_test <- bptest(ssn_mod)

> print("Breusch-Pagan Test Results:")
[1] "Breusch-Pagan Test Results:"

> print(bp_test)

	studentized Breusch-Pagan test

data:  ssn_mod
BP = 75.814, df = 19, p-value = 9.683e-09


> # --------- Moran's I Test for Spatial Autocorrelation ---------
> print("\n-------- Moran's I Test for Spatial Autocorrelation ---------")
[1] "\n-------- Moran's I Test for Spatial Autocorrelation ---------"

> print("  - Spatial Autocorrelation: To determine if there is spatial autocorrelation in the residuals.")
[1] "  - Spatial Autocorrelation: To determine if there is spatial autocorrelation in the residuals."

> print("  - p-value > 0.05: Fail to reject null hypothesis (lack of spatial autocorrelation in residuals holds).")
[1] "  - p-value > 0.05: Fail to reject null hypothesis (lack of spatial autocorrelation in residuals holds)."

> print("  - p-value <= 0.05: Reject null hypothesis (spatial autocorrelation present).\n")
[1] "  - p-value <= 0.05: Reject null hypothesis (spatial autocorrelation present).\n"

> sink()

> # Extract spatial coordinates from the SSN object
> # Ensure that your SSN object has geometry information
> coords <- st_coordinates(ssn_get_data(s .... [TRUNCATED] 

> # Create a spatial weights matrix using k-nearest neighbors (k = 4 as an example)
> knn <- knearneigh(coords, k = 4)

> nb <- knn2nb(knn)

> lw <- nb2listw(nb, style = "W", zero.policy = TRUE)

> # Compute Moran's I
> moran_test <- moran.test(residuals, lw, zero.policy = TRUE)

> sink(output_file, append = TRUE, split = TRUE)

> print("Moran's I Test Results:")
[1] "Moran's I Test Results:"

> print(moran_test)

	Moran I test under randomisation

data:  residuals  
weights: lw    

Moran I statistic standard deviate = -7.2671, p-value = 1
alternative hypothesis: greater
sample estimates:
Moran I statistic       Expectation          Variance 
     -0.198457287      -0.001552795       0.000734155 


> # Stop redirecting output
> sink()

> # --------------------------------------------------
> # End of Script
> # --------------------------------------------------
> 
> 
> library(car)

> vif_result <- vif(lm(ch_sfm.erosion.norm ~ 
+                        ch_slope.median +
+                        ch_curvature.median +
+              .... [TRUNCATED] 

> # --------------------------------------------------
> # Spatial Statistical Modeling with SSN2
> # ------------------------------------------------ .... [TRUNCATED] 

> # Define the formula for the ssn_lm function
> # You can modify this formula as needed for different analyses
> model_formula <- as.formula(
+   "ch ..." ... [TRUNCATED] 

> # Specify the input and output directories
> input_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/Inputs"

> output_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/SSN ET/ET Full ws_re"

> model_name <- "glm ch_sfm.erosion.norm VIF 3 100 ct thresh ws_re"

> obs_points_path <- file.path(input_dir, "Combined Watersheds", "ET Full ssn points.gpkg")

> read_ssn <- TRUE # whether to create a new ssn (FALSE) or read the pre-existing ssn (TRUE)

> # Use file.path to create platform-independent file paths
> streams_path <- file.path(input_dir, "streams_100k.gpkg")

> ssn_path <- file.path(output_dir, "1_ET_Full_logtrans_independent_vars.ssn")

> output_file <- file.path(output_dir, model_name, "Results.txt")

> lsn_out <- file.path(output_dir, "0_lsn")

> # Define whether to save graphs and the directory to save them
> save_graphs <- TRUE  # Set to TRUE to save graphs as PNG

> graph_save_dir <- file.path(output_dir, model_name)  # Directory to save graphs

> # ----------------------------#
> # 1. Load Necessary Libraries
> # ----------------------------#
> 
> # Load required libraries
> library(SSN2)

> library(SSNbler)

> library(sf)

> library(dplyr)

> library(purrr)

> library(ggplot2)

> library(lmtest)

> library(spdep)

> library(classInt)   # Required for knearneigh

> library(broom)      # For tidy() and glance() functions

> library(grid)       # For grid.newpage()

> if (!dir.exists(graph_save_dir)) {
+   dir.create(graph_save_dir, recursive = TRUE)
+ }

> # ----------------------------#
> # 2. Read Spatial Data
> # ----------------------------#
> 
> # Read the streams dataset
> ET_streams <- st_read(s .... [TRUNCATED] 
Reading layer `streams_100k' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\streams_100k.gpkg' using driver `GPKG'
Simple feature collection with 643 features and 2 fields
Geometry type: LINESTRING
Dimension:     XY
Bounding box:  xmin: 404042.6 ymin: 4447904 xmax: 414579.6 ymax: 4466669
Projected CRS: NAD83 / UTM zone 13N

> # Read the observation points dataset
> ET_obs <- st_read(obs_points_path)
Reading layer `ET Full ssn points' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\Combined Watersheds\ET Full ssn points.gpkg' using driver `GPKG'
Simple feature collection with 645 features and 60 fields
Geometry type: POINT
Dimension:     XY
Bounding box:  xmin: 407401.1 ymin: 4449827 xmax: 413032.9 ymax: 4464548
Projected CRS: NAD83 / UTM zone 13N

> # Uncomment the following line if you encounter an error about Multilinestrings
> # ET_streams <- st_cast(ET_streams, "LINESTRING")
> 
> # --------- .... [TRUNCATED] 

> # Create a distance matrix for spatial relationships
> # Purpose: Define spatial dependencies based on distances between sites
> ssn_create_distmat( .... [TRUNCATED] 

> # ----------------------------#
> # 4. Model Fitting and Output
> # ----------------------------#
> 
> # Redirect output to the specified file and a .... [TRUNCATED] 

> model_name
[1] "glm ch_sfm.erosion.norm VIF 3 100 ct thresh ws_re"

> model_formula
ch_sfm.erosion.norm ~ ws_flow.accum.max + ws_slope.mean + ws_bare.earth.mean + 
    ws_drainage_density + ws_RV.Sand + ch_slope.median + ch_curvature.median + 
    ch_valley_width + ch_change.in.slope.over.width + ch_channel.width.over.valley.width + 
    ch_slope.over.width.central.diff + ch_stream.power.central.diff + 
    hs_hillslope.length + hs_slope.median + hs_northness.median + 
    hs_eastness.median + hs_curvature.median + hs_bare.earth.mean + 
    hs_ndvi.range + hs_dnbr.median + hs_drainage_density + flow.accumulation.max

> ssn_mod <- ssn_glm(
+   formula = model_formula,
+   ssn.object = ET_ssn,
+   family = "Gamma",
+   tailup_type = "exponential",
+   taildown_type = .... [TRUNCATED] 

> # Print the summary of the model to the file and console
> print(summary(ssn_mod))

Call:
ssn_glm(formula = model_formula, ssn.object = ET_ssn, family = "Gamma", 
    tailup_type = "exponential", taildown_type = "none", euclid_type = "gaussian", 
    additive = "afv_flow_accum", random = ~as.factor(ch_watershed))

Deviance Residuals:
      Min        1Q    Median        3Q       Max 
-1.899096 -0.244484  0.005467  0.190863  1.013314 

Coefficients (fixed):
                                     Estimate Std. Error z value Pr(>|z|)    
(Intercept)                        -1.9686360  0.8984917  -2.191   0.0284 *  
ws_flow.accum.max                  -0.4236557  0.2325182  -1.822   0.0685 .  
ws_slope.mean                       1.1187663  0.2768520   4.041 5.32e-05 ***
ws_bare.earth.mean                 -0.2392941  0.1509909  -1.585   0.1130    
ws_drainage_density                 0.0383747  0.0194197   1.976   0.0481 *  
ws_RV.Sand                         -0.4079859  0.4034231  -1.011   0.3119    
ch_slope.median                     0.1481487  0.0706427   2.097   0.0360 *  
ch_curvature.median                 0.0008038  0.0666369   0.012   0.9904    
ch_valley_width                    -0.0488746  0.0746302  -0.655   0.5125    
ch_change.in.slope.over.width      -0.0271306  0.0178150  -1.523   0.1278    
ch_channel.width.over.valley.width  0.0736065  0.0756281   0.973   0.3304    
ch_slope.over.width.central.diff    0.0457687  0.0266721   1.716   0.0862 .  
ch_stream.power.central.diff        0.0053541  0.0176862   0.303   0.7621    
hs_hillslope.length                -0.0551840  0.0466631  -1.183   0.2370    
hs_slope.median                     0.0838467  0.0900029   0.932   0.3515    
hs_northness.median                -0.1063774  0.0667991  -1.592   0.1113    
hs_eastness.median                 -0.0179435  0.0455613  -0.394   0.6937    
hs_curvature.median                 0.0109864  0.0303161   0.362   0.7171    
hs_bare.earth.mean                  0.0871841  0.0677662   1.287   0.1983    
hs_ndvi.range                      -0.0358530  0.0722844  -0.496   0.6199    
hs_dnbr.median                      0.0227799  0.0780155   0.292   0.7703    
hs_drainage_density                 0.4510822 13.7896864   0.033   0.9739    
flow.accumulation.max              -0.1191132  0.0745331  -1.598   0.1100    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Pseudo R-squared: 0.03917

Coefficients (covariance):
              Effect                    Parameter   Estimate
  tailup exponential                 de (parsill)  1.417e+00
  tailup exponential                        range  8.651e+01
     euclid gaussian                 de (parsill)  1.813e+00
     euclid gaussian                        range  5.405e+03
              nugget                       nugget  1.308e-03
          dispersion                   dispersion  3.411e+00
              random  1 | as.factor(ch_watershed)  3.019e-01


> # Print variance components of the model
> varcomp(ssn_mod)
# A tibble: 6 × 2
  varcomp                     proportion
  <chr>                            <dbl>
1 Covariates (PR-sq)            0.0392  
2 tailup_de                     0.385   
3 taildown_de                   0       
4 euclid_de                     0.493   
5 nugget                        0.000356
6 1 | as.factor(ch_watershed)   0.0821  

> # Tidy the model output with confidence intervals and print
> print(tidy(ssn_mod, conf.int = TRUE))  
# A tibble: 23 × 7
   term                                estimate std.error statistic p.value conf.low conf.high
   <chr>                                  <dbl>     <dbl>     <dbl>   <dbl>    <dbl>     <dbl>
 1 (Intercept)                        -1.97        0.898    -2.19    0.0284 -3.73     -0.208  
 2 ch_change.in.slope.over.width      -0.0271      0.0178   -1.52    0.128  -0.0620    0.00779
 3 ch_channel.width.over.valley.width  0.0736      0.0756    0.973   0.330  -0.0746    0.222  
 4 ch_curvature.median                 0.000804    0.0666    0.0121  0.990  -0.130     0.131  
 5 ch_slope.median                     0.148       0.0706    2.10    0.0360  0.00969   0.287  
 6 ch_slope.over.width.central.diff    0.0458      0.0267    1.72    0.0862 -0.00651   0.0980 
 7 ch_stream.power.central.diff        0.00535     0.0177    0.303   0.762  -0.0293    0.0400 
 8 ch_valley_width                    -0.0489      0.0746   -0.655   0.513  -0.195     0.0974 
 9 flow.accumulation.max              -0.119       0.0745   -1.60    0.110  -0.265     0.0270 
10 hs_bare.earth.mean                  0.0872      0.0678    1.29    0.198  -0.0456    0.220  
# ℹ 13 more rows
# ℹ Use `print(n = ...)` to see more rows

> # Provide a glance summary of the model and print
> print(glance(ssn_mod))
# A tibble: 1 × 9
      n     p  npar value   AIC  AICc logLik deviance pseudo.r.squared
  <int> <dbl> <int> <dbl> <dbl> <dbl>  <dbl>    <dbl>            <dbl>
1   645    23     7 1013. 1027. 1027.  -506.     99.1           0.0392

> # Perform Leave-One-Out Cross Validation and print
> print("Leave One Out Cross Validation")
[1] "Leave One Out Cross Validation"

> loocv_results <- loocv(ssn_mod)

> print(loocv_results)
# A tibble: 1 × 4
     bias  MSPE RMSPE   RAV
    <dbl> <dbl> <dbl> <dbl>
1 -0.0753 0.163 0.403 0.768

> # Stop redirecting output
> sink()

> # ----------------------------#
> # 5. Model Evaluation
> # ----------------------------#
> 
> # Extract residuals and fitted values from the model
 .... [TRUNCATED] 

> fitted_values <- fitted(ssn_mod)   

> # ----------------------------#
> # 6. Plotting and Saving Graphs
> # ----------------------------#
> 
> 
> # Create the graph save directory if sav .... [TRUNCATED] 

> # ----------------------------#
> # 7. Residuals vs Fitted Values Plot
> # ----------------------------#
> 
> # Purpose:
> #   - Linearity: Ensure t .... [TRUNCATED] 

> # Create the Residuals vs Fitted Values plot
> resid_fitted_plot <- ggplot(data.frame(Fitted = fitted_values, Residuals = residuals), aes(x = Fitted .... [TRUNCATED] 

> # Display the plot
> print(resid_fitted_plot)

> # Save the plot if saving is enabled
> if (save_graphs) {
+   ggsave(filename = file.path(graph_save_dir, "Residuals_vs_Fitted.png"), plot = resid_f .... [TRUNCATED] 
[1] "Saved Residuals vs Fitted Values plot."

> # ----------------------------#
> # 8. Q-Q Plot for Residuals
> # ----------------------------#
> 
> # Purpose:
> #   - Normality: Verify that resid .... [TRUNCATED] 

> # Enhanced Q-Q Plot using ggplot2
> qq_plot <- ggplot(data.frame(Residuals = residuals), aes(sample = Residuals)) +
+   stat_qq(color = "blue") +
+  .... [TRUNCATED] 

> # Display the ggplot2 Q-Q plot
> print(qq_plot)

> # Save the ggplot2 Q-Q plot if saving is enabled
> if (save_graphs) {
+   ggsave(filename = file.path(graph_save_dir, "QQ_Plot_Residuals_GGPlot2.png ..." ... [TRUNCATED] 
[1] "Saved ggplot2 Q-Q Plot of Residuals."

> # ----------------------------#
> # 9. Histogram of Residuals
> # ----------------------------#
> 
> # Purpose:
> #   - Normality
> #
> # What to Lo .... [TRUNCATED] 

> # Enhanced Histogram using ggplot2
> hist_plot <- ggplot(data.frame(Residuals = residuals), aes(x = Residuals)) +
+   geom_histogram(aes(y = ..densi .... [TRUNCATED] 

> # Display the ggplot2 histogram
> print(hist_plot)

> # Save the ggplot2 histogram if saving is enabled
> if (save_graphs) {
+   ggsave(filename = file.path(graph_save_dir, "Histogram_Residuals_GGPlot2. ..." ... [TRUNCATED] 
[1] "Saved ggplot2 Histogram of Residuals with Normal Curve."

> # Redirect output to the specified file and also print to console
> sink(output_file, append = TRUE, split = TRUE)

> print("")
[1] ""

> # ----------------------------#
> # 10. Statistical Tests
> # ----------------------------#
> 
> 
> # --------- Shapiro-Wilk Test for Normality ---- .... [TRUNCATED] 
[1] "-------- Shapiro-Wilk Test for Normality ---------"

> print("  - Normality: To check if the residuals are normally distributed.")
[1] "  - Normality: To check if the residuals are normally distributed."

> print("  - p-value > 0.05: Fail to reject null hypothesis (residuals are normally distributed).")
[1] "  - p-value > 0.05: Fail to reject null hypothesis (residuals are normally distributed)."

> print("  - p-value <= 0.05: Reject null hypothesis (residuals are not normally distributed).\n")
[1] "  - p-value <= 0.05: Reject null hypothesis (residuals are not normally distributed).\n"

> shapiro_test <- shapiro.test(residuals)

> print("Shapiro-Wilk Test Results:")
[1] "Shapiro-Wilk Test Results:"

> print(shapiro_test)

	Shapiro-Wilk normality test

data:  residuals
W = 0.96702, p-value = 7.299e-11


> # --------- Breusch-Pagan Test for Homoscedasticity ---------
> print("-------- Breusch-Pagan Test for Homoscedasticity ---------")
[1] "-------- Breusch-Pagan Test for Homoscedasticity ---------"

> print("  - Homoscedasticity: To check if residuals have constant variance across all levels of fitted values.")
[1] "  - Homoscedasticity: To check if residuals have constant variance across all levels of fitted values."

> print("  - p-value > 0.05: Fail to reject null hypothesis (homoscedasticity holds).")
[1] "  - p-value > 0.05: Fail to reject null hypothesis (homoscedasticity holds)."

> print("  - p-value <= 0.05: Reject null hypothesis (heteroscedasticity present).\n")
[1] "  - p-value <= 0.05: Reject null hypothesis (heteroscedasticity present).\n"

> # Extract the model frame from the ssn_lm model
> data_ssn <- model.frame(ssn_mod)

> # Perform Breusch-Pagan Test
> bp_test <- bptest(ssn_mod)

> print("Breusch-Pagan Test Results:")
[1] "Breusch-Pagan Test Results:"

> print(bp_test)

	studentized Breusch-Pagan test

data:  ssn_mod
BP = 59.412, df = 22, p-value = 2.729e-05


> # --------- Moran's I Test for Spatial Autocorrelation ---------
> print("\n-------- Moran's I Test for Spatial Autocorrelation ---------")
[1] "\n-------- Moran's I Test for Spatial Autocorrelation ---------"

> print("  - Spatial Autocorrelation: To determine if there is spatial autocorrelation in the residuals.")
[1] "  - Spatial Autocorrelation: To determine if there is spatial autocorrelation in the residuals."

> print("  - p-value > 0.05: Fail to reject null hypothesis (lack of spatial autocorrelation in residuals holds).")
[1] "  - p-value > 0.05: Fail to reject null hypothesis (lack of spatial autocorrelation in residuals holds)."

> print("  - p-value <= 0.05: Reject null hypothesis (spatial autocorrelation present).\n")
[1] "  - p-value <= 0.05: Reject null hypothesis (spatial autocorrelation present).\n"

> sink()

> # Extract spatial coordinates from the SSN object
> # Ensure that your SSN object has geometry information
> coords <- st_coordinates(ssn_get_data(s .... [TRUNCATED] 

> # Create a spatial weights matrix using k-nearest neighbors (k = 4 as an example)
> knn <- knearneigh(coords, k = 4)

> nb <- knn2nb(knn)

> lw <- nb2listw(nb, style = "W", zero.policy = TRUE)

> # Compute Moran's I
> moran_test <- moran.test(residuals, lw, zero.policy = TRUE)

> sink(output_file, append = TRUE, split = TRUE)

> print("Moran's I Test Results:")
[1] "Moran's I Test Results:"

> print(moran_test)

	Moran I test under randomisation

data:  residuals  
weights: lw    

Moran I statistic standard deviate = -7.2445, p-value = 1
alternative hypothesis: greater
sample estimates:
Moran I statistic       Expectation          Variance 
    -0.1978360659     -0.0015527950      0.0007340926 


> # Stop redirecting output
> sink()

> # --------------------------------------------------
> # End of Script
> # --------------------------------------------------
> 
> 

> # --------------------------------------------------
> # Spatial Statistical Modeling with SSN2
> # ------------------------------------------------ .... [TRUNCATED] 

> # Define the formula for the ssn_lm function
> # You can modify this formula as needed for different analyses
> model_formula <- as.formula(
+   "ch ..." ... [TRUNCATED] 

> # Specify the input and output directories
> input_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/Inputs"

> output_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/SSN ET/ET Full ws_re"

> model_name <- "glm ch_sfm.erosion.norm VIF 2 100 ct thresh ws_re"

> obs_points_path <- file.path(input_dir, "Combined Watersheds", "ET Full ssn points.gpkg")

> read_ssn <- TRUE # whether to create a new ssn (FALSE) or read the pre-existing ssn (TRUE)

> # Use file.path to create platform-independent file paths
> streams_path <- file.path(input_dir, "streams_100k.gpkg")

> ssn_path <- file.path(output_dir, "1_ET_Full_logtrans_independent_vars.ssn")

> output_file <- file.path(output_dir, model_name, "Results.txt")

> lsn_out <- file.path(output_dir, "0_lsn")

> # Define whether to save graphs and the directory to save them
> save_graphs <- TRUE  # Set to TRUE to save graphs as PNG

> graph_save_dir <- file.path(output_dir, model_name)  # Directory to save graphs

> # ----------------------------#
> # 1. Load Necessary Libraries
> # ----------------------------#
> 
> # Load required libraries
> library(SSN2)

> library(SSNbler)

> library(sf)

> library(dplyr)

> library(purrr)

> library(ggplot2)

> library(lmtest)

> library(spdep)

> library(classInt)   # Required for knearneigh

> library(broom)      # For tidy() and glance() functions

> library(grid)       # For grid.newpage()

> if (!dir.exists(graph_save_dir)) {
+   dir.create(graph_save_dir, recursive = TRUE)
+ }

> # ----------------------------#
> # 2. Read Spatial Data
> # ----------------------------#
> 
> # Read the streams dataset
> ET_streams <- st_read(s .... [TRUNCATED] 
Reading layer `streams_100k' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\streams_100k.gpkg' using driver `GPKG'
Simple feature collection with 643 features and 2 fields
Geometry type: LINESTRING
Dimension:     XY
Bounding box:  xmin: 404042.6 ymin: 4447904 xmax: 414579.6 ymax: 4466669
Projected CRS: NAD83 / UTM zone 13N

> # Read the observation points dataset
> ET_obs <- st_read(obs_points_path)
Reading layer `ET Full ssn points' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\Combined Watersheds\ET Full ssn points.gpkg' using driver `GPKG'
Simple feature collection with 645 features and 60 fields
Geometry type: POINT
Dimension:     XY
Bounding box:  xmin: 407401.1 ymin: 4449827 xmax: 413032.9 ymax: 4464548
Projected CRS: NAD83 / UTM zone 13N

> # Uncomment the following line if you encounter an error about Multilinestrings
> # ET_streams <- st_cast(ET_streams, "LINESTRING")
> 
> # --------- .... [TRUNCATED] 

> # Create a distance matrix for spatial relationships
> # Purpose: Define spatial dependencies based on distances between sites
> ssn_create_distmat( .... [TRUNCATED] 

> # ----------------------------#
> # 4. Model Fitting and Output
> # ----------------------------#
> 
> # Redirect output to the specified file and a .... [TRUNCATED] 

> model_name
[1] "glm ch_sfm.erosion.norm VIF 2 100 ct thresh ws_re"

> model_formula
ch_sfm.erosion.norm ~ ws_flow.accum.max + ws_slope.mean + ws_bare.earth.mean + 
    ws_drainage_density + ws_RV.Sand + ch_curvature.median + 
    ch_valley_width + ch_change.in.slope.over.width + ch_channel.width.over.valley.width + 
    ch_stream.power.central.diff + hs_hillslope.length + hs_slope.median + 
    hs_northness.median + hs_eastness.median + hs_curvature.median + 
    hs_ndvi.range + hs_dnbr.median + hs_drainage_density + flow.accumulation.max

> ssn_mod <- ssn_glm(
+   formula = model_formula,
+   ssn.object = ET_ssn,
+   family = "Gamma",
+   tailup_type = "exponential",
+   taildown_type = .... [TRUNCATED] 

> # Print the summary of the model to the file and console
> print(summary(ssn_mod))

Call:
ssn_glm(formula = model_formula, ssn.object = ET_ssn, family = "Gamma", 
    tailup_type = "exponential", taildown_type = "none", euclid_type = "gaussian", 
    additive = "afv_flow_accum", random = ~as.factor(ch_watershed))

Deviance Residuals:
       Min         1Q     Median         3Q        Max 
-1.8782655 -0.2339728 -0.0003834  0.1816483  0.9904105 

Coefficients (fixed):
                                    Estimate Std. Error z value Pr(>|z|)    
(Intercept)                        -1.949913   0.714828  -2.728  0.00638 ** 
ws_flow.accum.max                  -0.404024   0.228735  -1.766  0.07734 .  
ws_slope.mean                       1.139317   0.257134   4.431 9.39e-06 ***
ws_bare.earth.mean                 -0.227948   0.149620  -1.524  0.12763    
ws_drainage_density                 0.038633   0.018219   2.120  0.03396 *  
ws_RV.Sand                         -0.297464   0.379620  -0.784  0.43329    
ch_curvature.median                -0.008997   0.065960  -0.136  0.89150    
ch_valley_width                    -0.049524   0.074984  -0.660  0.50896    
ch_change.in.slope.over.width      -0.018392   0.017042  -1.079  0.28049    
ch_channel.width.over.valley.width  0.050237   0.075984   0.661  0.50851    
ch_stream.power.central.diff        0.024825   0.013866   1.790  0.07340 .  
hs_hillslope.length                -0.045256   0.045787  -0.988  0.32296    
hs_slope.median                     0.073010   0.089769   0.813  0.41604    
hs_northness.median                -0.128885   0.066777  -1.930  0.05360 .  
hs_eastness.median                 -0.020493   0.045418  -0.451  0.65184    
hs_curvature.median                 0.011279   0.030421   0.371  0.71080    
hs_ndvi.range                      -0.082624   0.065184  -1.268  0.20496    
hs_dnbr.median                      0.026938   0.078471   0.343  0.73138    
hs_drainage_density                 1.009103  13.868616   0.073  0.94200    
flow.accumulation.max              -0.141148   0.077038  -1.832  0.06692 .  
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Pseudo R-squared: 0.03101

Coefficients (covariance):
              Effect                    Parameter   Estimate
  tailup exponential                 de (parsill)  1.494e+00
  tailup exponential                        range  8.519e+01
     euclid gaussian                 de (parsill)  1.352e+00
     euclid gaussian                        range  3.729e+03
              nugget                       nugget  6.909e-04
          dispersion                   dispersion  3.482e+00
              random  1 | as.factor(ch_watershed)  1.759e-01


> # Print variance components of the model
> varcomp(ssn_mod)
# A tibble: 6 × 2
  varcomp                     proportion
  <chr>                            <dbl>
1 Covariates (PR-sq)            0.0310  
2 tailup_de                     0.479   
3 taildown_de                   0       
4 euclid_de                     0.433   
5 nugget                        0.000221
6 1 | as.factor(ch_watershed)   0.0564  

> # Tidy the model output with confidence intervals and print
> print(tidy(ssn_mod, conf.int = TRUE))  
# A tibble: 20 × 7
   term                               estimate std.error statistic    p.value  conf.low conf.high
   <chr>                                 <dbl>     <dbl>     <dbl>      <dbl>     <dbl>     <dbl>
 1 (Intercept)                        -1.95       0.715    -2.73   0.00638     -3.35     -0.549  
 2 ch_change.in.slope.over.width      -0.0184     0.0170   -1.08   0.280       -0.0518    0.0150 
 3 ch_channel.width.over.valley.width  0.0502     0.0760    0.661  0.509       -0.0987    0.199  
 4 ch_curvature.median                -0.00900    0.0660   -0.136  0.891       -0.138     0.120  
 5 ch_stream.power.central.diff        0.0248     0.0139    1.79   0.0734      -0.00235   0.0520 
 6 ch_valley_width                    -0.0495     0.0750   -0.660  0.509       -0.196     0.0974 
 7 flow.accumulation.max              -0.141      0.0770   -1.83   0.0669      -0.292     0.00984
 8 hs_curvature.median                 0.0113     0.0304    0.371  0.711       -0.0483    0.0709 
 9 hs_dnbr.median                      0.0269     0.0785    0.343  0.731       -0.127     0.181  
10 hs_drainage_density                 1.01      13.9       0.0728 0.942      -26.2      28.2    
11 hs_eastness.median                 -0.0205     0.0454   -0.451  0.652       -0.110     0.0685 
12 hs_hillslope.length                -0.0453     0.0458   -0.988  0.323       -0.135     0.0445 
13 hs_ndvi.range                      -0.0826     0.0652   -1.27   0.205       -0.210     0.0451 
14 hs_northness.median                -0.129      0.0668   -1.93   0.0536      -0.260     0.00200
15 hs_slope.median                     0.0730     0.0898    0.813  0.416       -0.103     0.249  
16 ws_bare.earth.mean                 -0.228      0.150    -1.52   0.128       -0.521     0.0653 
17 ws_drainage_density                 0.0386     0.0182    2.12   0.0340       0.00292   0.0743 
18 ws_flow.accum.max                  -0.404      0.229    -1.77   0.0773      -0.852     0.0443 
19 ws_RV.Sand                         -0.297      0.380    -0.784  0.433       -1.04      0.447  
20 ws_slope.mean                       1.14       0.257     4.43   0.00000939   0.635     1.64   

> # Provide a glance summary of the model and print
> print(glance(ssn_mod))
# A tibble: 1 × 9
      n     p  npar value   AIC  AICc logLik deviance pseudo.r.squared
  <int> <dbl> <int> <dbl> <dbl> <dbl>  <dbl>    <dbl>            <dbl>
1   645    20     7 1009. 1023. 1023.  -504.     94.0           0.0310

> # Perform Leave-One-Out Cross Validation and print
> print("Leave One Out Cross Validation")
[1] "Leave One Out Cross Validation"

> loocv_results <- loocv(ssn_mod)

> print(loocv_results)
# A tibble: 1 × 4
     bias  MSPE RMSPE   RAV
    <dbl> <dbl> <dbl> <dbl>
1 -0.0768 0.163 0.404 0.727

> # Stop redirecting output
> sink()

> # ----------------------------#
> # 5. Model Evaluation
> # ----------------------------#
> 
> # Extract residuals and fitted values from the model
 .... [TRUNCATED] 

> fitted_values <- fitted(ssn_mod)   

> # ----------------------------#
> # 6. Plotting and Saving Graphs
> # ----------------------------#
> 
> 
> # Create the graph save directory if sav .... [TRUNCATED] 

> # ----------------------------#
> # 7. Residuals vs Fitted Values Plot
> # ----------------------------#
> 
> # Purpose:
> #   - Linearity: Ensure t .... [TRUNCATED] 

> # Create the Residuals vs Fitted Values plot
> resid_fitted_plot <- ggplot(data.frame(Fitted = fitted_values, Residuals = residuals), aes(x = Fitted .... [TRUNCATED] 

> # Display the plot
> print(resid_fitted_plot)

> # Save the plot if saving is enabled
> if (save_graphs) {
+   ggsave(filename = file.path(graph_save_dir, "Residuals_vs_Fitted.png"), plot = resid_f .... [TRUNCATED] 
[1] "Saved Residuals vs Fitted Values plot."

> # ----------------------------#
> # 8. Q-Q Plot for Residuals
> # ----------------------------#
> 
> # Purpose:
> #   - Normality: Verify that resid .... [TRUNCATED] 

> # Enhanced Q-Q Plot using ggplot2
> qq_plot <- ggplot(data.frame(Residuals = residuals), aes(sample = Residuals)) +
+   stat_qq(color = "blue") +
+  .... [TRUNCATED] 

> # Display the ggplot2 Q-Q plot
> print(qq_plot)

> # Save the ggplot2 Q-Q plot if saving is enabled
> if (save_graphs) {
+   ggsave(filename = file.path(graph_save_dir, "QQ_Plot_Residuals_GGPlot2.png ..." ... [TRUNCATED] 
[1] "Saved ggplot2 Q-Q Plot of Residuals."

> # ----------------------------#
> # 9. Histogram of Residuals
> # ----------------------------#
> 
> # Purpose:
> #   - Normality
> #
> # What to Lo .... [TRUNCATED] 

> # Enhanced Histogram using ggplot2
> hist_plot <- ggplot(data.frame(Residuals = residuals), aes(x = Residuals)) +
+   geom_histogram(aes(y = ..densi .... [TRUNCATED] 

> # Display the ggplot2 histogram
> print(hist_plot)

> # Save the ggplot2 histogram if saving is enabled
> if (save_graphs) {
+   ggsave(filename = file.path(graph_save_dir, "Histogram_Residuals_GGPlot2. ..." ... [TRUNCATED] 
[1] "Saved ggplot2 Histogram of Residuals with Normal Curve."

> # Redirect output to the specified file and also print to console
> sink(output_file, append = TRUE, split = TRUE)

> print("")
[1] ""

> # ----------------------------#
> # 10. Statistical Tests
> # ----------------------------#
> 
> 
> # --------- Shapiro-Wilk Test for Normality ---- .... [TRUNCATED] 
[1] "-------- Shapiro-Wilk Test for Normality ---------"

> print("  - Normality: To check if the residuals are normally distributed.")
[1] "  - Normality: To check if the residuals are normally distributed."

> print("  - p-value > 0.05: Fail to reject null hypothesis (residuals are normally distributed).")
[1] "  - p-value > 0.05: Fail to reject null hypothesis (residuals are normally distributed)."

> print("  - p-value <= 0.05: Reject null hypothesis (residuals are not normally distributed).\n")
[1] "  - p-value <= 0.05: Reject null hypothesis (residuals are not normally distributed).\n"

> shapiro_test <- shapiro.test(residuals)

> print("Shapiro-Wilk Test Results:")
[1] "Shapiro-Wilk Test Results:"

> print(shapiro_test)

	Shapiro-Wilk normality test

data:  residuals
W = 0.96812, p-value = 1.252e-10


> # --------- Breusch-Pagan Test for Homoscedasticity ---------
> print("-------- Breusch-Pagan Test for Homoscedasticity ---------")
[1] "-------- Breusch-Pagan Test for Homoscedasticity ---------"

> print("  - Homoscedasticity: To check if residuals have constant variance across all levels of fitted values.")
[1] "  - Homoscedasticity: To check if residuals have constant variance across all levels of fitted values."

> print("  - p-value > 0.05: Fail to reject null hypothesis (homoscedasticity holds).")
[1] "  - p-value > 0.05: Fail to reject null hypothesis (homoscedasticity holds)."

> print("  - p-value <= 0.05: Reject null hypothesis (heteroscedasticity present).\n")
[1] "  - p-value <= 0.05: Reject null hypothesis (heteroscedasticity present).\n"

> # Extract the model frame from the ssn_lm model
> data_ssn <- model.frame(ssn_mod)

> # Perform Breusch-Pagan Test
> bp_test <- bptest(ssn_mod)

> print("Breusch-Pagan Test Results:")
[1] "Breusch-Pagan Test Results:"

> print(bp_test)

	studentized Breusch-Pagan test

data:  ssn_mod
BP = 59.158, df = 19, p-value = 5.254e-06


> # --------- Moran's I Test for Spatial Autocorrelation ---------
> print("\n-------- Moran's I Test for Spatial Autocorrelation ---------")
[1] "\n-------- Moran's I Test for Spatial Autocorrelation ---------"

> print("  - Spatial Autocorrelation: To determine if there is spatial autocorrelation in the residuals.")
[1] "  - Spatial Autocorrelation: To determine if there is spatial autocorrelation in the residuals."

> print("  - p-value > 0.05: Fail to reject null hypothesis (lack of spatial autocorrelation in residuals holds).")
[1] "  - p-value > 0.05: Fail to reject null hypothesis (lack of spatial autocorrelation in residuals holds)."

> print("  - p-value <= 0.05: Reject null hypothesis (spatial autocorrelation present).\n")
[1] "  - p-value <= 0.05: Reject null hypothesis (spatial autocorrelation present).\n"

> sink()

> # Extract spatial coordinates from the SSN object
> # Ensure that your SSN object has geometry information
> coords <- st_coordinates(ssn_get_data(s .... [TRUNCATED] 

> # Create a spatial weights matrix using k-nearest neighbors (k = 4 as an example)
> knn <- knearneigh(coords, k = 4)

> nb <- knn2nb(knn)

> lw <- nb2listw(nb, style = "W", zero.policy = TRUE)

> # Compute Moran's I
> moran_test <- moran.test(residuals, lw, zero.policy = TRUE)

> sink(output_file, append = TRUE, split = TRUE)

> print("Moran's I Test Results:")
[1] "Moran's I Test Results:"

> print(moran_test)

	Moran I test under randomisation

data:  residuals  
weights: lw    

Moran I statistic standard deviate = -7.382, p-value = 1
alternative hypothesis: greater
sample estimates:
Moran I statistic       Expectation          Variance 
    -0.2015572429     -0.0015527950      0.0007340585 


> # Stop redirecting output
> sink()

> # --------------------------------------------------
> # End of Script
> # --------------------------------------------------
> 
> 
