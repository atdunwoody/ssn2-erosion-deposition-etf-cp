
> model_name
[1] "glm ch_sfm.erosion.norm VIF 3 100ct thresh ws_re"

> model_formula
ch_sfm.erosion.norm ~ ch_slope.median + ch_flow.accumulation.max + 
    ch_curvature.median + ch_valley_width + ch_central.slope.difference + 
    ch_channel.width.over.valley.width + ch_slope.over.width.central.diff + 
    hs_area + hs_slope.median + hs_eastness.median + hs_curvature.median + 
    hs_ndvi.range + hs_dnbr.median + hs_drainage_density

> ssn_mod <- ssn_glm(
+   formula = model_formula,
+   ssn.object = ET_ssn,
+   family = "Gamma",
+   tailup_type = "exponential",
+   taildown_type = .... [TRUNCATED] 

> # Print the summary of the model to the file and console
> print(summary(ssn_mod))

Call:
ssn_glm(formula = model_formula, ssn.object = ET_ssn, family = "Gamma", 
    tailup_type = "exponential", taildown_type = "none", euclid_type = "gaussian", 
    additive = "afv_flow_accum")

Deviance Residuals:
       Min         1Q     Median         3Q        Max 
-0.0070917 -0.0016667  0.0000772  0.0015103  0.0068540 

Coefficients (fixed):
                                    Estimate Std. Error z value Pr(>|z|)    
(Intercept)                          0.07162    0.16155   0.443  0.65751    
ch_slope.median                      0.21851    0.15029   1.454  0.14596    
ch_flow.accumulation.max             1.30897    0.28874   4.533 5.81e-06 ***
ch_curvature.median                  0.02483    0.10655   0.233  0.81576    
ch_valley_width                     -0.41059    0.15866  -2.588  0.00966 ** 
ch_central.slope.difference          0.07123    0.07860   0.906  0.36476    
ch_channel.width.over.valley.width  -0.28161    0.17129  -1.644  0.10017    
ch_slope.over.width.central.diff     0.02645    0.07671   0.345  0.73026    
hs_area                              0.01978    0.11720   0.169  0.86597    
hs_slope.median                     -0.12173    0.11210  -1.086  0.27753    
hs_eastness.median                  -0.10291    0.14229  -0.723  0.46951    
hs_curvature.median                  0.06978    0.10336   0.675  0.49962    
hs_ndvi.range                        0.06150    0.15706   0.392  0.69537    
hs_dnbr.median                      -0.39137    0.20229  -1.935  0.05303 .  
hs_drainage_density                -36.29232   45.59787  -0.796  0.42608    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Pseudo R-squared: 0.1683

Coefficients (covariance):
              Effect     Parameter   Estimate
  tailup exponential  de (parsill)  6.465e-01
  tailup exponential         range  1.565e+01
     euclid gaussian  de (parsill)  2.372e-08
     euclid gaussian         range  8.643e+04
              nugget        nugget  2.164e-02
          dispersion    dispersion  5.548e+02


> # Print variance components of the model
> varcomp(ssn_mod)
# A tibble: 5 × 2
  varcomp              proportion
  <chr>                     <dbl>
1 Covariates (PR-sq) 0.168       
2 tailup_de          0.805       
3 taildown_de        0           
4 euclid_de          0.0000000295
5 nugget             0.0269      

> # Tidy the model output with confidence intervals and print
> print(tidy(ssn_mod, conf.int = TRUE))  
# A tibble: 15 × 7
   term                               estimate std.error statistic    p.value  conf.low conf.high
   <chr>                                 <dbl>     <dbl>     <dbl>      <dbl>     <dbl>     <dbl>
 1 (Intercept)                          0.0716    0.162      0.443 0.658        -0.245    0.388  
 2 ch_central.slope.difference          0.0712    0.0786     0.906 0.365        -0.0828   0.225  
 3 ch_channel.width.over.valley.width  -0.282     0.171     -1.64  0.100        -0.617    0.0541 
 4 ch_curvature.median                  0.0248    0.107      0.233 0.816        -0.184    0.234  
 5 ch_flow.accumulation.max             1.31      0.289      4.53  0.00000581    0.743    1.87   
 6 ch_slope.median                      0.219     0.150      1.45  0.146        -0.0760   0.513  
 7 ch_slope.over.width.central.diff     0.0264    0.0767     0.345 0.730        -0.124    0.177  
 8 ch_valley_width                     -0.411     0.159     -2.59  0.00966      -0.722   -0.0996 
 9 hs_area                              0.0198    0.117      0.169 0.866        -0.210    0.249  
10 hs_curvature.median                  0.0698    0.103      0.675 0.500        -0.133    0.272  
11 hs_dnbr.median                      -0.391     0.202     -1.93  0.0530       -0.788    0.00511
12 hs_drainage_density                -36.3      45.6       -0.796 0.426      -126.      53.1    
13 hs_eastness.median                  -0.103     0.142     -0.723 0.470        -0.382    0.176  
14 hs_ndvi.range                        0.0615    0.157      0.392 0.695        -0.246    0.369  
15 hs_slope.median                     -0.122     0.112     -1.09  0.278        -0.341    0.0980 

> # Provide a glance summary of the model and print
> print(glance(ssn_mod))
# A tibble: 1 × 9
      n     p  npar value   AIC  AICc logLik deviance pseudo.r.squared
  <int> <dbl> <int> <dbl> <dbl> <dbl>  <dbl>    <dbl>            <dbl>
1   107    15     6  369.  381.  381.  -184. 0.000664            0.168

> # Perform Leave-One-Out Cross Validation and print
> print("Leave One Out Cross Validation")
[1] "Leave One Out Cross Validation"

> loocv_results <- loocv(ssn_mod)

> print(loocv_results)
# A tibble: 1 × 4
    bias  MSPE RMSPE   RAV
   <dbl> <dbl> <dbl> <dbl>
1 -0.120 0.723 0.850 0.728

> # Stop redirecting output
> sink()
difference          0.07123    0.07860   0.906  0.36476    
ch_channel.width.over.valley.width  -0.28161    0.17129  -1.644  0.10017    
ch_slope.over.width.central.diff     0.02645    0.07671   0.345  0.73026    
hs_area                              0.01978    0.11720   0.169  0.86597    
hs_slope.median                     -0.12173    0.11210  -1.086  0.27753    
hs_eastness.median                  -0.10291    0.14229  -0.723  0.46951    
hs_curvature.median                  0.06978    0.10336   0.675  0.49962    
hs_ndvi.range                        0.06150    0.15706   0.392  0.69537    
hs_dnbr.median                      -0.39137    0.20229  -1.935  0.05303 .  
hs_drainage_density                -36.29232   45.59787  -0.796  0.42608    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Pseudo R-squared: 0.1683

Coefficients (covariance):
              Effect     Parameter   Estimate
  tailup exponential  de (parsill)  6.465e-01
  tailup exponential         range  1.565e+01
     euclid gaussian  de (parsill)  2.372e-08
     euclid gaussian         range  8.643e+04
              nugget        nugget  2.164e-02
          dispersion    dispersion  5.548e+02


> # Print variance components of the model
> varcomp(ssn_mod)
# A tibble: 5 × 2
  varcomp              proportion
  <chr>                     <dbl>
1 Covariates (PR-sq) 0.168       
2 tailup_de          0.805       
3 taildown_de        0           
4 euclid_de          0.0000000295
5 nugget             0.0269      

> # Tidy the model output with confidence intervals and print
> print(tidy(ssn_mod, conf.int = TRUE))  
# A tibble: 15 × 7
   term                               estimate std.error statistic    p.value  conf.low conf.high
   <chr>                                 <dbl>     <dbl>     <dbl>      <dbl>     <dbl>     <dbl>
 1 (Intercept)                          0.0716    0.162      0.443 0.658        -0.245    0.388  
 2 ch_central.slope.difference          0.0712    0.0786     0.906 0.365        -0.0828   0.225  
 3 ch_channel.width.over.valley.width  -0.282     0.171     -1.64  0.100        -0.617    0.0541 
 4 ch_curvature.median                  0.0248    0.107      0.233 0.816        -0.184    0.234  
 5 ch_flow.accumulation.max             1.31      0.289      4.53  0.00000581    0.743    1.87   
 6 ch_slope.median                      0.219     0.150      1.45  0.146        -0.0760   0.513  
 7 ch_slope.over.width.central.diff     0.0264    0.0767     0.345 0.730        -0.124    0.177  
 8 ch_valley_width                     -0.411     0.159     -2.59  0.00966      -0.722   -0.0996 
 9 hs_area                              0.0198    0.117      0.169 0.866        -0.210    0.249  
10 hs_curvature.median                  0.0698    0.103      0.675 0.500        -0.133    0.272  
11 hs_dnbr.median                      -0.391     0.202     -1.93  0.0530       -0.788    0.00511
12 hs_drainage_density                -36.3      45.6       -0.796 0.426      -126.      53.1    
13 hs_eastness.median                  -0.103     0.142     -0.723 0.470        -0.382    0.176  
14 hs_ndvi.range                        0.0615    0.157      0.392 0.695        -0.246    0.369  
15 hs_slope.median                     -0.122     0.112     -1.09  0.278        -0.341    0.0980 

> # Provide a glance summary of the model and print
> print(glance(ssn_mod))
# A tibble: 1 × 9
      n     p  npar value   AIC  AICc logLik deviance pseudo.r.squared
  <int> <dbl> <int> <dbl> <dbl> <dbl>  <dbl>    <dbl>            <dbl>
1   107    15     6  369.  381.  381.  -184. 0.000664            0.168

> # Perform Leave-One-Out Cross Validation and print
> print("Leave One Out Cross Validation")
[1] "Leave One Out Cross Validation"

> loocv_results <- loocv(ssn_mod)

> print(loocv_results)
# A tibble: 1 × 4
    bias  MSPE RMSPE   RAV
   <dbl> <dbl> <dbl> <dbl>
1 -0.120 0.723 0.850 0.728

> # Stop redirecting output
> sink()

> # ----------------------------#
> # 5. Model Evaluation
> # ----------------------------#
> 
> # Extract residuals and fitted values from the model
 .... [TRUNCATED] 

> fitted_values <- fitted(ssn_mod)   

> # ----------------------------#
> # 6. Plotting and Saving Graphs
> # ----------------------------#
> 
> 
> # Create the graph save directory if sav .... [TRUNCATED] 

> # ----------------------------#
> # 7. Residuals vs Fitted Values Plot
> # ----------------------------#
> 
> # Purpose:
> #   - Linearity: Ensure t .... [TRUNCATED] 

> # Create the Residuals vs Fitted Values plot
> resid_fitted_plot <- ggplot(data.frame(Fitted = fitted_values, Residuals = residuals), aes(x = Fitted .... [TRUNCATED] 

> # Display the plot
> print(resid_fitted_plot)

> # Save the plot if saving is enabled
> if (save_graphs) {
+   ggsave(filename = file.path(graph_save_dir, "Residuals_vs_Fitted.png"), plot = resid_f .... [TRUNCATED] 
[1] "Saved Residuals vs Fitted Values plot."

> # ----------------------------#
> # 8. Q-Q Plot for Residuals
> # ----------------------------#
> 
> # Purpose:
> #   - Normality: Verify that resid .... [TRUNCATED] 

> # Enhanced Q-Q Plot using ggplot2
> qq_plot <- ggplot(data.frame(Residuals = residuals), aes(sample = Residuals)) +
+   stat_qq(color = "blue") +
+  .... [TRUNCATED] 

> # Display the ggplot2 Q-Q plot
> print(qq_plot)

> # Save the ggplot2 Q-Q plot if saving is enabled
> if (save_graphs) {
+   ggsave(filename = file.path(graph_save_dir, "QQ_Plot_Residuals_GGPlot2.png ..." ... [TRUNCATED] 
[1] "Saved ggplot2 Q-Q Plot of Residuals."

> # ----------------------------#
> # 9. Histogram of Residuals
> # ----------------------------#
> 
> # Purpose:
> #   - Normality
> #
> # What to Lo .... [TRUNCATED] 

> # Enhanced Histogram using ggplot2
> hist_plot <- ggplot(data.frame(Residuals = residuals), aes(x = Residuals)) +
+   geom_histogram(aes(y = ..densi .... [TRUNCATED] 

> # Display the ggplot2 histogram
> print(hist_plot)

> # Save the ggplot2 histogram if saving is enabled
> if (save_graphs) {
+   ggsave(filename = file.path(graph_save_dir, "Histogram_Residuals_GGPlot2. ..." ... [TRUNCATED] 
[1] "Saved ggplot2 Histogram of Residuals with Normal Curve."

> # Redirect output to the specified file and also print to console
> sink(output_file, append = TRUE, split = TRUE)

> print("")
[1] ""

> # ----------------------------#
> # 10. Statistical Tests
> # ----------------------------#
> 
> 
> # --------- Shapiro-Wilk Test for Normality ---- .... [TRUNCATED] 
[1] "-------- Shapiro-Wilk Test for Normality ---------"

> print("  - Normality: To check if the residuals are normally distributed.")
[1] "  - Normality: To check if the residuals are normally distributed."

> print("  - p-value > 0.05: Fail to reject null hypothesis (residuals are normally distributed).")
[1] "  - p-value > 0.05: Fail to reject null hypothesis (residuals are normally distributed)."

> print("  - p-value <= 0.05: Reject null hypothesis (residuals are not normally distributed).\n")
[1] "  - p-value <= 0.05: Reject null hypothesis (residuals are not normally distributed).\n"

> shapiro_test <- shapiro.test(residuals)

> print("Shapiro-Wilk Test Results:")
[1] "Shapiro-Wilk Test Results:"

> print(shapiro_test)

	Shapiro-Wilk normality test

data:  residuals
W = 0.98881, p-value = 0.52


> # --------- Breusch-Pagan Test for Homoscedasticity ---------
> print("-------- Breusch-Pagan Test for Homoscedasticity ---------")
[1] "-------- Breusch-Pagan Test for Homoscedasticity ---------"

> print("  - Homoscedasticity: To check if residuals have constant variance across all levels of fitted values.")
[1] "  - Homoscedasticity: To check if residuals have constant variance across all levels of fitted values."

> print("  - p-value > 0.05: Fail to reject null hypothesis (homoscedasticity holds).")
[1] "  - p-value > 0.05: Fail to reject null hypothesis (homoscedasticity holds)."

> print("  - p-value <= 0.05: Reject null hypothesis (heteroscedasticity present).\n")
[1] "  - p-value <= 0.05: Reject null hypothesis (heteroscedasticity present).\n"

> # Extract the model frame from the ssn_lm model
> data_ssn <- model.frame(ssn_mod)

> # Perform Breusch-Pagan Test
> bp_test <- bptest(ssn_mod)

> print("Breusch-Pagan Test Results:")
[1] "Breusch-Pagan Test Results:"

> print(bp_test)

	studentized Breusch-Pagan test

data:  ssn_mod
BP = 20.444, df = 14, p-value = 0.1167


> # --------- Moran's I Test for Spatial Autocorrelation ---------
> print("\n-------- Moran's I Test for Spatial Autocorrelation ---------")
[1] "\n-------- Moran's I Test for Spatial Autocorrelation ---------"

> print("  - Spatial Autocorrelation: To determine if there is spatial autocorrelation in the residuals.")
[1] "  - Spatial Autocorrelation: To determine if there is spatial autocorrelation in the residuals."

> print("  - p-value > 0.05: Fail to reject null hypothesis (lack of spatial autocorrelation in residuals holds).")
[1] "  - p-value > 0.05: Fail to reject null hypothesis (lack of spatial autocorrelation in residuals holds)."

> print("  - p-value <= 0.05: Reject null hypothesis (spatial autocorrelation present).\n")
[1] "  - p-value <= 0.05: Reject null hypothesis (spatial autocorrelation present).\n"

> sink()

> # Extract spatial coordinates from the SSN object
> # Ensure that your SSN object has geometry information
> coords <- st_coordinates(ssn_get_data(s .... [TRUNCATED] 

> # Create a spatial weights matrix using k-nearest neighbors (k = 4 as an example)
> knn <- knearneigh(coords, k = 4)

> nb <- knn2nb(knn)

> lw <- nb2listw(nb, style = "W", zero.policy = TRUE)

> # Compute Moran's I
> moran_test <- moran.test(residuals, lw, zero.policy = TRUE)

> sink(output_file, append = TRUE, split = TRUE)

> print("Moran's I Test Results:")
[1] "Moran's I Test Results:"

> print(moran_test)

	Moran I test under randomisation

data:  residuals  
weights: lw    

Moran I statistic standard deviate = -2.5563, p-value = 0.9947
alternative hypothesis: greater
sample estimates:
Moran I statistic       Expectation          Variance 
     -0.175219908      -0.009433962       0.004205943 


> # Stop redirecting output
> sink()

> # --------------------------------------------------
> # End of Script
> # --------------------------------------------------
> 

> # --------------------------------------------------
> # Spatial Statistical Modeling with SSN2
> # ------------------------------------------------ .... [TRUNCATED] 

> # Specify the input and output directories
> input_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/Inputs"

> output_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/SSN ET/ET Full ws_re"

> model_name <- "glm ch_sfm.erosion.norm VIF 3 ws_re"

> obs_points_path <- file.path(input_dir, "Combined Watersheds", "ET Full ssn points.gpkg")

> read_ssn <- FALSE # whether to create a new ssn (FALSE) or read the pre-existing ssn (TRUE)

> # Use file.path to create platform-independent file paths
> streams_path <- file.path(input_dir, "streams_100k.gpkg")

> ssn_path <- file.path(output_dir, "1_ET_Full_logtrans_independent_vars.ssn")

> output_file <- file.path(output_dir, model_name, "Results.txt")

> lsn_out <- file.path(output_dir, "0_lsn")

> # Define whether to save graphs and the directory to save them
> save_graphs <- TRUE  # Set to TRUE to save graphs as PNG

> graph_save_dir <- file.path(output_dir, model_name)  # Directory to save graphs

> # ----------------------------#
> # 1. Load Necessary Libraries
> # ----------------------------#
> 
> # Load required libraries
> library(SSN2)

> library(SSNbler)

> library(sf)

> library(dplyr)

> library(purrr)

> library(ggplot2)

> library(lmtest)

> library(spdep)

> library(classInt)   # Required for knearneigh

> library(broom)      # For tidy() and glance() functions

> library(grid)       # For grid.newpage()

> if (!dir.exists(graph_save_dir)) {
+   dir.create(graph_save_dir, recursive = TRUE)
+ }

> # ----------------------------#
> # 2. Read Spatial Data
> # ----------------------------#
> 
> # Read the streams dataset
> ET_streams <- st_read(s .... [TRUNCATED] 
Reading layer `streams_100k' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\streams_100k.gpkg' using driver `GPKG'
Simple feature collection with 643 features and 2 fields
Geometry type: LINESTRING
Dimension:     XY
Bounding box:  xmin: 404042.6 ymin: 4447904 xmax: 414579.6 ymax: 4466669
Projected CRS: NAD83 / UTM zone 13N

> # Read the observation points dataset
> ET_obs <- st_read(obs_points_path)
Reading layer `ET Full ssn points' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\Combined Watersheds\ET Full ssn points.gpkg' using driver `GPKG'
Simple feature collection with 645 features and 60 fields
Geometry type: POINT
Dimension:     XY
Bounding box:  xmin: 407401.1 ymin: 4449827 xmax: 413032.9 ymax: 4464548
Projected CRS: NAD83 / UTM zone 13N

> # Uncomment the following line if you encounter an error about Multilinestrings
> # ET_streams <- st_cast(ET_streams, "LINESTRING")
> 
> # --------- .... [TRUNCATED] 
[1] "Edge Attributes:"
[1] "rid"            "STRM_VAL"       "flow_accum_max" "Length"         "upDist"         "geometry"      
[1] "Site List Components:"
[1] "obs"
[1] "Updated Edge Attributes:"
[1] "rid"            "STRM_VAL"       "flow_accum_max" "Length"         "upDist"         "flow_accum_PI"  "afv_flow_accum" "geometry"      


SSN object is valid: TRUE

> # Create a distance matrix for spatial relationships
> # Purpose: Define spatial dependencies based on distances between sites
> ssn_create_distmat( .... [TRUNCATED] 

> # ----------------------------#
> # 4. Model Fitting and Output
> # ----------------------------#
> 
> # Redirect output to the specified file and a .... [TRUNCATED] 

> model_name
[1] "glm ch_sfm.erosion.norm VIF 3 ws_re"

> model_formula
ch_sfm.erosion.norm ~ ch_slope.median + ch_flow.accumulation.max + 
    ch_curvature.median + ch_valley_width + ch_central.slope.difference + 
    ch_channel.width.over.valley.width + ch_slope.over.width.central.diff + 
    hs_area + hs_slope.median + hs_eastness.median + hs_curvature.median + 
    hs_ndvi.range + hs_dnbr.median + hs_drainage_density + (1 | 
    ch_watershed)

> ssn_mod <- ssn_glm(
+   formula = model_formula,
+   ssn.object = ET_ssn,
+   family = "Gamma",
+   tailup_type = "exponential",
+   taildown_type = .... [TRUNCATED] 

> # --------------------------------------------------
> # Spatial Statistical Modeling with SSN2
> # ------------------------------------------------ .... [TRUNCATED] 

> # Specify the input and output directories
> input_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/Inputs"

> output_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/SSN ET/ET Full ws_re"

> model_name <- "glm ch_sfm.erosion.norm VIF 3 ws_re"

> obs_points_path <- file.path(input_dir, "Combined Watersheds", "ET Full ssn points.gpkg")

> read_ssn <- TRUE # whether to create a new ssn (FALSE) or read the pre-existing ssn (TRUE)

> # Use file.path to create platform-independent file paths
> streams_path <- file.path(input_dir, "streams_100k.gpkg")

> ssn_path <- file.path(output_dir, "1_ET_Full_logtrans_independent_vars.ssn")

> output_file <- file.path(output_dir, model_name, "Results.txt")

> lsn_out <- file.path(output_dir, "0_lsn")

> # Define whether to save graphs and the directory to save them
> save_graphs <- TRUE  # Set to TRUE to save graphs as PNG

> graph_save_dir <- file.path(output_dir, model_name)  # Directory to save graphs

> # ----------------------------#
> # 1. Load Necessary Libraries
> # ----------------------------#
> 
> # Load required libraries
> library(SSN2)

> library(SSNbler)

> library(sf)

> library(dplyr)

> library(purrr)

> library(ggplot2)

> library(lmtest)

> library(spdep)

> library(classInt)   # Required for knearneigh

> library(broom)      # For tidy() and glance() functions

> library(grid)       # For grid.newpage()

> if (!dir.exists(graph_save_dir)) {
+   dir.create(graph_save_dir, recursive = TRUE)
+ }

> # ----------------------------#
> # 2. Read Spatial Data
> # ----------------------------#
> 
> # Read the streams dataset
> ET_streams <- st_read(s .... [TRUNCATED] 
Reading layer `streams_100k' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\streams_100k.gpkg' using driver `GPKG'
Simple feature collection with 643 features and 2 fields
Geometry type: LINESTRING
Dimension:     XY
Bounding box:  xmin: 404042.6 ymin: 4447904 xmax: 414579.6 ymax: 4466669
Projected CRS: NAD83 / UTM zone 13N

> # Read the observation points dataset
> ET_obs <- st_read(obs_points_path)
Reading layer `ET Full ssn points' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\Combined Watersheds\ET Full ssn points.gpkg' using driver `GPKG'
Simple feature collection with 645 features and 60 fields
Geometry type: POINT
Dimension:     XY
Bounding box:  xmin: 407401.1 ymin: 4449827 xmax: 413032.9 ymax: 4464548
Projected CRS: NAD83 / UTM zone 13N

> # Uncomment the following line if you encounter an error about Multilinestrings
> # ET_streams <- st_cast(ET_streams, "LINESTRING")
> 
> # --------- .... [TRUNCATED] 

> # Create a distance matrix for spatial relationships
> # Purpose: Define spatial dependencies based on distances between sites
> ssn_create_distmat( .... [TRUNCATED] 

> # ----------------------------#
> # 4. Model Fitting and Output
> # ----------------------------#
> 
> # Redirect output to the specified file and a .... [TRUNCATED] 

> model_name
[1] "glm ch_sfm.erosion.norm VIF 3 ws_re"

> model_formula
ch_sfm.erosion.norm ~ ch_slope.median + ch_curvature.median + 
    ch_valley_width + ch_central.slope.difference + ch_channel.width.over.valley.width + 
    ch_slope.over.width.central.diff + hs_area + hs_slope.median + 
    hs_eastness.median + hs_curvature.median + hs_ndvi.range + 
    hs_dnbr.median + hs_drainage_density + (1 | ch_watershed)

> ssn_mod <- ssn_glm(
+   formula = model_formula,
+   ssn.object = ET_ssn,
+   family = "Gamma",
+   tailup_type = "exponential",
+   taildown_type = .... [TRUNCATED] 

> # --------------------------------------------------
> # Spatial Statistical Modeling with SSN2
> # ------------------------------------------------ .... [TRUNCATED] 

> # Specify the input and output directories
> input_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/Inputs"

> output_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/SSN ET/ET Full ws_re"

> model_name <- "glm ch_sfm.erosion.norm VIF 3 ws_re"

> obs_points_path <- file.path(input_dir, "Combined Watersheds", "ET Full ssn points.gpkg")

> read_ssn <- TRUE # whether to create a new ssn (FALSE) or read the pre-existing ssn (TRUE)

> # Use file.path to create platform-independent file paths
> streams_path <- file.path(input_dir, "streams_100k.gpkg")

> ssn_path <- file.path(output_dir, "1_ET_Full_logtrans_independent_vars.ssn")

> output_file <- file.path(output_dir, model_name, "Results.txt")

> lsn_out <- file.path(output_dir, "0_lsn")

> # Define whether to save graphs and the directory to save them
> save_graphs <- TRUE  # Set to TRUE to save graphs as PNG

> graph_save_dir <- file.path(output_dir, model_name)  # Directory to save graphs

> # ----------------------------#
> # 1. Load Necessary Libraries
> # ----------------------------#
> 
> # Load required libraries
> library(SSN2)

> library(SSNbler)

> library(sf)

> library(dplyr)

> library(purrr)

> library(ggplot2)

> library(lmtest)

> library(spdep)

> library(classInt)   # Required for knearneigh

> library(broom)      # For tidy() and glance() functions

> library(grid)       # For grid.newpage()

> if (!dir.exists(graph_save_dir)) {
+   dir.create(graph_save_dir, recursive = TRUE)
+ }

> # ----------------------------#
> # 2. Read Spatial Data
> # ----------------------------#
> 
> # Read the streams dataset
> ET_streams <- st_read(s .... [TRUNCATED] 
Reading layer `streams_100k' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\streams_100k.gpkg' using driver `GPKG'
Simple feature collection with 643 features and 2 fields
Geometry type: LINESTRING
Dimension:     XY
Bounding box:  xmin: 404042.6 ymin: 4447904 xmax: 414579.6 ymax: 4466669
Projected CRS: NAD83 / UTM zone 13N

> # Read the observation points dataset
> ET_obs <- st_read(obs_points_path)
Reading layer `ET Full ssn points' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\Combined Watersheds\ET Full ssn points.gpkg' using driver `GPKG'
Simple feature collection with 645 features and 60 fields
Geometry type: POINT
Dimension:     XY
Bounding box:  xmin: 407401.1 ymin: 4449827 xmax: 413032.9 ymax: 4464548
Projected CRS: NAD83 / UTM zone 13N

> # Uncomment the following line if you encounter an error about Multilinestrings
> # ET_streams <- st_cast(ET_streams, "LINESTRING")
> 
> # --------- .... [TRUNCATED] 

> # Create a distance matrix for spatial relationships
> # Purpose: Define spatial dependencies based on distances between sites
> ssn_create_distmat( .... [TRUNCATED] 

> # ----------------------------#
> # 4. Model Fitting and Output
> # ----------------------------#
> 
> # Redirect output to the specified file and a .... [TRUNCATED] 

> model_name
[1] "glm ch_sfm.erosion.norm VIF 3 ws_re"

> model_formula
ch_sfm.erosion.norm ~ ch_slope.median + ch_curvature.median + 
    ch_valley_width + ch_central.slope.difference + ch_channel.width.over.valley.width + 
    ch_slope.over.width.central.diff + hs_area + hs_slope.median + 
    hs_eastness.median + hs_curvature.median + hs_ndvi.range + 
    hs_dnbr.median + hs_drainage_density

> ssn_mod <- ssn_glm(
+   formula = model_formula,
+   ssn.object = ET_ssn,
+   family = "Gamma",
+   tailup_type = "exponential",
+   taildown_type = .... [TRUNCATED] 

> # --------------------------------------------------
> # Spatial Statistical Modeling with SSN2
> # ------------------------------------------------ .... [TRUNCATED] 

> # Specify the input and output directories
> input_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/Inputs"

> output_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/SSN ET/ET Full ws_re"

> model_name <- "glm ch_sfm.erosion.norm VIF 3 ws_re"

> obs_points_path <- file.path(input_dir, "Combined Watersheds", "ET Full ssn points.gpkg")

> read_ssn <- TRUE # whether to create a new ssn (FALSE) or read the pre-existing ssn (TRUE)

> # Use file.path to create platform-independent file paths
> streams_path <- file.path(input_dir, "streams_100k.gpkg")

> ssn_path <- file.path(output_dir, "1_ET_Full_logtrans_independent_vars.ssn")

> output_file <- file.path(output_dir, model_name, "Results.txt")

> lsn_out <- file.path(output_dir, "0_lsn")

> # Define whether to save graphs and the directory to save them
> save_graphs <- TRUE  # Set to TRUE to save graphs as PNG

> graph_save_dir <- file.path(output_dir, model_name)  # Directory to save graphs

> # ----------------------------#
> # 1. Load Necessary Libraries
> # ----------------------------#
> 
> # Load required libraries
> library(SSN2)

> library(SSNbler)

> library(sf)

> library(dplyr)

> library(purrr)

> library(ggplot2)

> library(lmtest)

> library(spdep)

> library(classInt)   # Required for knearneigh

> library(broom)      # For tidy() and glance() functions

> library(grid)       # For grid.newpage()

> if (!dir.exists(graph_save_dir)) {
+   dir.create(graph_save_dir, recursive = TRUE)
+ }

> # ----------------------------#
> # 2. Read Spatial Data
> # ----------------------------#
> 
> # Read the streams dataset
> ET_streams <- st_read(s .... [TRUNCATED] 
Reading layer `streams_100k' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\streams_100k.gpkg' using driver `GPKG'
Simple feature collection with 643 features and 2 fields
Geometry type: LINESTRING
Dimension:     XY
Bounding box:  xmin: 404042.6 ymin: 4447904 xmax: 414579.6 ymax: 4466669
Projected CRS: NAD83 / UTM zone 13N

> # Read the observation points dataset
> ET_obs <- st_read(obs_points_path)
Reading layer `ET Full ssn points' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\Combined Watersheds\ET Full ssn points.gpkg' using driver `GPKG'
Simple feature collection with 645 features and 60 fields
Geometry type: POINT
Dimension:     XY
Bounding box:  xmin: 407401.1 ymin: 4449827 xmax: 413032.9 ymax: 4464548
Projected CRS: NAD83 / UTM zone 13N

> # Uncomment the following line if you encounter an error about Multilinestrings
> # ET_streams <- st_cast(ET_streams, "LINESTRING")
> 
> # --------- .... [TRUNCATED] 

> # Create a distance matrix for spatial relationships
> # Purpose: Define spatial dependencies based on distances between sites
> ssn_create_distmat( .... [TRUNCATED] 

> # ----------------------------#
> # 4. Model Fitting and Output
> # ----------------------------#
> 
> # Redirect output to the specified file and a .... [TRUNCATED] 

> model_name
[1] "glm ch_sfm.erosion.norm VIF 3 ws_re"

> model_formula
ch_sfm.erosion.norm ~ ch_slope.median + ch_flow.accumulation.max + 
    ch_valley_width + ch_central.slope.difference + hs_ndvi.range + 
    (1 | ch_watershed)

> ssn_mod <- ssn_glm(
+   formula = model_formula,
+   ssn.object = ET_ssn,
+   family = "Gamma",
+   tailup_type = "exponential",
+   taildown_type = .... [TRUNCATED] 

> # --------------------------------------------------
> # Spatial Statistical Modeling with SSN2
> # ------------------------------------------------ .... [TRUNCATED] 

> # Specify the input and output directories
> input_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/Inputs"

> output_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/SSN ET/ET Full ws_re"

> model_name <- "glm ch_sfm.erosion.norm VIF 3 ws_re"

> obs_points_path <- file.path(input_dir, "Combined Watersheds", "ET Full ssn points.gpkg")

> read_ssn <- TRUE # whether to create a new ssn (FALSE) or read the pre-existing ssn (TRUE)

> # Use file.path to create platform-independent file paths
> streams_path <- file.path(input_dir, "streams_100k.gpkg")

> ssn_path <- file.path(output_dir, "1_ET_Full_logtrans_independent_vars.ssn")

> output_file <- file.path(output_dir, model_name, "Results.txt")

> lsn_out <- file.path(output_dir, "0_lsn")

> # Define whether to save graphs and the directory to save them
> save_graphs <- TRUE  # Set to TRUE to save graphs as PNG

> graph_save_dir <- file.path(output_dir, model_name)  # Directory to save graphs

> # ----------------------------#
> # 1. Load Necessary Libraries
> # ----------------------------#
> 
> # Load required libraries
> library(SSN2)

> library(SSNbler)

> library(sf)

> library(dplyr)

> library(purrr)

> library(ggplot2)

> library(lmtest)

> library(spdep)

> library(classInt)   # Required for knearneigh

> library(broom)      # For tidy() and glance() functions

> library(grid)       # For grid.newpage()

> if (!dir.exists(graph_save_dir)) {
+   dir.create(graph_save_dir, recursive = TRUE)
+ }

> # ----------------------------#
> # 2. Read Spatial Data
> # ----------------------------#
> 
> # Read the streams dataset
> ET_streams <- st_read(s .... [TRUNCATED] 
Reading layer `streams_100k' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\streams_100k.gpkg' using driver `GPKG'
Simple feature collection with 643 features and 2 fields
Geometry type: LINESTRING
Dimension:     XY
Bounding box:  xmin: 404042.6 ymin: 4447904 xmax: 414579.6 ymax: 4466669
Projected CRS: NAD83 / UTM zone 13N

> # Read the observation points dataset
> ET_obs <- st_read(obs_points_path)
Reading layer `ET Full ssn points' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\Combined Watersheds\ET Full ssn points.gpkg' using driver `GPKG'
Simple feature collection with 645 features and 60 fields
Geometry type: POINT
Dimension:     XY
Bounding box:  xmin: 407401.1 ymin: 4449827 xmax: 413032.9 ymax: 4464548
Projected CRS: NAD83 / UTM zone 13N

> # Uncomment the following line if you encounter an error about Multilinestrings
> # ET_streams <- st_cast(ET_streams, "LINESTRING")
> 
> # --------- .... [TRUNCATED] 

> # Create a distance matrix for spatial relationships
> # Purpose: Define spatial dependencies based on distances between sites
> ssn_create_distmat( .... [TRUNCATED] 

> # ----------------------------#
> # 4. Model Fitting and Output
> # ----------------------------#
> 
> # Redirect output to the specified file and a .... [TRUNCATED] 

> # --------------------------------------------------
> # Spatial Statistical Modeling with SSN2
> # ------------------------------------------------ .... [TRUNCATED] 

> # Specify the input and output directories
> input_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/Inputs"

> output_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/SSN ET/ET Full ws_re"

> model_name <- "glm ch_sfm.erosion.norm VIF 3 ws_re"

> obs_points_path <- file.path(input_dir, "Combined Watersheds", "ET Full ssn points.gpkg")

> read_ssn <- TRUE # whether to create a new ssn (FALSE) or read the pre-existing ssn (TRUE)

> # Use file.path to create platform-independent file paths
> streams_path <- file.path(input_dir, "streams_100k.gpkg")

> ssn_path <- file.path(output_dir, "1_ET_Full_logtrans_independent_vars.ssn")

> output_file <- file.path(output_dir, model_name, "Results.txt")

> lsn_out <- file.path(output_dir, "0_lsn")

> # Define whether to save graphs and the directory to save them
> save_graphs <- TRUE  # Set to TRUE to save graphs as PNG

> graph_save_dir <- file.path(output_dir, model_name)  # Directory to save graphs

> # ----------------------------#
> # 1. Load Necessary Libraries
> # ----------------------------#
> 
> # Load required libraries
> library(SSN2)

> library(SSNbler)

> library(sf)

> library(dplyr)

> library(purrr)

> library(ggplot2)

> library(lmtest)

> library(spdep)

> library(classInt)   # Required for knearneigh

> library(broom)      # For tidy() and glance() functions

> library(grid)       # For grid.newpage()

> if (!dir.exists(graph_save_dir)) {
+   dir.create(graph_save_dir, recursive = TRUE)
+ }

> # ----------------------------#
> # 2. Read Spatial Data
> # ----------------------------#
> 
> # Read the streams dataset
> ET_streams <- st_read(s .... [TRUNCATED] 
Reading layer `streams_100k' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\streams_100k.gpkg' using driver `GPKG'
Simple feature collection with 643 features and 2 fields
Geometry type: LINESTRING
Dimension:     XY
Bounding box:  xmin: 404042.6 ymin: 4447904 xmax: 414579.6 ymax: 4466669
Projected CRS: NAD83 / UTM zone 13N

> # Read the observation points dataset
> ET_obs <- st_read(obs_points_path)
Reading layer `ET Full ssn points' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\Combined Watersheds\ET Full ssn points.gpkg' using driver `GPKG'
Simple feature collection with 645 features and 60 fields
Geometry type: POINT
Dimension:     XY
Bounding box:  xmin: 407401.1 ymin: 4449827 xmax: 413032.9 ymax: 4464548
Projected CRS: NAD83 / UTM zone 13N

> # Uncomment the following line if you encounter an error about Multilinestrings
> # ET_streams <- st_cast(ET_streams, "LINESTRING")
> 
> # --------- .... [TRUNCATED] 

> # Create a distance matrix for spatial relationships
> # Purpose: Define spatial dependencies based on distances between sites
> ssn_create_distmat( .... [TRUNCATED] 

> # ----------------------------#
> # 4. Model Fitting and Output
> # ----------------------------#
> 
> # Redirect output to the specified file and a .... [TRUNCATED] 

> # --------------------------------------------------
> # Spatial Statistical Modeling with SSN2
> # ------------------------------------------------ .... [TRUNCATED] 

> # Define the formula for the ssn_lm function
> # You can modify this formula as needed for different analyses
> model_formula <- as.formula(
+   "ch ..." ... [TRUNCATED] 

> # Specify the input and output directories
> input_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/Inputs"

> output_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/SSN ET/ET Full ws_re"

> model_name <- "glm ch_sfm.erosion.norm VIF 3 ws_re"

> obs_points_path <- file.path(input_dir, "Combined Watersheds", "ET Full ssn points.gpkg")

> read_ssn <- TRUE # whether to create a new ssn (FALSE) or read the pre-existing ssn (TRUE)

> # Use file.path to create platform-independent file paths
> streams_path <- file.path(input_dir, "streams_100k.gpkg")

> ssn_path <- file.path(output_dir, "1_ET_Full_logtrans_independent_vars.ssn")

> output_file <- file.path(output_dir, model_name, "Results.txt")

> lsn_out <- file.path(output_dir, "0_lsn")

> # Define whether to save graphs and the directory to save them
> save_graphs <- TRUE  # Set to TRUE to save graphs as PNG

> graph_save_dir <- file.path(output_dir, model_name)  # Directory to save graphs

> # ----------------------------#
> # 1. Load Necessary Libraries
> # ----------------------------#
> 
> # Load required libraries
> library(SSN2)

> library(SSNbler)

> library(sf)

> library(dplyr)

> library(purrr)

> library(ggplot2)

> library(lmtest)

> library(spdep)

> library(classInt)   # Required for knearneigh

> library(broom)      # For tidy() and glance() functions

> library(grid)       # For grid.newpage()

> if (!dir.exists(graph_save_dir)) {
+   dir.create(graph_save_dir, recursive = TRUE)
+ }

> # ----------------------------#
> # 2. Read Spatial Data
> # ----------------------------#
> 
> # Read the streams dataset
> ET_streams <- st_read(s .... [TRUNCATED] 
Reading layer `streams_100k' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\streams_100k.gpkg' using driver `GPKG'
Simple feature collection with 643 features and 2 fields
Geometry type: LINESTRING
Dimension:     XY
Bounding box:  xmin: 404042.6 ymin: 4447904 xmax: 414579.6 ymax: 4466669
Projected CRS: NAD83 / UTM zone 13N

> # Read the observation points dataset
> ET_obs <- st_read(obs_points_path)
Reading layer `ET Full ssn points' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\Combined Watersheds\ET Full ssn points.gpkg' using driver `GPKG'
Simple feature collection with 645 features and 60 fields
Geometry type: POINT
Dimension:     XY
Bounding box:  xmin: 407401.1 ymin: 4449827 xmax: 413032.9 ymax: 4464548
Projected CRS: NAD83 / UTM zone 13N

> # Uncomment the following line if you encounter an error about Multilinestrings
> # ET_streams <- st_cast(ET_streams, "LINESTRING")
> 
> # --------- .... [TRUNCATED] 

> # Create a distance matrix for spatial relationships
> # Purpose: Define spatial dependencies based on distances between sites
> ssn_create_distmat( .... [TRUNCATED] 

> # ----------------------------#
> # 4. Model Fitting and Output
> # ----------------------------#
> 
> # Redirect output to the specified file and a .... [TRUNCATED] 

> model_name
[1] "glm ch_sfm.erosion.norm VIF 3 ws_re"

> model_formula
ch_sfm.erosion.norm ~ ch_slope.median + (1 | ch_watershed)

> ssn_mod <- ssn_glm(
+   formula = model_formula,
+   ssn.object = ET_ssn,
+   family = "Gamma",
+   tailup_type = "exponential",
+   taildown_type = .... [TRUNCATED] 

> # --------------------------------------------------
> # Spatial Statistical Modeling with SSN2
> # ------------------------------------------------ .... [TRUNCATED] 

> # Define the formula for the ssn_lm function
> # You can modify this formula as needed for different analyses
> model_formula <- as.formula(
+   "ch ..." ... [TRUNCATED] 

> # Specify the input and output directories
> input_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/Inputs"

> output_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/SSN ET/ET Full ws_re"

> model_name <- "glm ch_sfm.erosion.norm VIF 3 ws_re"

> obs_points_path <- file.path(input_dir, "Combined Watersheds", "ET Full ssn points.gpkg")

> read_ssn <- TRUE # whether to create a new ssn (FALSE) or read the pre-existing ssn (TRUE)

> # Use file.path to create platform-independent file paths
> streams_path <- file.path(input_dir, "streams_100k.gpkg")

> ssn_path <- file.path(output_dir, "1_ET_Full_logtrans_independent_vars.ssn")

> output_file <- file.path(output_dir, model_name, "Results.txt")

> lsn_out <- file.path(output_dir, "0_lsn")

> # Define whether to save graphs and the directory to save them
> save_graphs <- TRUE  # Set to TRUE to save graphs as PNG

> graph_save_dir <- file.path(output_dir, model_name)  # Directory to save graphs

> # ----------------------------#
> # 1. Load Necessary Libraries
> # ----------------------------#
> 
> # Load required libraries
> library(SSN2)

> library(SSNbler)

> library(sf)

> library(dplyr)

> library(purrr)

> library(ggplot2)

> library(lmtest)

> library(spdep)

> library(classInt)   # Required for knearneigh

> library(broom)      # For tidy() and glance() functions

> library(grid)       # For grid.newpage()

> if (!dir.exists(graph_save_dir)) {
+   dir.create(graph_save_dir, recursive = TRUE)
+ }

> # ----------------------------#
> # 2. Read Spatial Data
> # ----------------------------#
> 
> # Read the streams dataset
> ET_streams <- st_read(s .... [TRUNCATED] 
Reading layer `streams_100k' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\streams_100k.gpkg' using driver `GPKG'
Simple feature collection with 643 features and 2 fields
Geometry type: LINESTRING
Dimension:     XY
Bounding box:  xmin: 404042.6 ymin: 4447904 xmax: 414579.6 ymax: 4466669
Projected CRS: NAD83 / UTM zone 13N

> # Read the observation points dataset
> ET_obs <- st_read(obs_points_path)
Reading layer `ET Full ssn points' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\Combined Watersheds\ET Full ssn points.gpkg' using driver `GPKG'
Simple feature collection with 645 features and 60 fields
Geometry type: POINT
Dimension:     XY
Bounding box:  xmin: 407401.1 ymin: 4449827 xmax: 413032.9 ymax: 4464548
Projected CRS: NAD83 / UTM zone 13N

> # Uncomment the following line if you encounter an error about Multilinestrings
> # ET_streams <- st_cast(ET_streams, "LINESTRING")
> 
> # --------- .... [TRUNCATED] 

> # Create a distance matrix for spatial relationships
> # Purpose: Define spatial dependencies based on distances between sites
> ssn_create_distmat( .... [TRUNCATED] 

> # ----------------------------#
> # 4. Model Fitting and Output
> # ----------------------------#
> 
> # Redirect output to the specified file and a .... [TRUNCATED] 

> model_name
[1] "glm ch_sfm.erosion.norm VIF 3 ws_re"

> model_formula
ch_sfm.erosion.norm ~ (1 | ch_watershed)

> ssn_mod <- ssn_glm(
+   formula = model_formula,
+   ssn.object = ET_ssn,
+   family = "Gamma",
+   tailup_type = "exponential",
+   taildown_type = .... [TRUNCATED] 
NULL
< table of extent 0 >

> # --------------------------------------------------
> # Spatial Statistical Modeling with SSN2
> # ------------------------------------------------ .... [TRUNCATED] 

> # Specify the input and output directories
> input_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/Inputs"

> output_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/SSN ET/ET Full ws_re"

> model_name <- "glm ch_sfm.erosion.norm VIF 3 ws_re"

> obs_points_path <- file.path(input_dir, "Combined Watersheds", "ET Full ssn points.gpkg")

> read_ssn <- TRUE # whether to create a new ssn (FALSE) or read the pre-existing ssn (TRUE)

> # Use file.path to create platform-independent file paths
> streams_path <- file.path(input_dir, "streams_100k.gpkg")

> ssn_path <- file.path(output_dir, "1_ET_Full_logtrans_independent_vars.ssn")

> output_file <- file.path(output_dir, model_name, "Results.txt")

> lsn_out <- file.path(output_dir, "0_lsn")

> # Define whether to save graphs and the directory to save them
> save_graphs <- TRUE  # Set to TRUE to save graphs as PNG

> graph_save_dir <- file.path(output_dir, model_name)  # Directory to save graphs

> # ----------------------------#
> # 1. Load Necessary Libraries
> # ----------------------------#
> 
> # Load required libraries
> library(SSN2)

> library(SSNbler)

> library(sf)

> library(dplyr)

> library(purrr)

> library(ggplot2)

> library(lmtest)

> library(spdep)

> library(classInt)   # Required for knearneigh

> library(broom)      # For tidy() and glance() functions

> library(grid)       # For grid.newpage()

> if (!dir.exists(graph_save_dir)) {
+   dir.create(graph_save_dir, recursive = TRUE)
+ }

> # ----------------------------#
> # 2. Read Spatial Data
> # ----------------------------#
> 
> # Read the streams dataset
> ET_streams <- st_read(s .... [TRUNCATED] 
Reading layer `streams_100k' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\streams_100k.gpkg' using driver `GPKG'
Simple feature collection with 643 features and 2 fields
Geometry type: LINESTRING
Dimension:     XY
Bounding box:  xmin: 404042.6 ymin: 4447904 xmax: 414579.6 ymax: 4466669
Projected CRS: NAD83 / UTM zone 13N

> # Read the observation points dataset
> ET_obs <- st_read(obs_points_path)
Reading layer `ET Full ssn points' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\Combined Watersheds\ET Full ssn points.gpkg' using driver `GPKG'
Simple feature collection with 645 features and 60 fields
Geometry type: POINT
Dimension:     XY
Bounding box:  xmin: 407401.1 ymin: 4449827 xmax: 413032.9 ymax: 4464548
Projected CRS: NAD83 / UTM zone 13N

> # Uncomment the following line if you encounter an error about Multilinestrings
> # ET_streams <- st_cast(ET_streams, "LINESTRING")
> 
> # --------- .... [TRUNCATED] 

> # Create a distance matrix for spatial relationships
> # Purpose: Define spatial dependencies based on distances between sites
> ssn_create_distmat( .... [TRUNCATED] 

> # ----------------------------#
> # 4. Model Fitting and Output
> # ----------------------------#
> 
> # Redirect output to the specified file and a .... [TRUNCATED] 

> # --------------------------------------------------
> # Spatial Statistical Modeling with SSN2
> # ------------------------------------------------ .... [TRUNCATED] 

> # Define the formula for the ssn_lm function
> # You can modify this formula as needed for different analyses
> model_formula <- as.formula(
+   "ch ..." ... [TRUNCATED] 

> # Specify the input and output directories
> input_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/Inputs"

> output_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/SSN ET/ET Full ws_re"

> model_name <- "glm ch_sfm.erosion.norm VIF 3 ws_re"

> obs_points_path <- file.path(input_dir, "Combined Watersheds", "ET Full ssn points.gpkg")

> read_ssn <- TRUE # whether to create a new ssn (FALSE) or read the pre-existing ssn (TRUE)

> # Use file.path to create platform-independent file paths
> streams_path <- file.path(input_dir, "streams_100k.gpkg")

> ssn_path <- file.path(output_dir, "1_ET_Full_logtrans_independent_vars.ssn")

> output_file <- file.path(output_dir, model_name, "Results.txt")

> lsn_out <- file.path(output_dir, "0_lsn")

> # Define whether to save graphs and the directory to save them
> save_graphs <- TRUE  # Set to TRUE to save graphs as PNG

> graph_save_dir <- file.path(output_dir, model_name)  # Directory to save graphs

> # ----------------------------#
> # 1. Load Necessary Libraries
> # ----------------------------#
> 
> # Load required libraries
> library(SSN2)

> library(SSNbler)

> library(sf)

> library(dplyr)

> library(purrr)

> library(ggplot2)

> library(lmtest)

> library(spdep)

> library(classInt)   # Required for knearneigh

> library(broom)      # For tidy() and glance() functions

> library(grid)       # For grid.newpage()

> if (!dir.exists(graph_save_dir)) {
+   dir.create(graph_save_dir, recursive = TRUE)
+ }

> # ----------------------------#
> # 2. Read Spatial Data
> # ----------------------------#
> 
> # Read the streams dataset
> ET_streams <- st_read(s .... [TRUNCATED] 
Reading layer `streams_100k' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\streams_100k.gpkg' using driver `GPKG'
Simple feature collection with 643 features and 2 fields
Geometry type: LINESTRING
Dimension:     XY
Bounding box:  xmin: 404042.6 ymin: 4447904 xmax: 414579.6 ymax: 4466669
Projected CRS: NAD83 / UTM zone 13N

> # Read the observation points dataset
> ET_obs <- st_read(obs_points_path)
Reading layer `ET Full ssn points' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\Combined Watersheds\ET Full ssn points.gpkg' using driver `GPKG'
Simple feature collection with 645 features and 60 fields
Geometry type: POINT
Dimension:     XY
Bounding box:  xmin: 407401.1 ymin: 4449827 xmax: 413032.9 ymax: 4464548
Projected CRS: NAD83 / UTM zone 13N

> # Uncomment the following line if you encounter an error about Multilinestrings
> # ET_streams <- st_cast(ET_streams, "LINESTRING")
> 
> # --------- .... [TRUNCATED] 

> # Create a distance matrix for spatial relationships
> # Purpose: Define spatial dependencies based on distances between sites
> ssn_create_distmat( .... [TRUNCATED] 

> # ----------------------------#
> # 4. Model Fitting and Output
> # ----------------------------#
> 
> # Redirect output to the specified file and a .... [TRUNCATED] 

> model_name
[1] "glm ch_sfm.erosion.norm VIF 3 ws_re"

> model_formula
ch_sfm.erosion.norm ~ ch_slope.median + ch_curvature.median + 
    ch_valley_width + ch_central.slope.difference + ch_channel.width.over.valley.width + 
    ch_slope.over.width.central.diff + hs_area + hs_slope.median + 
    hs_eastness.median + hs_curvature.median + hs_ndvi.range + 
    hs_dnbr.median + hs_drainage_density + ch_watershed

> ssn_mod <- ssn_glm(
+   formula = model_formula,
+   ssn.object = ET_ssn,
+   family = "Gamma",
+   tailup_type = "exponential",
+   taildown_type = .... [TRUNCATED] 

> # Print the summary of the model to the file and console
> print(summary(ssn_mod))

Call:
ssn_glm(formula = model_formula, ssn.object = ET_ssn, family = "Gamma", 
    tailup_type = "exponential", taildown_type = "none", euclid_type = "gaussian", 
    additive = "afv_flow_accum")

Deviance Residuals:
     Min       1Q   Median       3Q      Max 
-1.97575 -0.29152 -0.01429  0.22337  1.14741 

Coefficients (fixed):
                                    Estimate Std. Error z value Pr(>|z|)   
(Intercept)                         0.081420   1.391434   0.059  0.95334   
ch_slope.median                     0.151747   0.070068   2.166  0.03033 * 
ch_curvature.median                 0.009959   0.066831   0.149  0.88154   
ch_valley_width                    -0.054263   0.075628  -0.717  0.47307   
ch_central.slope.difference        -0.051828   0.030209  -1.716  0.08622 . 
ch_channel.width.over.valley.width  0.082748   0.075513   1.096  0.27316   
ch_slope.over.width.central.diff    0.056676   0.021293   2.662  0.00777 **
hs_area                            -0.021892   0.041007  -0.534  0.59344   
hs_slope.median                     0.078084   0.089237   0.875  0.38156   
hs_eastness.median                 -0.002436   0.043498  -0.056  0.95535   
hs_curvature.median                 0.008276   0.029486   0.281  0.77896   
hs_ndvi.range                      -0.060944   0.063676  -0.957  0.33852   
hs_dnbr.median                     -0.030411   0.074332  -0.409  0.68244   
hs_drainage_density                 2.149034  13.965222   0.154  0.87770   
ch_watershed                       -0.612585   0.222942  -2.748  0.00600 **
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Pseudo R-squared: 0.01247

Coefficients (covariance):
              Effect     Parameter   Estimate
  tailup exponential  de (parsill)  2.514e+00
  tailup exponential         range  2.041e+02
     euclid gaussian  de (parsill)  1.219e+00
     euclid gaussian         range  3.394e+04
              nugget        nugget  3.303e-04
          dispersion    dispersion  2.975e+00


> # Print variance components of the model
> varcomp(ssn_mod)
# A tibble: 5 × 2
  varcomp            proportion
  <chr>                   <dbl>
1 Covariates (PR-sq)  0.0125   
2 tailup_de           0.665    
3 taildown_de         0        
4 euclid_de           0.322    
5 nugget              0.0000874

> # Tidy the model output with confidence intervals and print
> print(tidy(ssn_mod, conf.int = TRUE))  
# A tibble: 15 × 7
   term                               estimate std.error statistic p.value conf.low conf.high
   <chr>                                 <dbl>     <dbl>     <dbl>   <dbl>    <dbl>     <dbl>
 1 (Intercept)                         0.0814     1.39      0.0585 0.953    -2.65     2.81   
 2 ch_central.slope.difference        -0.0518     0.0302   -1.72   0.0862   -0.111    0.00738
 3 ch_channel.width.over.valley.width  0.0827     0.0755    1.10   0.273    -0.0653   0.231  
 4 ch_curvature.median                 0.00996    0.0668    0.149  0.882    -0.121    0.141  
 5 ch_slope.median                     0.152      0.0701    2.17   0.0303    0.0144   0.289  
 6 ch_slope.over.width.central.diff    0.0567     0.0213    2.66   0.00777   0.0149   0.0984 
 7 ch_valley_width                    -0.0543     0.0756   -0.717  0.473    -0.202    0.0940 
 8 ch_watershed                       -0.613      0.223    -2.75   0.00600  -1.05    -0.176  
 9 hs_area                            -0.0219     0.0410   -0.534  0.593    -0.102    0.0585 
10 hs_curvature.median                 0.00828    0.0295    0.281  0.779    -0.0495   0.0661 
11 hs_dnbr.median                     -0.0304     0.0743   -0.409  0.682    -0.176    0.115  
12 hs_drainage_density                 2.15      14.0       0.154  0.878   -25.2     29.5    
13 hs_eastness.median                 -0.00244    0.0435   -0.0560 0.955    -0.0877   0.0828 
14 hs_ndvi.range                      -0.0609     0.0637   -0.957  0.339    -0.186    0.0639 
15 hs_slope.median                     0.0781     0.0892    0.875  0.382    -0.0968   0.253  

> # Provide a glance summary of the model and print
> print(glance(ssn_mod))
# A tibble: 1 × 9
      n     p  npar value   AIC  AICc logLik deviance pseudo.r.squared
  <int> <dbl> <int> <dbl> <dbl> <dbl>  <dbl>    <dbl>            <dbl>
1   645    15     6 1017. 1029. 1029.  -508.     131.           0.0125

> # Perform Leave-One-Out Cross Validation and print
> print("Leave One Out Cross Validation")
[1] "Leave One Out Cross Validation"

> loocv_results <- loocv(ssn_mod)

> print(loocv_results)
# A tibble: 1 × 4
     bias  MSPE RMSPE   RAV
    <dbl> <dbl> <dbl> <dbl>
1 -0.0674 0.154 0.392 0.493

> # Stop redirecting output
> sink()

> # ----------------------------#
> # 5. Model Evaluation
> # ----------------------------#
> 
> # Extract residuals and fitted values from the model
 .... [TRUNCATED] 

> fitted_values <- fitted(ssn_mod)   

> # ----------------------------#
> # 6. Plotting and Saving Graphs
> # ----------------------------#
> 
> 
> # Create the graph save directory if sav .... [TRUNCATED] 

> # ----------------------------#
> # 7. Residuals vs Fitted Values Plot
> # ----------------------------#
> 
> # Purpose:
> #   - Linearity: Ensure t .... [TRUNCATED] 

> # Create the Residuals vs Fitted Values plot
> resid_fitted_plot <- ggplot(data.frame(Fitted = fitted_values, Residuals = residuals), aes(x = Fitted .... [TRUNCATED] 

> # Display the plot
> print(resid_fitted_plot)

> # Save the plot if saving is enabled
> if (save_graphs) {
+   ggsave(filename = file.path(graph_save_dir, "Residuals_vs_Fitted.png"), plot = resid_f .... [TRUNCATED] 
[1] "Saved Residuals vs Fitted Values plot."

> # ----------------------------#
> # 8. Q-Q Plot for Residuals
> # ----------------------------#
> 
> # Purpose:
> #   - Normality: Verify that resid .... [TRUNCATED] 

> # Enhanced Q-Q Plot using ggplot2
> qq_plot <- ggplot(data.frame(Residuals = residuals), aes(sample = Residuals)) +
+   stat_qq(color = "blue") +
+  .... [TRUNCATED] 

> # Display the ggplot2 Q-Q plot
> print(qq_plot)

> # Save the ggplot2 Q-Q plot if saving is enabled
> if (save_graphs) {
+   ggsave(filename = file.path(graph_save_dir, "QQ_Plot_Residuals_GGPlot2.png ..." ... [TRUNCATED] 
[1] "Saved ggplot2 Q-Q Plot of Residuals."

> # ----------------------------#
> # 9. Histogram of Residuals
> # ----------------------------#
> 
> # Purpose:
> #   - Normality
> #
> # What to Lo .... [TRUNCATED] 

> # Enhanced Histogram using ggplot2
> hist_plot <- ggplot(data.frame(Residuals = residuals), aes(x = Residuals)) +
+   geom_histogram(aes(y = ..densi .... [TRUNCATED] 

> # Display the ggplot2 histogram
> print(hist_plot)

> # Save the ggplot2 histogram if saving is enabled
> if (save_graphs) {
+   ggsave(filename = file.path(graph_save_dir, "Histogram_Residuals_GGPlot2. ..." ... [TRUNCATED] 
[1] "Saved ggplot2 Histogram of Residuals with Normal Curve."

> # Redirect output to the specified file and also print to console
> sink(output_file, append = TRUE, split = TRUE)

> print("")
[1] ""

> # ----------------------------#
> # 10. Statistical Tests
> # ----------------------------#
> 
> 
> # --------- Shapiro-Wilk Test for Normality ---- .... [TRUNCATED] 
[1] "-------- Shapiro-Wilk Test for Normality ---------"

> print("  - Normality: To check if the residuals are normally distributed.")
[1] "  - Normality: To check if the residuals are normally distributed."

> print("  - p-value > 0.05: Fail to reject null hypothesis (residuals are normally distributed).")
[1] "  - p-value > 0.05: Fail to reject null hypothesis (residuals are normally distributed)."

> print("  - p-value <= 0.05: Reject null hypothesis (residuals are not normally distributed).\n")
[1] "  - p-value <= 0.05: Reject null hypothesis (residuals are not normally distributed).\n"

> shapiro_test <- shapiro.test(residuals)

> print("Shapiro-Wilk Test Results:")
[1] "Shapiro-Wilk Test Results:"

> print(shapiro_test)

	Shapiro-Wilk normality test

data:  residuals
W = 0.97505, p-value = 5e-09


> # --------- Breusch-Pagan Test for Homoscedasticity ---------
> print("-------- Breusch-Pagan Test for Homoscedasticity ---------")
[1] "-------- Breusch-Pagan Test for Homoscedasticity ---------"

> print("  - Homoscedasticity: To check if residuals have constant variance across all levels of fitted values.")
[1] "  - Homoscedasticity: To check if residuals have constant variance across all levels of fitted values."

> print("  - p-value > 0.05: Fail to reject null hypothesis (homoscedasticity holds).")
[1] "  - p-value > 0.05: Fail to reject null hypothesis (homoscedasticity holds)."

> print("  - p-value <= 0.05: Reject null hypothesis (heteroscedasticity present).\n")
[1] "  - p-value <= 0.05: Reject null hypothesis (heteroscedasticity present).\n"

> # Extract the model frame from the ssn_lm model
> data_ssn <- model.frame(ssn_mod)

> # Perform Breusch-Pagan Test
> bp_test <- bptest(ssn_mod)

> print("Breusch-Pagan Test Results:")
[1] "Breusch-Pagan Test Results:"

> print(bp_test)

	studentized Breusch-Pagan test

data:  ssn_mod
BP = 53.915, df = 14, p-value = 1.328e-06


> # --------- Moran's I Test for Spatial Autocorrelation ---------
> print("\n-------- Moran's I Test for Spatial Autocorrelation ---------")
[1] "\n-------- Moran's I Test for Spatial Autocorrelation ---------"

> print("  - Spatial Autocorrelation: To determine if there is spatial autocorrelation in the residuals.")
[1] "  - Spatial Autocorrelation: To determine if there is spatial autocorrelation in the residuals."

> print("  - p-value > 0.05: Fail to reject null hypothesis (lack of spatial autocorrelation in residuals holds).")
[1] "  - p-value > 0.05: Fail to reject null hypothesis (lack of spatial autocorrelation in residuals holds)."

> print("  - p-value <= 0.05: Reject null hypothesis (spatial autocorrelation present).\n")
[1] "  - p-value <= 0.05: Reject null hypothesis (spatial autocorrelation present).\n"

> sink()

> # Extract spatial coordinates from the SSN object
> # Ensure that your SSN object has geometry information
> coords <- st_coordinates(ssn_get_data(s .... [TRUNCATED] 

> # Create a spatial weights matrix using k-nearest neighbors (k = 4 as an example)
> knn <- knearneigh(coords, k = 4)

> nb <- knn2nb(knn)

> lw <- nb2listw(nb, style = "W", zero.policy = TRUE)

> # Compute Moran's I
> moran_test <- moran.test(residuals, lw, zero.policy = TRUE)

> sink(output_file, append = TRUE, split = TRUE)

> print("Moran's I Test Results:")
[1] "Moran's I Test Results:"

> print(moran_test)

	Moran I test under randomisation

data:  residuals  
weights: lw    

Moran I statistic standard deviate = -6.569, p-value = 1
alternative hypothesis: greater
sample estimates:
Moran I statistic       Expectation          Variance 
    -0.1795996935     -0.0015527950      0.0007346234 


> # Stop redirecting output
> sink()

> # --------------------------------------------------
> # End of Script
> # --------------------------------------------------
> 
> 
> library(car)

> vif_result <- vif(lm(ch_sfm.erosion.norm ~ 
+                        ch_slope.median +
+                        ch_curvature.median +
+              .... [TRUNCATED] 

> # --------------------------------------------------
> # Spatial Statistical Modeling with SSN2
> # ------------------------------------------------ .... [TRUNCATED] 

> # Define the formula for the ssn_lm function
> # You can modify this formula as needed for different analyses
> model_formula <- as.formula(
+   "ch ..." ... [TRUNCATED] 

> # Specify the input and output directories
> input_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/Inputs"

> output_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/SSN ET/ET Full ws_re"

> model_name <- "glm ch_sfm.erosion.norm VIF 3 100 ct thresh ws_re"

> obs_points_path <- file.path(input_dir, "Combined Watersheds", "ET Full ssn points.gpkg")

> read_ssn <- FALSE # whether to create a new ssn (FALSE) or read the pre-existing ssn (TRUE)

> # Use file.path to create platform-independent file paths
> streams_path <- file.path(input_dir, "streams_100k.gpkg")

> ssn_path <- file.path(output_dir, "1_ET_Full_logtrans_independent_vars.ssn")

> output_file <- file.path(output_dir, model_name, "Results.txt")

> lsn_out <- file.path(output_dir, "0_lsn")

> # Define whether to save graphs and the directory to save them
> save_graphs <- TRUE  # Set to TRUE to save graphs as PNG

> graph_save_dir <- file.path(output_dir, model_name)  # Directory to save graphs

> # ----------------------------#
> # 1. Load Necessary Libraries
> # ----------------------------#
> 
> # Load required libraries
> library(SSN2)

> library(SSNbler)

> library(sf)

> library(dplyr)

> library(purrr)

> library(ggplot2)

> library(lmtest)

> library(spdep)

> library(classInt)   # Required for knearneigh

> library(broom)      # For tidy() and glance() functions

> library(grid)       # For grid.newpage()

> if (!dir.exists(graph_save_dir)) {
+   dir.create(graph_save_dir, recursive = TRUE)
+ }

> # ----------------------------#
> # 2. Read Spatial Data
> # ----------------------------#
> 
> # Read the streams dataset
> ET_streams <- st_read(s .... [TRUNCATED] 
Reading layer `streams_100k' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\streams_100k.gpkg' using driver `GPKG'
Simple feature collection with 643 features and 2 fields
Geometry type: LINESTRING
Dimension:     XY
Bounding box:  xmin: 404042.6 ymin: 4447904 xmax: 414579.6 ymax: 4466669
Projected CRS: NAD83 / UTM zone 13N

> # Read the observation points dataset
> ET_obs <- st_read(obs_points_path)
Reading layer `ET Full ssn points' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\Combined Watersheds\ET Full ssn points.gpkg' using driver `GPKG'
Simple feature collection with 645 features and 60 fields
Geometry type: POINT
Dimension:     XY
Bounding box:  xmin: 407401.1 ymin: 4449827 xmax: 413032.9 ymax: 4464548
Projected CRS: NAD83 / UTM zone 13N

> # Uncomment the following line if you encounter an error about Multilinestrings
> # ET_streams <- st_cast(ET_streams, "LINESTRING")
> 
> # --------- .... [TRUNCATED] 
[1] "Edge Attributes:"
[1] "rid"            "STRM_VAL"       "flow_accum_max" "Length"         "upDist"         "geometry"      
[1] "Site List Components:"
[1] "obs"
[1] "Updated Edge Attributes:"
[1] "rid"            "STRM_VAL"       "flow_accum_max" "Length"         "upDist"         "flow_accum_PI"  "afv_flow_accum" "geometry"      


SSN object is valid: TRUE

> # Create a distance matrix for spatial relationships
> # Purpose: Define spatial dependencies based on distances between sites
> ssn_create_distmat( .... [TRUNCATED] 

> # ----------------------------#
> # 4. Model Fitting and Output
> # ----------------------------#
> 
> # Redirect output to the specified file and a .... [TRUNCATED] 

> model_name
[1] "glm ch_sfm.erosion.norm VIF 3 100 ct thresh ws_re"

> model_formula
ch_sfm.erosion.norm ~ ch_elevation.mean + ch_slope.median + ch_flow.accumulation.max + 
    ch_curvature.median + ch_valley_width + ch_change.in.slope.over.width + 
    ch_channel.width.over.valley.width + ch_slope.over.width.central.diff + 
    ch_stream.power.central.diff + hs_hillslope.length + hs_slope.median + 
    hs_northness.median + hs_eastness.median + hs_curvature.median + 
    hs_bare.earth.mean + hs_ndvi.range + hs_dnbr.median + hs_drainage_density + 
    flow.accumulation.max + (1 | ch_watershed)

> ssn_mod <- ssn_glm(
+   formula = model_formula,
+   ssn.object = ET_ssn,
+   family = "Gamma",
+   tailup_type = "exponential",
+   taildown_type = .... [TRUNCATED] 

> # --------------------------------------------------
> # Spatial Statistical Modeling with SSN2
> # ------------------------------------------------ .... [TRUNCATED] 

> # Define the formula for the ssn_lm function
> # You can modify this formula as needed for different analyses
> model_formula <- as.formula(
+   "ch ..." ... [TRUNCATED] 

> # Specify the input and output directories
> input_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/Inputs"

> output_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/SSN ET/ET Full ws_re"

> model_name <- "glm ch_sfm.erosion.norm VIF 3 100 ct thresh ws_re"

> obs_points_path <- file.path(input_dir, "Combined Watersheds", "ET Full ssn points.gpkg")

> read_ssn <- TRUE # whether to create a new ssn (FALSE) or read the pre-existing ssn (TRUE)

> # Use file.path to create platform-independent file paths
> streams_path <- file.path(input_dir, "streams_100k.gpkg")

> ssn_path <- file.path(output_dir, "1_ET_Full_logtrans_independent_vars.ssn")

> output_file <- file.path(output_dir, model_name, "Results.txt")

> lsn_out <- file.path(output_dir, "0_lsn")

> # Define whether to save graphs and the directory to save them
> save_graphs <- TRUE  # Set to TRUE to save graphs as PNG

> graph_save_dir <- file.path(output_dir, model_name)  # Directory to save graphs

> # ----------------------------#
> # 1. Load Necessary Libraries
> # ----------------------------#
> 
> # Load required libraries
> library(SSN2)

> library(SSNbler)

> library(sf)

> library(dplyr)

> library(purrr)

> library(ggplot2)

> library(lmtest)

> library(spdep)

> library(classInt)   # Required for knearneigh

> library(broom)      # For tidy() and glance() functions

> library(grid)       # For grid.newpage()

> if (!dir.exists(graph_save_dir)) {
+   dir.create(graph_save_dir, recursive = TRUE)
+ }

> # ----------------------------#
> # 2. Read Spatial Data
> # ----------------------------#
> 
> # Read the streams dataset
> ET_streams <- st_read(s .... [TRUNCATED] 
Reading layer `streams_100k' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\streams_100k.gpkg' using driver `GPKG'
Simple feature collection with 643 features and 2 fields
Geometry type: LINESTRING
Dimension:     XY
Bounding box:  xmin: 404042.6 ymin: 4447904 xmax: 414579.6 ymax: 4466669
Projected CRS: NAD83 / UTM zone 13N

> # Read the observation points dataset
> ET_obs <- st_read(obs_points_path)
Reading layer `ET Full ssn points' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\Combined Watersheds\ET Full ssn points.gpkg' using driver `GPKG'
Simple feature collection with 645 features and 60 fields
Geometry type: POINT
Dimension:     XY
Bounding box:  xmin: 407401.1 ymin: 4449827 xmax: 413032.9 ymax: 4464548
Projected CRS: NAD83 / UTM zone 13N

> # Uncomment the following line if you encounter an error about Multilinestrings
> # ET_streams <- st_cast(ET_streams, "LINESTRING")
> 
> # --------- .... [TRUNCATED] 

> # Create a distance matrix for spatial relationships
> # Purpose: Define spatial dependencies based on distances between sites
> ssn_create_distmat( .... [TRUNCATED] 

> # ----------------------------#
> # 4. Model Fitting and Output
> # ----------------------------#
> 
> # Redirect output to the specified file and a .... [TRUNCATED] 

> model_name
[1] "glm ch_sfm.erosion.norm VIF 3 100 ct thresh ws_re"

> model_formula
ch_sfm.erosion.norm ~ ch_elevation.mean + ch_slope.median + ch_flow.accumulation.max + 
    ch_curvature.median + ch_valley_width + ch_change.in.slope.over.width + 
    ch_channel.width.over.valley.width + ch_slope.over.width.central.diff + 
    ch_stream.power.central.diff + hs_hillslope.length + hs_slope.median + 
    hs_northness.median + hs_eastness.median + hs_curvature.median + 
    hs_bare.earth.mean + hs_ndvi.range + hs_dnbr.median + hs_drainage_density + 
    flow.accumulation.max

> ssn_mod <- ssn_glm(
+   formula = model_formula,
+   ssn.object = ET_ssn,
+   family = "Gamma",
+   tailup_type = "exponential",
+   taildown_type = .... [TRUNCATED] 

> # Print the summary of the model to the file and console
> print(summary(ssn_mod))

Call:
ssn_glm(formula = model_formula, ssn.object = ET_ssn, family = "Gamma", 
    tailup_type = "exponential", taildown_type = "none", euclid_type = "gaussian", 
    additive = "afv_flow_accum", random = ~as.factor(ch_watershed))

Deviance Residuals:
    Min      1Q  Median      3Q     Max 
-1.9005 -0.2386 -0.0035  0.1847  1.0111 

Coefficients (fixed):
                                    Estimate Std. Error z value Pr(>|z|)  
(Intercept)                        -2.291130   1.000278  -2.290   0.0220 *
ch_elevation.mean                  -0.797335   0.943026  -0.846   0.3978  
ch_slope.median                     0.154667   0.071046   2.177   0.0295 *
ch_flow.accumulation.max            0.837915   0.754298   1.111   0.2666  
ch_curvature.median                 0.009497   0.066685   0.142   0.8868  
ch_valley_width                    -0.053729   0.075168  -0.715   0.4747  
ch_change.in.slope.over.width      -0.027491   0.017760  -1.548   0.1217  
ch_channel.width.over.valley.width  0.078486   0.075758   1.036   0.3002  
ch_slope.over.width.central.diff    0.045914   0.026656   1.722   0.0850 .
ch_stream.power.central.diff        0.004492   0.017657   0.254   0.7992  
hs_hillslope.length                -0.059319   0.046656  -1.271   0.2036  
hs_slope.median                     0.099233   0.089975   1.103   0.2701  
hs_northness.median                -0.097960   0.066669  -1.469   0.1417  
hs_eastness.median                 -0.015859   0.045612  -0.348   0.7281  
hs_curvature.median                 0.010601   0.030254   0.350   0.7260  
hs_bare.earth.mean                  0.074061   0.067308   1.100   0.2712  
hs_ndvi.range                      -0.056827   0.072440  -0.784   0.4328  
hs_dnbr.median                      0.006861   0.077904   0.088   0.9298  
hs_drainage_density                 3.230809  13.763039   0.235   0.8144  
flow.accumulation.max              -0.123641   0.093758  -1.319   0.1873  
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Pseudo R-squared: 0.02136

Coefficients (covariance):
              Effect                    Parameter   Estimate
  tailup exponential                 de (parsill)  1.540e+00
  tailup exponential                        range  9.958e+01
     euclid gaussian                 de (parsill)  2.340e+00
     euclid gaussian                        range  2.002e+03
              nugget                       nugget  8.270e-03
          dispersion                   dispersion  3.393e+00
              random  1 | as.factor(ch_watershed)  1.793e+00


> # Print variance components of the model
> varcomp(ssn_mod)
# A tibble: 6 × 2
  varcomp                     proportion
  <chr>                            <dbl>
1 Covariates (PR-sq)             0.0214 
2 tailup_de                      0.265  
3 taildown_de                    0      
4 euclid_de                      0.403  
5 nugget                         0.00142
6 1 | as.factor(ch_watershed)    0.309  

> # Tidy the model output with confidence intervals and print
> print(tidy(ssn_mod, conf.int = TRUE))  
# A tibble: 20 × 7
   term                               estimate std.error statistic p.value  conf.low conf.high
   <chr>                                 <dbl>     <dbl>     <dbl>   <dbl>     <dbl>     <dbl>
 1 (Intercept)                        -2.29       1.00     -2.29    0.0220  -4.25     -0.331  
 2 ch_change.in.slope.over.width      -0.0275     0.0178   -1.55    0.122   -0.0623    0.00732
 3 ch_channel.width.over.valley.width  0.0785     0.0758    1.04    0.300   -0.0700    0.227  
 4 ch_curvature.median                 0.00950    0.0667    0.142   0.887   -0.121     0.140  
 5 ch_elevation.mean                  -0.797      0.943    -0.846   0.398   -2.65      1.05   
 6 ch_flow.accumulation.max            0.838      0.754     1.11    0.267   -0.640     2.32   
 7 ch_slope.median                     0.155      0.0710    2.18    0.0295   0.0154    0.294  
 8 ch_slope.over.width.central.diff    0.0459     0.0267    1.72    0.0850  -0.00633   0.0982 
 9 ch_stream.power.central.diff        0.00449    0.0177    0.254   0.799   -0.0301    0.0391 
10 ch_valley_width                    -0.0537     0.0752   -0.715   0.475   -0.201     0.0936 
11 flow.accumulation.max              -0.124      0.0938   -1.32    0.187   -0.307     0.0601 
12 hs_bare.earth.mean                  0.0741     0.0673    1.10    0.271   -0.0579    0.206  
13 hs_curvature.median                 0.0106     0.0303    0.350   0.726   -0.0487    0.0699 
14 hs_dnbr.median                      0.00686    0.0779    0.0881  0.930   -0.146     0.160  
15 hs_drainage_density                 3.23      13.8       0.235   0.814  -23.7      30.2    
16 hs_eastness.median                 -0.0159     0.0456   -0.348   0.728   -0.105     0.0735 
17 hs_hillslope.length                -0.0593     0.0467   -1.27    0.204   -0.151     0.0321 
18 hs_ndvi.range                      -0.0568     0.0724   -0.784   0.433   -0.199     0.0852 
19 hs_northness.median                -0.0980     0.0667   -1.47    0.142   -0.229     0.0327 
20 hs_slope.median                     0.0992     0.0900    1.10    0.270   -0.0771    0.276  

> # Provide a glance summary of the model and print
> print(glance(ssn_mod))
# A tibble: 1 × 9
      n     p  npar value   AIC  AICc logLik deviance pseudo.r.squared
  <int> <dbl> <int> <dbl> <dbl> <dbl>  <dbl>    <dbl>            <dbl>
1   645    20     7 1013. 1027. 1028.  -507.     102.           0.0214

> # Perform Leave-One-Out Cross Validation and print
> print("Leave One Out Cross Validation")
[1] "Leave One Out Cross Validation"

> loocv_results <- loocv(ssn_mod)

> print(loocv_results)
# A tibble: 1 × 4
     bias  MSPE RMSPE   RAV
    <dbl> <dbl> <dbl> <dbl>
1 -0.0702 0.162 0.402 0.546

> # Stop redirecting output
> sink()

> # ----------------------------#
> # 5. Model Evaluation
> # ----------------------------#
> 
> # Extract residuals and fitted values from the model
 .... [TRUNCATED] 

> fitted_values <- fitted(ssn_mod)   

> # ----------------------------#
> # 6. Plotting and Saving Graphs
> # ----------------------------#
> 
> 
> # Create the graph save directory if sav .... [TRUNCATED] 

> # ----------------------------#
> # 7. Residuals vs Fitted Values Plot
> # ----------------------------#
> 
> # Purpose:
> #   - Linearity: Ensure t .... [TRUNCATED] 

> # Create the Residuals vs Fitted Values plot
> resid_fitted_plot <- ggplot(data.frame(Fitted = fitted_values, Residuals = residuals), aes(x = Fitted .... [TRUNCATED] 

> # Display the plot
> print(resid_fitted_plot)

> # Save the plot if saving is enabled
> if (save_graphs) {
+   ggsave(filename = file.path(graph_save_dir, "Residuals_vs_Fitted.png"), plot = resid_f .... [TRUNCATED] 
[1] "Saved Residuals vs Fitted Values plot."

> # ----------------------------#
> # 8. Q-Q Plot for Residuals
> # ----------------------------#
> 
> # Purpose:
> #   - Normality: Verify that resid .... [TRUNCATED] 

> # Enhanced Q-Q Plot using ggplot2
> qq_plot <- ggplot(data.frame(Residuals = residuals), aes(sample = Residuals)) +
+   stat_qq(color = "blue") +
+  .... [TRUNCATED] 

> # Display the ggplot2 Q-Q plot
> print(qq_plot)

> # Save the ggplot2 Q-Q plot if saving is enabled
> if (save_graphs) {
+   ggsave(filename = file.path(graph_save_dir, "QQ_Plot_Residuals_GGPlot2.png ..." ... [TRUNCATED] 
[1] "Saved ggplot2 Q-Q Plot of Residuals."

> # ----------------------------#
> # 9. Histogram of Residuals
> # ----------------------------#
> 
> # Purpose:
> #   - Normality
> #
> # What to Lo .... [TRUNCATED] 

> # Enhanced Histogram using ggplot2
> hist_plot <- ggplot(data.frame(Residuals = residuals), aes(x = Residuals)) +
+   geom_histogram(aes(y = ..densi .... [TRUNCATED] 

> # Display the ggplot2 histogram
> print(hist_plot)

> # Save the ggplot2 histogram if saving is enabled
> if (save_graphs) {
+   ggsave(filename = file.path(graph_save_dir, "Histogram_Residuals_GGPlot2. ..." ... [TRUNCATED] 
[1] "Saved ggplot2 Histogram of Residuals with Normal Curve."

> # Redirect output to the specified file and also print to console
> sink(output_file, append = TRUE, split = TRUE)

> print("")
[1] ""

> # ----------------------------#
> # 10. Statistical Tests
> # ----------------------------#
> 
> 
> # --------- Shapiro-Wilk Test for Normality ---- .... [TRUNCATED] 
[1] "-------- Shapiro-Wilk Test for Normality ---------"

> print("  - Normality: To check if the residuals are normally distributed.")
[1] "  - Normality: To check if the residuals are normally distributed."

> print("  - p-value > 0.05: Fail to reject null hypothesis (residuals are normally distributed).")
[1] "  - p-value > 0.05: Fail to reject null hypothesis (residuals are normally distributed)."

> print("  - p-value <= 0.05: Reject null hypothesis (residuals are not normally distributed).\n")
[1] "  - p-value <= 0.05: Reject null hypothesis (residuals are not normally distributed).\n"

> shapiro_test <- shapiro.test(residuals)

> print("Shapiro-Wilk Test Results:")
[1] "Shapiro-Wilk Test Results:"

> print(shapiro_test)

	Shapiro-Wilk normality test

data:  residuals
W = 0.96785, p-value = 1.094e-10


> # --------- Breusch-Pagan Test for Homoscedasticity ---------
> print("-------- Breusch-Pagan Test for Homoscedasticity ---------")
[1] "-------- Breusch-Pagan Test for Homoscedasticity ---------"

> print("  - Homoscedasticity: To check if residuals have constant variance across all levels of fitted values.")
[1] "  - Homoscedasticity: To check if residuals have constant variance across all levels of fitted values."

> print("  - p-value > 0.05: Fail to reject null hypothesis (homoscedasticity holds).")
[1] "  - p-value > 0.05: Fail to reject null hypothesis (homoscedasticity holds)."

> print("  - p-value <= 0.05: Reject null hypothesis (heteroscedasticity present).\n")
[1] "  - p-value <= 0.05: Reject null hypothesis (heteroscedasticity present).\n"

> # Extract the model frame from the ssn_lm model
> data_ssn <- model.frame(ssn_mod)

> # Perform Breusch-Pagan Test
> bp_test <- bptest(ssn_mod)

> print("Breusch-Pagan Test Results:")
[1] "Breusch-Pagan Test Results:"

> print(bp_test)

	studentized Breusch-Pagan test

data:  ssn_mod
BP = 75.814, df = 19, p-value = 9.683e-09


> # --------- Moran's I Test for Spatial Autocorrelation ---------
> print("\n-------- Moran's I Test for Spatial Autocorrelation ---------")
[1] "\n-------- Moran's I Test for Spatial Autocorrelation ---------"

> print("  - Spatial Autocorrelation: To determine if there is spatial autocorrelation in the residuals.")
[1] "  - Spatial Autocorrelation: To determine if there is spatial autocorrelation in the residuals."

> print("  - p-value > 0.05: Fail to reject null hypothesis (lack of spatial autocorrelation in residuals holds).")
[1] "  - p-value > 0.05: Fail to reject null hypothesis (lack of spatial autocorrelation in residuals holds)."

> print("  - p-value <= 0.05: Reject null hypothesis (spatial autocorrelation present).\n")
[1] "  - p-value <= 0.05: Reject null hypothesis (spatial autocorrelation present).\n"

> sink()

> # Extract spatial coordinates from the SSN object
> # Ensure that your SSN object has geometry information
> coords <- st_coordinates(ssn_get_data(s .... [TRUNCATED] 

> # Create a spatial weights matrix using k-nearest neighbors (k = 4 as an example)
> knn <- knearneigh(coords, k = 4)

> nb <- knn2nb(knn)

> lw <- nb2listw(nb, style = "W", zero.policy = TRUE)

> # Compute Moran's I
> moran_test <- moran.test(residuals, lw, zero.policy = TRUE)

> sink(output_file, append = TRUE, split = TRUE)

> print("Moran's I Test Results:")
[1] "Moran's I Test Results:"

> print(moran_test)

	Moran I test under randomisation

data:  residuals  
weights: lw    

Moran I statistic standard deviate = -7.2671, p-value = 1
alternative hypothesis: greater
sample estimates:
Moran I statistic       Expectation          Variance 
     -0.198457287      -0.001552795       0.000734155 


> # Stop redirecting output
> sink()

> # --------------------------------------------------
> # End of Script
> # --------------------------------------------------
> 
> 
> library(car)

> vif_result <- vif(lm(ch_sfm.erosion.norm ~ 
+                        ch_slope.median +
+                        ch_curvature.median +
+              .... [TRUNCATED] 

> # --------------------------------------------------
> # Spatial Statistical Modeling with SSN2
> # ------------------------------------------------ .... [TRUNCATED] 

> # Define the formula for the ssn_lm function
> # You can modify this formula as needed for different analyses
> model_formula <- as.formula(
+   "ch ..." ... [TRUNCATED] 

> # Specify the input and output directories
> input_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/Inputs"

> output_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/SSN ET/ET Full ws_re"

> model_name <- "glm ch_sfm.erosion.norm VIF 3 100 ct thresh ws_re"

> obs_points_path <- file.path(input_dir, "Combined Watersheds", "ET Full ssn points.gpkg")

> read_ssn <- TRUE # whether to create a new ssn (FALSE) or read the pre-existing ssn (TRUE)

> # Use file.path to create platform-independent file paths
> streams_path <- file.path(input_dir, "streams_100k.gpkg")

> ssn_path <- file.path(output_dir, "1_ET_Full_logtrans_independent_vars.ssn")

> output_file <- file.path(output_dir, model_name, "Results.txt")

> lsn_out <- file.path(output_dir, "0_lsn")

> # Define whether to save graphs and the directory to save them
> save_graphs <- TRUE  # Set to TRUE to save graphs as PNG

> graph_save_dir <- file.path(output_dir, model_name)  # Directory to save graphs

> # ----------------------------#
> # 1. Load Necessary Libraries
> # ----------------------------#
> 
> # Load required libraries
> library(SSN2)

> library(SSNbler)

> library(sf)

> library(dplyr)

> library(purrr)

> library(ggplot2)

> library(lmtest)

> library(spdep)

> library(classInt)   # Required for knearneigh

> library(broom)      # For tidy() and glance() functions

> library(grid)       # For grid.newpage()

> if (!dir.exists(graph_save_dir)) {
+   dir.create(graph_save_dir, recursive = TRUE)
+ }

> # ----------------------------#
> # 2. Read Spatial Data
> # ----------------------------#
> 
> # Read the streams dataset
> ET_streams <- st_read(s .... [TRUNCATED] 
Reading layer `streams_100k' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\streams_100k.gpkg' using driver `GPKG'
Simple feature collection with 643 features and 2 fields
Geometry type: LINESTRING
Dimension:     XY
Bounding box:  xmin: 404042.6 ymin: 4447904 xmax: 414579.6 ymax: 4466669
Projected CRS: NAD83 / UTM zone 13N

> # Read the observation points dataset
> ET_obs <- st_read(obs_points_path)
Reading layer `ET Full ssn points' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\Combined Watersheds\ET Full ssn points.gpkg' using driver `GPKG'
Simple feature collection with 645 features and 60 fields
Geometry type: POINT
Dimension:     XY
Bounding box:  xmin: 407401.1 ymin: 4449827 xmax: 413032.9 ymax: 4464548
Projected CRS: NAD83 / UTM zone 13N

> # Uncomment the following line if you encounter an error about Multilinestrings
> # ET_streams <- st_cast(ET_streams, "LINESTRING")
> 
> # --------- .... [TRUNCATED] 

> # Create a distance matrix for spatial relationships
> # Purpose: Define spatial dependencies based on distances between sites
> ssn_create_distmat( .... [TRUNCATED] 

> # ----------------------------#
> # 4. Model Fitting and Output
> # ----------------------------#
> 
> # Redirect output to the specified file and a .... [TRUNCATED] 

> model_name
[1] "glm ch_sfm.erosion.norm VIF 3 100 ct thresh ws_re"

> model_formula
ch_sfm.erosion.norm ~ ws_flow.accum.max + ws_slope.mean + ws_bare.earth.mean + 
    ws_drainage_density + ws_RV.Sand + ch_slope.median + ch_curvature.median + 
    ch_valley_width + ch_change.in.slope.over.width + ch_channel.width.over.valley.width + 
    ch_slope.over.width.central.diff + ch_stream.power.central.diff + 
    hs_hillslope.length + hs_slope.median + hs_northness.median + 
    hs_eastness.median + hs_curvature.median + hs_bare.earth.mean + 
    hs_ndvi.range + hs_dnbr.median + hs_drainage_density + flow.accumulation.max

> ssn_mod <- ssn_glm(
+   formula = model_formula,
+   ssn.object = ET_ssn,
+   family = "Gamma",
+   tailup_type = "exponential",
+   taildown_type = .... [TRUNCATED] 

> # Print the summary of the model to the file and console
> print(summary(ssn_mod))

Call:
ssn_glm(formula = model_formula, ssn.object = ET_ssn, family = "Gamma", 
    tailup_type = "exponential", taildown_type = "none", euclid_type = "gaussian", 
    additive = "afv_flow_accum", random = ~as.factor(ch_watershed))

Deviance Residuals:
      Min        1Q    Median        3Q       Max 
-1.899096 -0.244484  0.005467  0.190863  1.013314 

Coefficients (fixed):
                                     Estimate Std. Error z value Pr(>|z|)    
(Intercept)                        -1.9686360  0.8984917  -2.191   0.0284 *  
ws_flow.accum.max                  -0.4236557  0.2325182  -1.822   0.0685 .  
ws_slope.mean                       1.1187663  0.2768520   4.041 5.32e-05 ***
ws_bare.earth.mean                 -0.2392941  0.1509909  -1.585   0.1130    
ws_drainage_density                 0.0383747  0.0194197   1.976   0.0481 *  
ws_RV.Sand                         -0.4079859  0.4034231  -1.011   0.3119    
ch_slope.median                     0.1481487  0.0706427   2.097   0.0360 *  
ch_curvature.median                 0.0008038  0.0666369   0.012   0.9904    
ch_valley_width                    -0.0488746  0.0746302  -0.655   0.5125    
ch_change.in.slope.over.width      -0.0271306  0.0178150  -1.523   0.1278    
ch_channel.width.over.valley.width  0.0736065  0.0756281   0.973   0.3304    
ch_slope.over.width.central.diff    0.0457687  0.0266721   1.716   0.0862 .  
ch_stream.power.central.diff        0.0053541  0.0176862   0.303   0.7621    
hs_hillslope.length                -0.0551840  0.0466631  -1.183   0.2370    
hs_slope.median                     0.0838467  0.0900029   0.932   0.3515    
hs_northness.median                -0.1063774  0.0667991  -1.592   0.1113    
hs_eastness.median                 -0.0179435  0.0455613  -0.394   0.6937    
hs_curvature.median                 0.0109864  0.0303161   0.362   0.7171    
hs_bare.earth.mean                  0.0871841  0.0677662   1.287   0.1983    
hs_ndvi.range                      -0.0358530  0.0722844  -0.496   0.6199    
hs_dnbr.median                      0.0227799  0.0780155   0.292   0.7703    
hs_drainage_density                 0.4510822 13.7896864   0.033   0.9739    
flow.accumulation.max              -0.1191132  0.0745331  -1.598   0.1100    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Pseudo R-squared: 0.03917

Coefficients (covariance):
              Effect                    Parameter   Estimate
  tailup exponential                 de (parsill)  1.417e+00
  tailup exponential                        range  8.651e+01
     euclid gaussian                 de (parsill)  1.813e+00
     euclid gaussian                        range  5.405e+03
              nugget                       nugget  1.308e-03
          dispersion                   dispersion  3.411e+00
              random  1 | as.factor(ch_watershed)  3.019e-01


> # Print variance components of the model
> varcomp(ssn_mod)
# A tibble: 6 × 2
  varcomp                     proportion
  <chr>                            <dbl>
1 Covariates (PR-sq)            0.0392  
2 tailup_de                     0.385   
3 taildown_de                   0       
4 euclid_de                     0.493   
5 nugget                        0.000356
6 1 | as.factor(ch_watershed)   0.0821  

> # Tidy the model output with confidence intervals and print
> print(tidy(ssn_mod, conf.int = TRUE))  
# A tibble: 23 × 7
   term                                estimate std.error statistic p.value conf.low conf.high
   <chr>                                  <dbl>     <dbl>     <dbl>   <dbl>    <dbl>     <dbl>
 1 (Intercept)                        -1.97        0.898    -2.19    0.0284 -3.73     -0.208  
 2 ch_change.in.slope.over.width      -0.0271      0.0178   -1.52    0.128  -0.0620    0.00779
 3 ch_channel.width.over.valley.width  0.0736      0.0756    0.973   0.330  -0.0746    0.222  
 4 ch_curvature.median                 0.000804    0.0666    0.0121  0.990  -0.130     0.131  
 5 ch_slope.median                     0.148       0.0706    2.10    0.0360  0.00969   0.287  
 6 ch_slope.over.width.central.diff    0.0458      0.0267    1.72    0.0862 -0.00651   0.0980 
 7 ch_stream.power.central.diff        0.00535     0.0177    0.303   0.762  -0.0293    0.0400 
 8 ch_valley_width                    -0.0489      0.0746   -0.655   0.513  -0.195     0.0974 
 9 flow.accumulation.max              -0.119       0.0745   -1.60    0.110  -0.265     0.0270 
10 hs_bare.earth.mean                  0.0872      0.0678    1.29    0.198  -0.0456    0.220  
# ℹ 13 more rows
# ℹ Use `print(n = ...)` to see more rows

> # Provide a glance summary of the model and print
> print(glance(ssn_mod))
# A tibble: 1 × 9
      n     p  npar value   AIC  AICc logLik deviance pseudo.r.squared
  <int> <dbl> <int> <dbl> <dbl> <dbl>  <dbl>    <dbl>            <dbl>
1   645    23     7 1013. 1027. 1027.  -506.     99.1           0.0392

> # Perform Leave-One-Out Cross Validation and print
> print("Leave One Out Cross Validation")
[1] "Leave One Out Cross Validation"

> loocv_results <- loocv(ssn_mod)

> print(loocv_results)
# A tibble: 1 × 4
     bias  MSPE RMSPE   RAV
    <dbl> <dbl> <dbl> <dbl>
1 -0.0753 0.163 0.403 0.768

> # Stop redirecting output
> sink()

> # ----------------------------#
> # 5. Model Evaluation
> # ----------------------------#
> 
> # Extract residuals and fitted values from the model
 .... [TRUNCATED] 

> fitted_values <- fitted(ssn_mod)   

> # ----------------------------#
> # 6. Plotting and Saving Graphs
> # ----------------------------#
> 
> 
> # Create the graph save directory if sav .... [TRUNCATED] 

> # ----------------------------#
> # 7. Residuals vs Fitted Values Plot
> # ----------------------------#
> 
> # Purpose:
> #   - Linearity: Ensure t .... [TRUNCATED] 

> # Create the Residuals vs Fitted Values plot
> resid_fitted_plot <- ggplot(data.frame(Fitted = fitted_values, Residuals = residuals), aes(x = Fitted .... [TRUNCATED] 

> # Display the plot
> print(resid_fitted_plot)

> # Save the plot if saving is enabled
> if (save_graphs) {
+   ggsave(filename = file.path(graph_save_dir, "Residuals_vs_Fitted.png"), plot = resid_f .... [TRUNCATED] 
[1] "Saved Residuals vs Fitted Values plot."

> # ----------------------------#
> # 8. Q-Q Plot for Residuals
> # ----------------------------#
> 
> # Purpose:
> #   - Normality: Verify that resid .... [TRUNCATED] 

> # Enhanced Q-Q Plot using ggplot2
> qq_plot <- ggplot(data.frame(Residuals = residuals), aes(sample = Residuals)) +
+   stat_qq(color = "blue") +
+  .... [TRUNCATED] 

> # Display the ggplot2 Q-Q plot
> print(qq_plot)

> # Save the ggplot2 Q-Q plot if saving is enabled
> if (save_graphs) {
+   ggsave(filename = file.path(graph_save_dir, "QQ_Plot_Residuals_GGPlot2.png ..." ... [TRUNCATED] 
[1] "Saved ggplot2 Q-Q Plot of Residuals."

> # ----------------------------#
> # 9. Histogram of Residuals
> # ----------------------------#
> 
> # Purpose:
> #   - Normality
> #
> # What to Lo .... [TRUNCATED] 

> # Enhanced Histogram using ggplot2
> hist_plot <- ggplot(data.frame(Residuals = residuals), aes(x = Residuals)) +
+   geom_histogram(aes(y = ..densi .... [TRUNCATED] 

> # Display the ggplot2 histogram
> print(hist_plot)

> # Save the ggplot2 histogram if saving is enabled
> if (save_graphs) {
+   ggsave(filename = file.path(graph_save_dir, "Histogram_Residuals_GGPlot2. ..." ... [TRUNCATED] 
[1] "Saved ggplot2 Histogram of Residuals with Normal Curve."

> # Redirect output to the specified file and also print to console
> sink(output_file, append = TRUE, split = TRUE)

> print("")
[1] ""

> # ----------------------------#
> # 10. Statistical Tests
> # ----------------------------#
> 
> 
> # --------- Shapiro-Wilk Test for Normality ---- .... [TRUNCATED] 
[1] "-------- Shapiro-Wilk Test for Normality ---------"

> print("  - Normality: To check if the residuals are normally distributed.")
[1] "  - Normality: To check if the residuals are normally distributed."

> print("  - p-value > 0.05: Fail to reject null hypothesis (residuals are normally distributed).")
[1] "  - p-value > 0.05: Fail to reject null hypothesis (residuals are normally distributed)."

> print("  - p-value <= 0.05: Reject null hypothesis (residuals are not normally distributed).\n")
[1] "  - p-value <= 0.05: Reject null hypothesis (residuals are not normally distributed).\n"

> shapiro_test <- shapiro.test(residuals)

> print("Shapiro-Wilk Test Results:")
[1] "Shapiro-Wilk Test Results:"

> print(shapiro_test)

	Shapiro-Wilk normality test

data:  residuals
W = 0.96702, p-value = 7.299e-11


> # --------- Breusch-Pagan Test for Homoscedasticity ---------
> print("-------- Breusch-Pagan Test for Homoscedasticity ---------")
[1] "-------- Breusch-Pagan Test for Homoscedasticity ---------"

> print("  - Homoscedasticity: To check if residuals have constant variance across all levels of fitted values.")
[1] "  - Homoscedasticity: To check if residuals have constant variance across all levels of fitted values."

> print("  - p-value > 0.05: Fail to reject null hypothesis (homoscedasticity holds).")
[1] "  - p-value > 0.05: Fail to reject null hypothesis (homoscedasticity holds)."

> print("  - p-value <= 0.05: Reject null hypothesis (heteroscedasticity present).\n")
[1] "  - p-value <= 0.05: Reject null hypothesis (heteroscedasticity present).\n"

> # Extract the model frame from the ssn_lm model
> data_ssn <- model.frame(ssn_mod)

> # Perform Breusch-Pagan Test
> bp_test <- bptest(ssn_mod)

> print("Breusch-Pagan Test Results:")
[1] "Breusch-Pagan Test Results:"

> print(bp_test)

	studentized Breusch-Pagan test

data:  ssn_mod
BP = 59.412, df = 22, p-value = 2.729e-05


> # --------- Moran's I Test for Spatial Autocorrelation ---------
> print("\n-------- Moran's I Test for Spatial Autocorrelation ---------")
[1] "\n-------- Moran's I Test for Spatial Autocorrelation ---------"

> print("  - Spatial Autocorrelation: To determine if there is spatial autocorrelation in the residuals.")
[1] "  - Spatial Autocorrelation: To determine if there is spatial autocorrelation in the residuals."

> print("  - p-value > 0.05: Fail to reject null hypothesis (lack of spatial autocorrelation in residuals holds).")
[1] "  - p-value > 0.05: Fail to reject null hypothesis (lack of spatial autocorrelation in residuals holds)."

> print("  - p-value <= 0.05: Reject null hypothesis (spatial autocorrelation present).\n")
[1] "  - p-value <= 0.05: Reject null hypothesis (spatial autocorrelation present).\n"

> sink()

> # Extract spatial coordinates from the SSN object
> # Ensure that your SSN object has geometry information
> coords <- st_coordinates(ssn_get_data(s .... [TRUNCATED] 

> # Create a spatial weights matrix using k-nearest neighbors (k = 4 as an example)
> knn <- knearneigh(coords, k = 4)

> nb <- knn2nb(knn)

> lw <- nb2listw(nb, style = "W", zero.policy = TRUE)

> # Compute Moran's I
> moran_test <- moran.test(residuals, lw, zero.policy = TRUE)

> sink(output_file, append = TRUE, split = TRUE)

> print("Moran's I Test Results:")
[1] "Moran's I Test Results:"

> print(moran_test)

	Moran I test under randomisation

data:  residuals  
weights: lw    

Moran I statistic standard deviate = -7.2445, p-value = 1
alternative hypothesis: greater
sample estimates:
Moran I statistic       Expectation          Variance 
    -0.1978360659     -0.0015527950      0.0007340926 


> # Stop redirecting output
> sink()

> # --------------------------------------------------
> # End of Script
> # --------------------------------------------------
> 
> 

> # --------------------------------------------------
> # Spatial Statistical Modeling with SSN2
> # ------------------------------------------------ .... [TRUNCATED] 

> # Define the formula for the ssn_lm function
> # You can modify this formula as needed for different analyses
> model_formula <- as.formula(
+   "ch ..." ... [TRUNCATED] 

> # Specify the input and output directories
> input_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/Inputs"

> output_dir <- "Y:/ATD/GIS/ETF/Watershed Stats/SSN2/SSN ET/ET Full ws_re"

> model_name <- "glm ch_sfm.erosion.norm VIF 2 100 ct thresh ws_re"

> obs_points_path <- file.path(input_dir, "Combined Watersheds", "ET Full ssn points.gpkg")

> read_ssn <- TRUE # whether to create a new ssn (FALSE) or read the pre-existing ssn (TRUE)

> # Use file.path to create platform-independent file paths
> streams_path <- file.path(input_dir, "streams_100k.gpkg")

> ssn_path <- file.path(output_dir, "1_ET_Full_logtrans_independent_vars.ssn")

> output_file <- file.path(output_dir, model_name, "Results.txt")

> lsn_out <- file.path(output_dir, "0_lsn")

> # Define whether to save graphs and the directory to save them
> save_graphs <- TRUE  # Set to TRUE to save graphs as PNG

> graph_save_dir <- file.path(output_dir, model_name)  # Directory to save graphs

> # ----------------------------#
> # 1. Load Necessary Libraries
> # ----------------------------#
> 
> # Load required libraries
> library(SSN2)

> library(SSNbler)

> library(sf)

> library(dplyr)

> library(purrr)

> library(ggplot2)

> library(lmtest)

> library(spdep)

> library(classInt)   # Required for knearneigh

> library(broom)      # For tidy() and glance() functions

> library(grid)       # For grid.newpage()

> if (!dir.exists(graph_save_dir)) {
+   dir.create(graph_save_dir, recursive = TRUE)
+ }

> # ----------------------------#
> # 2. Read Spatial Data
> # ----------------------------#
> 
> # Read the streams dataset
> ET_streams <- st_read(s .... [TRUNCATED] 
Reading layer `streams_100k' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\streams_100k.gpkg' using driver `GPKG'
Simple feature collection with 643 features and 2 fields
Geometry type: LINESTRING
Dimension:     XY
Bounding box:  xmin: 404042.6 ymin: 4447904 xmax: 414579.6 ymax: 4466669
Projected CRS: NAD83 / UTM zone 13N

> # Read the observation points dataset
> ET_obs <- st_read(obs_points_path)
Reading layer `ET Full ssn points' from data source `Y:\ATD\GIS\ETF\Watershed Stats\SSN2\Inputs\Combined Watersheds\ET Full ssn points.gpkg' using driver `GPKG'
Simple feature collection with 645 features and 60 fields
Geometry type: POINT
Dimension:     XY
Bounding box:  xmin: 407401.1 ymin: 4449827 xmax: 413032.9 ymax: 4464548
Projected CRS: NAD83 / UTM zone 13N

> # Uncomment the following line if you encounter an error about Multilinestrings
> # ET_streams <- st_cast(ET_streams, "LINESTRING")
> 
> # --------- .... [TRUNCATED] 

> # Create a distance matrix for spatial relationships
> # Purpose: Define spatial dependencies based on distances between sites
> ssn_create_distmat( .... [TRUNCATED] 

> # ----------------------------#
> # 4. Model Fitting and Output
> # ----------------------------#
> 
> # Redirect output to the specified file and a .... [TRUNCATED] 

> model_name
[1] "glm ch_sfm.erosion.norm VIF 2 100 ct thresh ws_re"

> model_formula
ch_sfm.erosion.norm ~ ws_flow.accum.max + ws_slope.mean + ws_bare.earth.mean + 
    ws_drainage_density + ws_RV.Sand + ch_curvature.median + 
    ch_valley_width + ch_change.in.slope.over.width + ch_channel.width.over.valley.width + 
    ch_stream.power.central.diff + hs_hillslope.length + hs_slope.median + 
    hs_northness.median + hs_eastness.median + hs_curvature.median + 
    hs_ndvi.range + hs_dnbr.median + hs_drainage_density + flow.accumulation.max

> ssn_mod <- ssn_glm(
+   formula = model_formula,
+   ssn.object = ET_ssn,
+   family = "Gamma",
+   tailup_type = "exponential",
+   taildown_type = .... [TRUNCATED] 

> # Print the summary of the model to the file and console
> print(summary(ssn_mod))

Call:
ssn_glm(formula = model_formula, ssn.object = ET_ssn, family = "Gamma", 
    tailup_type = "exponential", taildown_type = "none", euclid_type = "gaussian", 
    additive = "afv_flow_accum", random = ~as.factor(ch_watershed))

Deviance Residuals:
       Min         1Q     Median         3Q        Max 
-1.8782655 -0.2339728 -0.0003834  0.1816483  0.9904105 

Coefficients (fixed):
                                    Estimate Std. Error z value Pr(>|z|)    
(Intercept)                        -1.949913   0.714828  -2.728  0.00638 ** 
ws_flow.accum.max                  -0.404024   0.228735  -1.766  0.07734 .  
ws_slope.mean                       1.139317   0.257134   4.431 9.39e-06 ***
ws_bare.earth.mean                 -0.227948   0.149620  -1.524  0.12763    
ws_drainage_density                 0.038633   0.018219   2.120  0.03396 *  
ws_RV.Sand                         -0.297464   0.379620  -0.784  0.43329    
ch_curvature.median                -0.008997   0.065960  -0.136  0.89150    
ch_valley_width                    -0.049524   0.074984  -0.660  0.50896    
ch_change.in.slope.over.width      -0.018392   0.017042  -1.079  0.28049    
ch_channel.width.over.valley.width  0.050237   0.075984   0.661  0.50851    
ch_stream.power.central.diff        0.024825   0.013866   1.790  0.07340 .  
hs_hillslope.length                -0.045256   0.045787  -0.988  0.32296    
hs_slope.median                     0.073010   0.089769   0.813  0.41604    
hs_northness.median                -0.128885   0.066777  -1.930  0.05360 .  
hs_eastness.median                 -0.020493   0.045418  -0.451  0.65184    
hs_curvature.median                 0.011279   0.030421   0.371  0.71080    
hs_ndvi.range                      -0.082624   0.065184  -1.268  0.20496    
hs_dnbr.median                      0.026938   0.078471   0.343  0.73138    
hs_drainage_density                 1.009103  13.868616   0.073  0.94200    
flow.accumulation.max              -0.141148   0.077038  -1.832  0.06692 .  
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Pseudo R-squared: 0.03101

Coefficients (covariance):
              Effect                    Parameter   Estimate
  tailup exponential                 de (parsill)  1.494e+00
  tailup exponential                        range  8.519e+01
     euclid gaussian                 de (parsill)  1.352e+00
     euclid gaussian                        range  3.729e+03
              nugget                       nugget  6.909e-04
          dispersion                   dispersion  3.482e+00
              random  1 | as.factor(ch_watershed)  1.759e-01


> # Print variance components of the model
> varcomp(ssn_mod)
# A tibble: 6 × 2
  varcomp                     proportion
  <chr>                            <dbl>
1 Covariates (PR-sq)            0.0310  
2 tailup_de                     0.479   
3 taildown_de                   0       
4 euclid_de                     0.433   
5 nugget                        0.000221
6 1 | as.factor(ch_watershed)   0.0564  

> # Tidy the model output with confidence intervals and print
> print(tidy(ssn_mod, conf.int = TRUE))  
# A tibble: 20 × 7
   term                               estimate std.error statistic    p.value  conf.low conf.high
   <chr>                                 <dbl>     <dbl>     <dbl>      <dbl>     <dbl>     <dbl>
 1 (Intercept)                        -1.95       0.715    -2.73   0.00638     -3.35     -0.549  
 2 ch_change.in.slope.over.width      -0.0184     0.0170   -1.08   0.280       -0.0518    0.0150 
 3 ch_channel.width.over.valley.width  0.0502     0.0760    0.661  0.509       -0.0987    0.199  
 4 ch_curvature.median                -0.00900    0.0660   -0.136  0.891       -0.138     0.120  
 5 ch_stream.power.central.diff        0.0248     0.0139    1.79   0.0734      -0.00235   0.0520 
 6 ch_valley_width                    -0.0495     0.0750   -0.660  0.509       -0.196     0.0974 
 7 flow.accumulation.max              -0.141      0.0770   -1.83   0.0669      -0.292     0.00984
 8 hs_curvature.median                 0.0113     0.0304    0.371  0.711       -0.0483    0.0709 
 9 hs_dnbr.median                      0.0269     0.0785    0.343  0.731       -0.127     0.181  
10 hs_drainage_density                 1.01      13.9       0.0728 0.942      -26.2      28.2    
11 hs_eastness.median                 -0.0205     0.0454   -0.451  0.652       -0.110     0.0685 
12 hs_hillslope.length                -0.0453     0.0458   -0.988  0.323       -0.135     0.0445 
13 hs_ndvi.range                      -0.0826     0.0652   -1.27   0.205       -0.210     0.0451 
14 hs_northness.median                -0.129      0.0668   -1.93   0.0536      -0.260     0.00200
15 hs_slope.median                     0.0730     0.0898    0.813  0.416       -0.103     0.249  
16 ws_bare.earth.mean                 -0.228      0.150    -1.52   0.128       -0.521     0.0653 
17 ws_drainage_density                 0.0386     0.0182    2.12   0.0340       0.00292   0.0743 
18 ws_flow.accum.max                  -0.404      0.229    -1.77   0.0773      -0.852     0.0443 
19 ws_RV.Sand                         -0.297      0.380    -0.784  0.433       -1.04      0.447  
20 ws_slope.mean                       1.14       0.257     4.43   0.00000939   0.635     1.64   

> # Provide a glance summary of the model and print
> print(glance(ssn_mod))
# A tibble: 1 × 9
      n     p  npar value   AIC  AICc logLik deviance pseudo.r.squared
  <int> <dbl> <int> <dbl> <dbl> <dbl>  <dbl>    <dbl>            <dbl>
1   645    20     7 1009. 1023. 1023.  -504.     94.0           0.0310

> # Perform Leave-One-Out Cross Validation and print
> print("Leave One Out Cross Validation")
[1] "Leave One Out Cross Validation"

> loocv_results <- loocv(ssn_mod)

> print(loocv_results)
# A tibble: 1 × 4
     bias  MSPE RMSPE   RAV
    <dbl> <dbl> <dbl> <dbl>
1 -0.0768 0.163 0.404 0.727

> # Stop redirecting output
> sink()

> # ----------------------------#
> # 5. Model Evaluation
> # ----------------------------#
> 
> # Extract residuals and fitted values from the model
 .... [TRUNCATED] 

> fitted_values <- fitted(ssn_mod)   

> # ----------------------------#
> # 6. Plotting and Saving Graphs
> # ----------------------------#
> 
> 
> # Create the graph save directory if sav .... [TRUNCATED] 

> # ----------------------------#
> # 7. Residuals vs Fitted Values Plot
> # ----------------------------#
> 
> # Purpose:
> #   - Linearity: Ensure t .... [TRUNCATED] 

> # Create the Residuals vs Fitted Values plot
> resid_fitted_plot <- ggplot(data.frame(Fitted = fitted_values, Residuals = residuals), aes(x = Fitted .... [TRUNCATED] 

> # Display the plot
> print(resid_fitted_plot)

> # Save the plot if saving is enabled
> if (save_graphs) {
+   ggsave(filename = file.path(graph_save_dir, "Residuals_vs_Fitted.png"), plot = resid_f .... [TRUNCATED] 
[1] "Saved Residuals vs Fitted Values plot."

> # ----------------------------#
> # 8. Q-Q Plot for Residuals
> # ----------------------------#
> 
> # Purpose:
> #   - Normality: Verify that resid .... [TRUNCATED] 

> # Enhanced Q-Q Plot using ggplot2
> qq_plot <- ggplot(data.frame(Residuals = residuals), aes(sample = Residuals)) +
+   stat_qq(color = "blue") +
+  .... [TRUNCATED] 

> # Display the ggplot2 Q-Q plot
> print(qq_plot)

> # Save the ggplot2 Q-Q plot if saving is enabled
> if (save_graphs) {
+   ggsave(filename = file.path(graph_save_dir, "QQ_Plot_Residuals_GGPlot2.png ..." ... [TRUNCATED] 
[1] "Saved ggplot2 Q-Q Plot of Residuals."

> # ----------------------------#
> # 9. Histogram of Residuals
> # ----------------------------#
> 
> # Purpose:
> #   - Normality
> #
> # What to Lo .... [TRUNCATED] 

> # Enhanced Histogram using ggplot2
> hist_plot <- ggplot(data.frame(Residuals = residuals), aes(x = Residuals)) +
+   geom_histogram(aes(y = ..densi .... [TRUNCATED] 

> # Display the ggplot2 histogram
> print(hist_plot)

> # Save the ggplot2 histogram if saving is enabled
> if (save_graphs) {
+   ggsave(filename = file.path(graph_save_dir, "Histogram_Residuals_GGPlot2. ..." ... [TRUNCATED] 
[1] "Saved ggplot2 Histogram of Residuals with Normal Curve."

> # Redirect output to the specified file and also print to console
> sink(output_file, append = TRUE, split = TRUE)

> print("")
[1] ""

> # ----------------------------#
> # 10. Statistical Tests
> # ----------------------------#
> 
> 
> # --------- Shapiro-Wilk Test for Normality ---- .... [TRUNCATED] 
[1] "-------- Shapiro-Wilk Test for Normality ---------"

> print("  - Normality: To check if the residuals are normally distributed.")
[1] "  - Normality: To check if the residuals are normally distributed."

> print("  - p-value > 0.05: Fail to reject null hypothesis (residuals are normally distributed).")
[1] "  - p-value > 0.05: Fail to reject null hypothesis (residuals are normally distributed)."

> print("  - p-value <= 0.05: Reject null hypothesis (residuals are not normally distributed).\n")
[1] "  - p-value <= 0.05: Reject null hypothesis (residuals are not normally distributed).\n"

> shapiro_test <- shapiro.test(residuals)

> print("Shapiro-Wilk Test Results:")
[1] "Shapiro-Wilk Test Results:"

> print(shapiro_test)

	Shapiro-Wilk normality test

data:  residuals
W = 0.96812, p-value = 1.252e-10


> # --------- Breusch-Pagan Test for Homoscedasticity ---------
> print("-------- Breusch-Pagan Test for Homoscedasticity ---------")
[1] "-------- Breusch-Pagan Test for Homoscedasticity ---------"

> print("  - Homoscedasticity: To check if residuals have constant variance across all levels of fitted values.")
[1] "  - Homoscedasticity: To check if residuals have constant variance across all levels of fitted values."

> print("  - p-value > 0.05: Fail to reject null hypothesis (homoscedasticity holds).")
[1] "  - p-value > 0.05: Fail to reject null hypothesis (homoscedasticity holds)."

> print("  - p-value <= 0.05: Reject null hypothesis (heteroscedasticity present).\n")
[1] "  - p-value <= 0.05: Reject null hypothesis (heteroscedasticity present).\n"

> # Extract the model frame from the ssn_lm model
> data_ssn <- model.frame(ssn_mod)

> # Perform Breusch-Pagan Test
> bp_test <- bptest(ssn_mod)

> print("Breusch-Pagan Test Results:")
[1] "Breusch-Pagan Test Results:"

> print(bp_test)

	studentized Breusch-Pagan test

data:  ssn_mod
BP = 59.158, df = 19, p-value = 5.254e-06


> # --------- Moran's I Test for Spatial Autocorrelation ---------
> print("\n-------- Moran's I Test for Spatial Autocorrelation ---------")
[1] "\n-------- Moran's I Test for Spatial Autocorrelation ---------"

> print("  - Spatial Autocorrelation: To determine if there is spatial autocorrelation in the residuals.")
[1] "  - Spatial Autocorrelation: To determine if there is spatial autocorrelation in the residuals."

> print("  - p-value > 0.05: Fail to reject null hypothesis (lack of spatial autocorrelation in residuals holds).")
[1] "  - p-value > 0.05: Fail to reject null hypothesis (lack of spatial autocorrelation in residuals holds)."

> print("  - p-value <= 0.05: Reject null hypothesis (spatial autocorrelation present).\n")
[1] "  - p-value <= 0.05: Reject null hypothesis (spatial autocorrelation present).\n"

> sink()

> # Extract spatial coordinates from the SSN object
> # Ensure that your SSN object has geometry information
> coords <- st_coordinates(ssn_get_data(s .... [TRUNCATED] 

> # Create a spatial weights matrix using k-nearest neighbors (k = 4 as an example)
> knn <- knearneigh(coords, k = 4)

> nb <- knn2nb(knn)

> lw <- nb2listw(nb, style = "W", zero.policy = TRUE)

> # Compute Moran's I
> moran_test <- moran.test(residuals, lw, zero.policy = TRUE)

> sink(output_file, append = TRUE, split = TRUE)

> print("Moran's I Test Results:")
[1] "Moran's I Test Results:"

> print(moran_test)

	Moran I test under randomisation

data:  residuals  
weights: lw    

Moran I statistic standard deviate = -7.382, p-value = 1
alternative hypothesis: greater
sample estimates:
Moran I statistic       Expectation          Variance 
    -0.2015572429     -0.0015527950      0.0007340585 


> # Stop redirecting output
> sink()

> # --------------------------------------------------
> # End of Script
> # --------------------------------------------------
> 
> 
